

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Klasteryzacja w Python &#8212; Silky Coders Data Science</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.4cbf315f70debaebd550c87a6162cf0f.min.css" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '7. Klasteryzacja/7_Klasteryzacja';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Klasyfikacja w Python" href="../12.%20Klasyfikacja/Klasyfikacja.html" />
    <link rel="prev" title="Czyszczenie danych" href="../10.%20Czyszczenie_danych/Czyszczenie%20danych.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/silky-logo.png" class="logo__image only-light" alt="Silky Coders Data Science - Home"/>
    <img src="../_static/silky-logo.png" class="logo__image only-dark pst-js-only" alt="Silky Coders Data Science - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Laboratorium specjalistyczne: Data Science w branży modowej, 1 semestr studiów magisterskich Matematyki na Wydziale Fizyki Technicznej i Matematyki Stosowanej na Politechnice Gdańskiej
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Fundamenty Pythona</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../0.%20Wst%C4%99p/AnacondaJupyter.html">JupyterLab &amp; Anaconda</a></li>

<li class="toctree-l1"><a class="reference internal" href="../0.%20Wst%C4%99p/TutorialBasicsPython.html">Podstawy Python</a></li>







</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Wprowadzenie do pakietów numpy i pandas</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../1.%20Tutorial%20pandas/1_Tutorial%20pandas.html">Pakiet pandas - tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2.%20Numpy_tutorial/2_Tutorial%20numpy.html">Pakiet NumPy - tutorial</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Wizualizacja danych</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../3.%20Wizualizacja_danych/3_Wizualizacja%20danych.html">Wizualizacja danych w Python</a></li>







</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Analiza statystyczna</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../4.%20Analiza_statystyczna/4_Analiza%20statystyczna.html">Analiza statystyczna - tutorial</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Wykrywanie anomalii</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../5.%20Wykrywanie_anomalii/Wykrywanie_anomalii_teoria.html">Wykrywanie anomalii - definicje</a></li>
<li class="toctree-l1"><a class="reference internal" href="../5.%20Wykrywanie_anomalii/5_Wykrywanie%20anomalii%20tutorial.html">Wykrywanie anomalii - tutorial</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Inżynieria cech</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../6.%20Inzynieria_cech/6_Inzynieria%20cech.html">Inżynieria cech</a></li>











</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Czyszczenie danych</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../10.%20Czyszczenie_danych/Czyszczenie%20danych.html">Czyszczenie danych</a></li>



</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Klasteryzacja</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Klasteryzacja w Python</a></li>



</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Klasyfikacja</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../12.%20Klasyfikacja/Klasyfikacja.html">Klasyfikacja w Python</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Regresja</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../11.%20Regresja/Regresja_lin.html">Liniowe modele regresji</a></li>
<li class="toctree-l1"><a class="reference internal" href="../11.%20Regresja/Regresja_trees.html">Regresja oparta o modele drzewiaste</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Wyjaśnialność modeli</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../8.%20Wyjasnialnosc/8_Tutorial%20metryki%20statystyczne.html">Wyjaśnialność modeli - metryki statystyczne - tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../9.%20XAI/Wyjasnialnosc_modeli_definicje.html">Wyjaśnialność modeli - definicje</a></li>
<li class="toctree-l1"><a class="reference internal" href="../9.%20XAI/9_Wyjasnialnosc%20modeli.html">Wyjaśnialność modeli - XAI - tutorial</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Przetwarzanie języka naturalnego</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../13.%20NLP/TutorialNLP.html">NLP</a></li>





</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/kikonPL/studia_PG/blob/main/7. Klasteryzacja/7_Klasteryzacja.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/kikonPL/studia_PG" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/kikonPL/studia_PG/issues/new?title=Issue%20on%20page%20%2F7. Klasteryzacja/7_Klasteryzacja.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/7. Klasteryzacja/7_Klasteryzacja.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Klasteryzacja w Python</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Klasteryzacja w Python</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#wstep">Wstęp</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#biblioteki">Biblioteki</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#przygotowanie-danych">Przygotowanie danych</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#losowe-dane-x-1">Losowe dane: <span class="math notranslate nohighlight">\(X_1\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#losowe-dane-x-2">Losowe dane: <span class="math notranslate nohighlight">\(X_2\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#losowe-dane-x-3">Losowe dane: <span class="math notranslate nohighlight">\(X_3\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#losowe-dane-x-4">Losowe dane: <span class="math notranslate nohighlight">\(X_4\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#losowe-dane-x-5">Losowe dane: <span class="math notranslate nohighlight">\(X_5\)</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#modele-klastrujace">Modele klastrujące</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#k-means">K-Means</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#czym-jest-k-means">Czym jest K-Means ++</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#przyklad-1">Przykład 1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#przyklad-2">Przykład 2</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bibliografia-k-means">Bibliografia [K-Means]</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#minibatch-k-means">MiniBatch K-Means</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#przyklad">Przykład</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bibliografia-minibatch-k-means">Bibliografia [Minibatch K-Means]</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#agglomerative-clustering">Agglomerative Clustering</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Przykład 1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Przykład 2</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bibliografia-agglomerative-clustering">Bibliografia [Agglomerative Clustering]</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spectral-clustering">Spectral Clustering</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Przykład</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bibliografia-spectral-clustering">Bibliografia [Spectral Clustering]</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dbscan">DBSCAN</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Przykład 1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">Przykład 2</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bibliografia-dbscan">Bibliografia [DBSCAN]</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#birch">BIRCH</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">Przykład 1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">Przykład 2</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bibliografia-birch">Bibliografia [BIRCH]</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#analiza-skutecznosci">Analiza skuteczności</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#silhouette-coefficient">Silhouette Coefficient</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calinski-harabasz-index">Caliński-Harabasz Index</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#davies-bouldin-index">Davies-Bouldin Index</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dunn-index">Dunn Index</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#przyklady-analiza-skutecznosci">Przykłady (analiza skuteczności)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">Przykład 1</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">Przykład 2</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="klasteryzacja-w-python">
<h1>Klasteryzacja w Python<a class="headerlink" href="#klasteryzacja-w-python" title="Permalink to this heading">#</a></h1>
<section id="wstep">
<h2>Wstęp<a class="headerlink" href="#wstep" title="Permalink to this heading">#</a></h2>
<p>Algorytmy klastrujące należą do grupy modeli uczenia maszynowego - konkretniej uczenia maszynowego bez nadzoru. Oznacza to, że zmienne nie dzielą się na zmienne objaśniające i zmienną celu. W tym kontekście nie mamy na czym “nadzorować” nauki naszego modelu. W przypadku tego rodzaju modeli naszym celem jest pogrupowanie danych w taki sposób, aby poszczególne skupienia, klastry jak najbardziej różniły się od siebie. Oczywiście podejście do grupowania różni się dla różnych zastosowań, jednak ostatecznie chcemy aby poszczególne grupy obserwacji charakteryzowały się czymś innym.</p>
<p>Poniższy tutorial wprowadzi nas w świat metod klastrujących wychodząc od podstawowych modeli do coraz to trudniejszych. W trakcie nauki zobaczymy w jaki sposób działa każdy z algorytmów oraz na czym polegają główne różnice między nimi. Dzięki takiemu podejściu możliwym jest nabranie intuicji pozwalającej określić kiedy powinniśmy korzystać z jakiego modelu. Ponadto w końcowej fazie zostaną zaprezentowane podstawowe metody badania skuteczności  algorytmów klastrujących.</p>
</section>
<section id="biblioteki">
<h2>Biblioteki<a class="headerlink" href="#biblioteki" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Manpulacja danych i operacje statystyczne</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Przykladowe ramki danych</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span><span class="p">,</span> <span class="n">make_blobs</span>

<span class="c1"># Wizualizacja danych</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Inne</span>
<span class="kn">import</span> <span class="nn">datetime</span> <span class="k">as</span> <span class="nn">dt</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="przygotowanie-danych">
<h2>Przygotowanie danych<a class="headerlink" href="#przygotowanie-danych" title="Permalink to this heading">#</a></h2>
<p>Do celów dydaktycznych przygotujemy 4 zbiory danych: <span class="math notranslate nohighlight">\(X_1\)</span>, <span class="math notranslate nohighlight">\(X_2\)</span>, <span class="math notranslate nohighlight">\(X_3\)</span>, <span class="math notranslate nohighlight">\(X_4\)</span> oraz <span class="math notranslate nohighlight">\(X_5\)</span>. Każdy z tych zbiorów charakteryzuje się czym innym. Na ich podstawie postaram się pokazać różnice między algorytmami.</p>
<section id="losowe-dane-x-1">
<h3>Losowe dane: <span class="math notranslate nohighlight">\(X_1\)</span><a class="headerlink" href="#losowe-dane-x-1" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Stworzenie losowego obiektu np.array</span>
<span class="n">X_1</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_clusters_per_class</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Typ obiektu: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Typ danych: </span><span class="si">{</span><span class="n">X_1</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Wymiar obiektu array: </span><span class="si">{</span><span class="n">X_1</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Typ obiektu: &lt;class &#39;numpy.ndarray&#39;&gt;
Typ danych: float64
Wymiar obiektu array: (1000, 2)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Wizualizacja</span>
<span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Wykres rozrzutu zmiennej x i y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/feec94b4dd7c8d08612bcca5fe6acafab5bd98f8bf2857451924f98c3761e26c.png" src="../_images/feec94b4dd7c8d08612bcca5fe6acafab5bd98f8bf2857451924f98c3761e26c.png" />
</div>
</div>
</section>
<section id="losowe-dane-x-2">
<h3>Losowe dane: <span class="math notranslate nohighlight">\(X_2\)</span><a class="headerlink" href="#losowe-dane-x-2" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_samples</span> <span class="o">=</span> <span class="mi">1500</span>
<span class="n">random_state</span> <span class="o">=</span> <span class="mi">170</span>
<span class="n">X_2</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Typ obiektu: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Typ danych: </span><span class="si">{</span><span class="n">X_2</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Wymiar obiektu array: </span><span class="si">{</span><span class="n">X_2</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Typ obiektu: &lt;class &#39;numpy.ndarray&#39;&gt;
Typ danych: float64
Wymiar obiektu array: (1500, 2)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Wizualizacja</span>
<span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Wykres rozrzutu zmiennej x i y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/6570204ff4a04121d83318a39a70ff97faccc2756984d5bf51ff883079f9eb5c.png" src="../_images/6570204ff4a04121d83318a39a70ff97faccc2756984d5bf51ff883079f9eb5c.png" />
</div>
</div>
</section>
<section id="losowe-dane-x-3">
<h3>Losowe dane: <span class="math notranslate nohighlight">\(X_3\)</span><a class="headerlink" href="#losowe-dane-x-3" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_samples</span> <span class="o">=</span> <span class="mi">1000000</span>
<span class="n">random_state</span> <span class="o">=</span> <span class="mi">170</span>
<span class="n">X_3</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Typ obiektu: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">X_3</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Typ danych: </span><span class="si">{</span><span class="n">X_3</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Wymiar obiektu array: </span><span class="si">{</span><span class="n">X_3</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Typ obiektu: &lt;class &#39;numpy.ndarray&#39;&gt;
Typ danych: float64
Wymiar obiektu array: (1000000, 2)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Wizualizacja</span>
<span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_3</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_3</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Wykres rozrzutu zmiennej x i y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/23deb74e50e083af82cf561328fdbb5ba1443d2df0105b6fa525369fdb87a9e8.png" src="../_images/23deb74e50e083af82cf561328fdbb5ba1443d2df0105b6fa525369fdb87a9e8.png" />
</div>
</div>
</section>
<section id="losowe-dane-x-4">
<h3>Losowe dane: <span class="math notranslate nohighlight">\(X_4\)</span><a class="headerlink" href="#losowe-dane-x-4" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set random state. </span>
<span class="n">rs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">generate_circle_sample_data</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate circle data with random Gaussian noise.&quot;&quot;&quot;</span>
    <span class="n">angles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>

    <span class="n">x_epsilon</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
    <span class="n">y_epsilon</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">r</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">angles</span><span class="p">)</span> <span class="o">+</span> <span class="n">x_epsilon</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">r</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">angles</span><span class="p">)</span> <span class="o">+</span> <span class="n">y_epsilon</span>
    
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>

<span class="k">def</span> <span class="nf">generate_concentric_circles_data</span><span class="p">(</span><span class="n">param_lists</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generates many circle data with random Gaussian noise.&quot;&quot;&quot;</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">num</span><span class="p">,</span> <span class="n">params</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">param_lists</span><span class="p">):</span>
        <span class="n">x_</span><span class="p">,</span> <span class="n">y_</span> <span class="o">=</span> <span class="n">generate_circle_sample_data</span><span class="p">(</span><span class="o">*</span><span class="n">params</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">x_</span><span class="p">])</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">y</span><span class="p">,</span> <span class="n">y_</span><span class="p">])</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">])</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span> 
    
    <span class="k">return</span> <span class="n">X</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Number of points per circle. </span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="c1"># Radius. </span>
<span class="n">r_list</span> <span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>
<span class="c1"># Standar deviation (Gaussian noise). </span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.2</span>

<span class="n">param_lists</span> <span class="o">=</span> <span class="p">[(</span><span class="n">r</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">r_list</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_4</span> <span class="o">=</span> <span class="n">generate_concentric_circles_data</span><span class="p">(</span><span class="n">param_lists</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Typ obiektu: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">X_4</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Typ danych: </span><span class="si">{</span><span class="n">X_4</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Wymiar obiektu array: </span><span class="si">{</span><span class="n">X_4</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Typ obiektu: &lt;class &#39;numpy.ndarray&#39;&gt;
Typ danych: float64
Wymiar obiektu array: (3000, 2)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Wizualizacja</span>
<span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_4</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_4</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Wykres rozrzutu zmiennej x i y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/798356ec9be460215efb1c2fcedfb1b2419c8750411efd3dec42d2fb4686aad9.png" src="../_images/798356ec9be460215efb1c2fcedfb1b2419c8750411efd3dec42d2fb4686aad9.png" />
</div>
</div>
</section>
<section id="losowe-dane-x-5">
<h3>Losowe dane: <span class="math notranslate nohighlight">\(X_5\)</span><a class="headerlink" href="#losowe-dane-x-5" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Number of points per circle. </span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="c1"># Radius. </span>
<span class="n">r_list</span> <span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>
<span class="c1"># Standar deviation (Gaussian noise). </span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.2</span>

<span class="n">param_lists</span> <span class="o">=</span> <span class="p">[(</span><span class="n">r</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">r_list</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_5</span> <span class="o">=</span> <span class="n">generate_concentric_circles_data</span><span class="p">(</span><span class="n">param_lists</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_5</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_clusters_per_class</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Typ obiektu: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">X_5</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Typ danych: </span><span class="si">{</span><span class="n">X_5</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Wymiar obiektu array: </span><span class="si">{</span><span class="n">X_5</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Typ obiektu: &lt;class &#39;numpy.ndarray&#39;&gt;
Typ danych: float64
Wymiar obiektu array: (10000, 2)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Wizualizacja</span>
<span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_5</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_5</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Wykres rozrzutu zmiennej x i y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/57bdc0f207343221685ed4ffb6459a343aea899e86b5c13237b98bca8b72dd31.png" src="../_images/57bdc0f207343221685ed4ffb6459a343aea899e86b5c13237b98bca8b72dd31.png" />
</div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="modele-klastrujace">
<h1>Modele klastrujące<a class="headerlink" href="#modele-klastrujace" title="Permalink to this heading">#</a></h1>
<p>W poniższym tutorialu zaprezentowanych zostanie kilka metod klastrowania, tj.:</p>
<ul class="simple">
<li><p>K-Means</p></li>
<li><p>MiniBatch K-Means</p></li>
<li><p>Agglomerative Clustering</p></li>
<li><p>Spectral Clustering</p></li>
<li><p>DBSCAN</p></li>
<li><p>BIRCH</p></li>
</ul>
<section id="k-means">
<h2>K-Means<a class="headerlink" href="#k-means" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
</pre></div>
</div>
</div>
</div>
<p>Algorytm <em>K-Means</em> jest jednym z podstawowych modeli uczenia maszynowego wykorzystywanym do klastrowania obserwacji. Jego działanie polega na minimalizacji wariancji wewnątrz klastra. Algorytm wymaga podania liczby klastrów na ile chcemy poidzielić nasze obserwacje. Wybór liczby klastrów zależy od zależności statystycznych w naszych danych jak i również wymagań biznesowych.</p>
<p>Algorytm <em>K-Means</em> ma za zadanie podzielić <span class="math notranslate nohighlight">\(N\)</span> elementową próbę zmiennych losowych <span class="math notranslate nohighlight">\(X_{j}\)</span>, gdzie <span class="math notranslate nohighlight">\(j=1,2,...\)</span> na <span class="math notranslate nohighlight">\(K\)</span> rozdzielnych klastrów <span class="math notranslate nohighlight">\(C\)</span>, gdzie każdy z klastrów jest opisany przez średnią <span class="math notranslate nohighlight">\(\mu_{k}\)</span> próbek w klastrze. Wartości średnie <span class="math notranslate nohighlight">\(\mu_{k}\)</span> nazywane są <em>centroidami</em> lub <em>środkami ciężkości</em> klastra <span class="math notranslate nohighlight">\(K\)</span>. Celem algorytmu jest wybór takich <em>centroidów</em>, które minimalizują wartość sumy kwadratów w ramach klastra:</p>
<div class="math notranslate nohighlight">
\[ \min_{C} \sum_{k=1}^{K} N_{k} \sum_{C(i) = k} (\|x_{i}-\mu_{k}\|^{2}) \]</div>
<p>gdzie <span class="math notranslate nohighlight">\(N=\sum_{k=1}^{K} N_{k}\)</span> oraz <span class="math notranslate nohighlight">\(C(i)=k\)</span> oznacza przynależność obserwacji <span class="math notranslate nohighlight">\(i\)</span> do klastra <span class="math notranslate nohighlight">\(k\)</span>.</p>
<section id="czym-jest-k-means">
<h3>Czym jest K-Means ++<a class="headerlink" href="#czym-jest-k-means" title="Permalink to this heading">#</a></h3>
<p>Algorytm <em>K-Means++</em> jest rozwinięciem algorytmu <em>K-Means</em>, które w głównej mierze polega na innej metodzie inicjalizacji <em>centroidów</em>. W klasycznej metodzie <em>K-means</em> centroidy w pierwszej iteracji dobierają się losowo - za wyjątkiem inicjalizacji ręcznej. W przypadku <em>K-means++</em> inicjalizacja polega na wybraniu punktów (ogólnie) jak najbardziej oddalonych od siebie. Ostatecznie prowadzi to do lepszych wyników niż losowa inicjalizacja.</p>
</section>
<section id="przyklad-1">
<h3>Przykład 1<a class="headerlink" href="#przyklad-1" title="Permalink to this heading">#</a></h3>
<p>Aby lepiej zrozumieć zachowanie obu algorytmów warto spojrzeć na poniższą wizualizajcę. W tym przykładzie opieramy się na losowych obserwacjach <span class="math notranslate nohighlight">\(X_2\)</span>, w których gołym okiem widać jak powinny rozłozyć się klastry dla tego zbioru. W pierwszej wizuzlizacji inijcalizujemy centroid przy pomocy estymatora <em>KMeans</em> biblioteki <em>sklearn</em> z inicjalizatorem <strong>random</strong>. W drugim przypadku inicjalizator random zastępujęmy algorytmem <strong>kmeans++</strong>. W obu przypadkach zakładamy jedną iterację algorytmu. Oznacza to, że w obu przypadkach początkowo wybrane centroidy będą tymi ostatecznymi.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># KMeans</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;WARD&#39;</span><span class="p">,</span> <span class="s1">&#39;AVERAGE&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_2</span><span class="o">.</span><span class="n">shape</span>

<span class="c1">## Inicjalizacja random</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_random</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;random&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model_random</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_random</span> <span class="o">=</span> <span class="n">model_random</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>

<span class="c1">## Inicjalizacja k-means++</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_plusplus</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model_plusplus</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_plusplus</span> <span class="o">=</span> <span class="n">model_plusplus</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_random</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_plusplus</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model_random</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">model_random</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;ro&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacją random&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model_plusplus</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">model_plusplus</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;ro&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacją k-means++&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_2 wraz z centroidami&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Cza kalkulacji</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">] Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\knajmajer\.conda\envs\jbook\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=6.
  warnings.warn(
C:\Users\knajmajer\.conda\envs\jbook\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=6.
  warnings.warn(
</pre></div>
</div>
<img alt="../_images/d1fc23855a386750dcc4e89a26a33ed96d1c5b4498bfe2f8b46b5649cfcf1dc0.png" src="../_images/d1fc23855a386750dcc4e89a26a33ed96d1c5b4498bfe2f8b46b5649cfcf1dc0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (1500, 2)
[WARD] Duration: 0:00:00.331159
[AVERAGE] Duration: 0:00:00.015630
</pre></div>
</div>
</div>
</div>
<p>Tutaj widać przewagę inicjalizatora kmeans++, który już na początku jest w stanie dobrze podzialić nasz zbiór obserwacji na 3 niezależne klastry. W przypadku inicjalizacji random potrzebujemy większej liczby iteracji, aby znaleźć dobrą lokalizacje centroidów.</p>
<div class="alert alert-block alert-info">
<b>Info</b> 
<p>Zbieżność algorytmu KMeans zależy od liczby iteracji algorytmu. Zazwyczaj przy dużej liczbie iteracji powinniśmy znaleźć globalne minimum naszej funkcji celu. Niestety czasami istnieje ryzyko znalezienia się w lokalnym minimum.</p>
</div><p>W tym prostym przypadku, w momencie gdy zwiększymy liczbę iteracji dla inicjalizacji random do 10, to algorytm osiąga przewidywane przez nas wyniki.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># KMeans</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;KMEANS_RANDOM&#39;</span><span class="p">,</span> <span class="s1">&#39;KMEANS_++&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_2</span><span class="o">.</span><span class="n">shape</span>

<span class="c1">## Inicjalizacja random</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_random</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;random&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">model_random</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_random</span> <span class="o">=</span> <span class="n">model_random</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>

<span class="c1">## Inicjalizacja k-means++</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_plusplus</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model_plusplus</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_plusplus</span> <span class="o">=</span> <span class="n">model_plusplus</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_random</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_plusplus</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model_random</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">model_random</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;ro&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacją random&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model_plusplus</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">model_plusplus</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;ro&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacją k-means++&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_2 wraz z centroidami&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Cza kalkulacji</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">] Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\knajmajer\.conda\envs\jbook\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=6.
  warnings.warn(
C:\Users\knajmajer\.conda\envs\jbook\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=6.
  warnings.warn(
</pre></div>
</div>
<img alt="../_images/cda888a28c1c7d206f4e64ea832243c2f26a8fd1ac25b9cb9320eeb47d01dbb0.png" src="../_images/cda888a28c1c7d206f4e64ea832243c2f26a8fd1ac25b9cb9320eeb47d01dbb0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (1500, 2)
[KMEANS_RANDOM] Duration: 0:00:00
[KMEANS_++] Duration: 0:00:00.018348
</pre></div>
</div>
</div>
</div>
</section>
<section id="przyklad-2">
<h3>Przykład 2<a class="headerlink" href="#przyklad-2" title="Permalink to this heading">#</a></h3>
<p>Poniższy przykład ilustruje zachowanie algorytmu <em>KMeans</em> w nieintuicyjny przez nas sposób. Oczekiwalibyśmy, aby algorytm klastrujący podzielił zbiór  obserwacji na dwa klastry względem widocznych przez nas grup. Niestety tak się nie dzieje i jest to niezależne od liczby iteracji algorytu - poprostu <em>KMeans</em> nie jest najlepszy w tego typu problemach.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># KMeans</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;KMEANS_RANDOM&#39;</span><span class="p">,</span> <span class="s1">&#39;KMEANS_++&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_2</span><span class="o">.</span><span class="n">shape</span>

<span class="c1">## Inicjalizacja random</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_random</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;random&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
<span class="n">model_random</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_random</span> <span class="o">=</span> <span class="n">model_random</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>

<span class="c1">## Inicjalizacja k-means++</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_plusplus</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
<span class="n">model_plusplus</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_plusplus</span> <span class="o">=</span> <span class="n">model_plusplus</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_random</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_plusplus</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model_random</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">model_random</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;ro&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacją random&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model_plusplus</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">model_plusplus</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;ro&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacją k-means++&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_2 wraz z centroidami&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Cza kalkulacji</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">] Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\knajmajer\.conda\envs\jbook\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\knajmajer\.conda\envs\jbook\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
</pre></div>
</div>
<img alt="../_images/c358b9a062c82426b3fcf13dd1bb1f59e744741ec6fc1e2a87a58fbcb03ee1f2.png" src="../_images/c358b9a062c82426b3fcf13dd1bb1f59e744741ec6fc1e2a87a58fbcb03ee1f2.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (1500, 2)
[KMEANS_RANDOM] Duration: 0:00:00.062651
[KMEANS_++] Duration: 0:00:00.063202
</pre></div>
</div>
</div>
</div>
</section>
<section id="bibliografia-k-means">
<h3>Bibliografia [K-Means]<a class="headerlink" href="#bibliografia-k-means" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/clustering.html#k-means">https://scikit-learn.org/stable/modules/clustering.html#k-means</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/K-means_clustering">https://en.wikipedia.org/wiki/K-means_clustering</a></p></li>
<li><p><em>The Elements of. Statistical Learning: Data Mining, Inference, and Prediction.</em> Second Edition. February 2009. Trevor Hastie · Robert Tibshirani</p></li>
<li><p><a class="reference external" href="https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1">https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1</a></p></li>
</ul>
</section>
</section>
<section id="minibatch-k-means">
<h2>MiniBatch K-Means<a class="headerlink" href="#minibatch-k-means" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">MiniBatchKMeans</span>
</pre></div>
</div>
</div>
</div>
<p>Algorytm <em>Minibatch KMeans</em> jest jednym z wariantów algorytmu <em>KMeans</em> szczególnie użytecznym w przypadku bardzo dużych zbiorów danych - w przypadkach, gdy czas ewaluacji algorytmu liczy się bardziej niż jego dokładność. <strong>MiniBatch</strong> to podzbiór danych wejściowych, losowo próbkowany w każdej iteracji podczas treningu modelu. W efekcie podział zbioru treningowego na mini-batche redukuję czas kalkulacji potrzebny do osiągnięcia zbieżności algorytmu. Ostatecznie algorytm oparty o mini-batche w ogólności osiąga tylko nieco gorsze wyniki niż klasyczna metoda <em>Kmeans</em>.</p>
<section id="przyklad">
<h3>Przykład<a class="headerlink" href="#przyklad" title="Permalink to this heading">#</a></h3>
<p>Zastosowanie algorytmu <em>MiniBatch K-Means</em> w przypadku jasno widocznych klastrów, jednak gdy obserwacji mamy więcej działa tak samo daję takie same wyniki jak algorytm <em>Kmeans</em>. Jednak w tym przypadku zależy nam na sprawdzeniu czasu przetwarzania - to tutaj powinna być widoczna różnica. Tak też się dzieje. Widoczny czas przetwarzania jasno wskazuje na przewagę algorytmu <em>MiniBatch K-Means</em> w przypadku dużych próbek. Czas przetwarzania w tym przypadku jest kilka razy szybszy przy zachowaniu niemal takiego samego podziału na klastry.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;KMEANS_++&#39;</span><span class="p">,</span> <span class="s1">&#39;MINIBATCH_KMEANS&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_3</span><span class="o">.</span><span class="n">shape</span>

<span class="c1"># KMeans</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_random</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">model_random</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_3</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_random</span> <span class="o">=</span> <span class="n">model_random</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_3</span><span class="p">)</span>

<span class="c1">#  Minibatch K-means</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_minibatch</span> <span class="o">=</span> <span class="n">MiniBatchKMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">model_minibatch</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_3</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_minibatch</span> <span class="o">=</span> <span class="n">model_minibatch</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_3</span><span class="p">)</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_3</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_3</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_random</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_3</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_3</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_minibatch</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model_random</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">model_random</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;ro&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie MiniBatch KMeans&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model_minibatch</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">model_minibatch</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;ro&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacją k-means++&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_3 wraz z centroidami&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Cza kalkulacji</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">] Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\knajmajer\.conda\envs\jbook\Lib\site-packages\sklearn\cluster\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size &gt;= 3584 or by setting the environment variable OMP_NUM_THREADS=1
  warnings.warn(
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\knajmajer\.conda\envs\jbook\Lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Creating legend with loc=&quot;best&quot; can be slow with large amounts of data.
  fig.canvas.print_figure(bytes_io, **kw)
</pre></div>
</div>
<img alt="../_images/0b3adb3391d01abe1c8bd4a57ff1a710f80b7c73c085a9e35c06a5fb1c3eceb2.png" src="../_images/0b3adb3391d01abe1c8bd4a57ff1a710f80b7c73c085a9e35c06a5fb1c3eceb2.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (1000000, 2)
[KMEANS_++] Duration: 0:00:03.517580
[MINIBATCH_KMEANS] Duration: 0:00:00.196371
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-success">
<b>Zadanie</b> 
<p>Korzystając z kodu dostępnego przy powyższych wizualizacjach znajdź współrzędne <em>centroidów</em> dla algorytmu KMeans oraz <em>MiniBatchKMeans</em>. Czy w tym przypadku jest jakaś różnica? Policz odległość Euklidesową między nimi.</p>
<p><em>Podpowiedź</em>: Najpierw znajdź punkty, które są najbliżej siebie. Może się zdarzyć, że oznaczenie klastrów 0, 1, 2 będzie różne dla różnych algorytmów.</p>
</div></section>
<section id="bibliografia-minibatch-k-means">
<h3>Bibliografia [Minibatch K-Means]<a class="headerlink" href="#bibliografia-minibatch-k-means" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/clustering.html#mini-batch-kmeans">https://scikit-learn.org/stable/modules/clustering.html#mini-batch-kmeans</a></p></li>
</ul>
</section>
</section>
<section id="agglomerative-clustering">
<h2>Agglomerative Clustering<a class="headerlink" href="#agglomerative-clustering" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">AgglomerativeClustering</span>
</pre></div>
</div>
</div>
</div>
<p>Klastrowanie hierarchiczne polega na budowaniu zagnieżdżonych klastrów poprzez ich kolejne scalanie lub dzielenie. Hierarchia klastrów jest reprezentowana jako drzewo (lub dendrogram). Korzeń drzewa jest unikalnym skupiskiem, które gromadzi wszystkie próbki, a liście są skupiskami z tylko jedną próbką. Obiekt <code class="docutils literal notranslate"><span class="pre">AgglomerativeClustering</span></code> wykonuje hierarchiczne grupowanie przy użyciu podejścia oddolnego: każda obserwacja rozpoczyna się we własnym klastrze, a klastry są sukcesywnie łączone ze sobą. Kryteria powiązania <code class="docutils literal notranslate"><span class="pre">linkage</span></code> określają metrykę używaną w strategii łączenia:</p>
<ul class="simple">
<li><p><strong>Ward</strong> - minimalizuje sumę kwadratów różnic we wszystkich klastrach. Jest to podejście minimalizujące wariancje i w tym sensie jest podobne do funkcji celu k-średnich, ale rozwiązywane za pomocą aglomeracyjnego podejścia hierarchicznego.</p></li>
<li><p><strong>Maximum linkage</strong>/<strong>Complete linkage</strong> - minimalizuje maksymalną odległość między obserwacjami par klastrów.</p></li>
<li><p><strong>Average linkage</strong> - minimalizuje średnią odległości między wszystkimi obserwacjami par klastrów.</p></li>
<li><p><strong>Single linkage</strong> - minimalizuje odległość pomiędzy najbliższymi obserwacjami par klastrów.</p></li>
</ul>
<section id="id1">
<h3>Przykład 1<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h3>
<p>Metody aglomeracyjne w przypadku klastrów o jasno widocznym środku ciężkości klastra radzą sobie bardzo dobrze. Obie metody <em>Ward</em> oraz <em>Average</em> bardzo dobrze dzielą obserwacje na klastry. Podział jest taki sam jak w przypadku algorytmów z rodziny <em>KMeans</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;WARD&#39;</span><span class="p">,</span> <span class="s1">&#39;AVERAGE&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_2</span><span class="o">.</span><span class="n">shape</span>

<span class="c1"># Algorytm Ward</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_ward</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">linkage</span><span class="o">=</span><span class="s1">&#39;ward&#39;</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">model_ward</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_ward</span> <span class="o">=</span> <span class="n">model_ward</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># Algorytm Average</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_avg</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">linkage</span><span class="o">=</span><span class="s1">&#39;average&#39;</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">model_avg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_avg</span> <span class="o">=</span> <span class="n">model_avg</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_ward</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_avg</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie WARD linkage&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie Average linkage&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Czas kalkulacji</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">] Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/9da0fabbf79138393c5db648ff7fcad7dd57ccfb1171692cfc0789e82e966dfc.png" src="../_images/9da0fabbf79138393c5db648ff7fcad7dd57ccfb1171692cfc0789e82e966dfc.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (1500, 2)
[WARD] Duration: 0:00:00.125844
[AVERAGE] Duration: 0:00:00.110446
</pre></div>
</div>
</div>
</div>
</section>
<section id="id2">
<h3>Przykład 2<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h3>
<p>Drugi przykład jest nieco trudniejszy. Klastry są widoczne ale są różnych kształtów. W tym przypadku oba algorytmy sobie nie radzą. Metoda <em>Ward</em> dzieli klastry podobnie jak algorytm <em>KMeans</em>. W przypadku metody opartej o powiązanie <em>Average</em> dostajemy dwa klastry z czego jeden z nich składa się z jednej obserwacji - raczej nie tego oczekujemy po algorytmie klastrującym.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;WARD&#39;</span><span class="p">,</span> <span class="s1">&#39;AVERAGE&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_1</span><span class="o">.</span><span class="n">shape</span>

<span class="c1"># Algorytm Ward</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_ward</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linkage</span><span class="o">=</span><span class="s1">&#39;ward&#39;</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">model_ward</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_ward</span> <span class="o">=</span> <span class="n">model_ward</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># Algorytm Average</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_avg</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linkage</span><span class="o">=</span><span class="s1">&#39;average&#39;</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">model_avg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_avg</span> <span class="o">=</span> <span class="n">model_avg</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_ward</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_avg</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie WARD linkage&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie Average linkage&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Cza kalkulacji</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">] Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/e603de3e9b968aeebe9eceb2097a76c7f9feaa412b58ce7713ee9952672deda5.png" src="../_images/e603de3e9b968aeebe9eceb2097a76c7f9feaa412b58ce7713ee9952672deda5.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (1000, 2)
[WARD] Duration: 0:00:00.015620
[AVERAGE] Duration: 0:00:00.031252
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-success">
<b>Zadanie</b> 
<p>Spróbuj analogicznie jak powyżej zastosować algorytmy <em>Single Linkage</em> oraz <em>Maximum Linkage</em>.</p>
</div></section>
<section id="bibliografia-agglomerative-clustering">
<h3>Bibliografia [Agglomerative Clustering]<a class="headerlink" href="#bibliografia-agglomerative-clustering" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering">https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Hierarchical_clustering">https://en.wikipedia.org/wiki/Hierarchical_clustering</a></p></li>
</ul>
</section>
</section>
<section id="spectral-clustering">
<h2>Spectral Clustering<a class="headerlink" href="#spectral-clustering" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">SpectralClustering</span>
</pre></div>
</div>
</div>
</div>
<p>W praktyce <em>Spectral Clustering</em> jest bardzo przydatne, gdy struktura poszczególnych klastrów jest wysoce niewypukła lub bardziej ogólnie, gdy miara środka i rozproszenia klastra nie jest odpowiednim opisem całego klastra, na przykład gdy klastry są zagnieżdżonymi okręgami na płaszczyźnie 2D. Cała teoria związana z klastrowaniem spektralnym wywodzi się z teorii grafów oraz algebry liniowej. Algorytm składa się na wejściu  danych w postaci macierzy podobieństwa <em>adjacency matrix</em>, a następnie wyznacza się macierz Laplace’a. Kolejnym etapem jest wyliczenie wektorów i wartosci własnych macierzy Laplace’a. Ostatecznie na wyznaczonych wektorach własnych uruchamiany algorytm <em>k-means</em>.</p>
<p>Aby wyliczyć macierz <em>adjacency matrix</em> możemy wykorzystać metody: skorzystać z algorytmu <em>k nearest neighbors</em> lub skorzystać z kalkulacji przy pomocy jądra <em>rbf</em>. W pierwszym przypadku do wyliczenia macierzy wykorzystujemy teorię grafów oraz algorytm <em>k nearest neighbor</em> znajdujący k najbliższych sąsiadów. W drugim przypadku wykorzystujemy jądro RBF, które (Radial basis function) na dwóch próbkach <span class="math notranslate nohighlight">\(x_{1}\)</span> i <span class="math notranslate nohighlight">\(x_{2}\)</span>, reprezentowanych jako wektory cech w pewnej przestrzeni wejściowej, jest zdefiniowane jako:</p>
<div class="math notranslate nohighlight">
\[ K(x_{1}, x_{2}) = \exp(-\gamma(\| x_{1} - x_{2}\|^{2})) \]</div>
<p>gdzie parameter <span class="math notranslate nohighlight">\(\gamma\)</span> jest parametrem modelu. Czasami możemy się spotkać z zapisem gdzie <span class="math notranslate nohighlight">\(\gamma = \frac{1}{2\sigma^{2}}\)</span>. Wynika to z tego, że jądro RBF jest pewnym “uogólnieniem” jądra Gaussowskiego. W dużym uproszczeniu oznacza to, że przy wywołaniu metody <code class="docutils literal notranslate"><span class="pre">fit</span></code> liczymy macierz <em>adjacency matrix</em> przy pomocy jądra RBF. A następnie dokonywana są kolejne kalkulacje tj. kalkulacja macierzy Laplace’a oraz wyznaczenie wektorów i wartości własnych.</p>
<section id="id3">
<h3>Przykład<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h3>
<p>W poniższym przykładzie dużo lepszym wyborem jest algorytm <em>SpectralClustering</em> wraz z metodą wyznaczenia macierzy podobieństwa <code class="docutils literal notranslate"><span class="pre">affinity</span></code> ustawioną jako <em>rbf</em>. Przy dobrze dobranych hiperparametrach jesteśmy w stanie skutecznie odseparować od siebie obie grupy obserwacji. W naszym odczuciu dobranie lepszych wartości parametrów dla metody <em>knn</em> jest trudniejsze. Ponadto wydaje się, że algorytm oparty o <em>rbf</em> działa nieco szybciej.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;SPECTRAL_KNN&#39;</span><span class="p">,</span> <span class="s1">&#39;SPECTRAL_RBF&#39;</span><span class="p">,</span> <span class="s1">&#39;KMEANS&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_1</span><span class="o">.</span><span class="n">shape</span>

<span class="c1"># Spectral Clustering (KNN)</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_sc</span> <span class="o">=</span> <span class="n">SpectralClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">affinity</span><span class="o">=</span><span class="s1">&#39;nearest_neighbors&#39;</span><span class="p">,</span>  <span class="n">assign_labels</span><span class="o">=</span><span class="s1">&#39;kmeans&#39;</span><span class="p">)</span>
<span class="n">model_sc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_spectral_knn</span> <span class="o">=</span> <span class="n">model_sc</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># Spectral Clustering (RBF)</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_sc</span> <span class="o">=</span> <span class="n">SpectralClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">affinity</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">assign_labels</span><span class="o">=</span><span class="s1">&#39;kmeans&#39;</span><span class="p">)</span>
<span class="n">model_sc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_spectral_rbf</span> <span class="o">=</span> <span class="n">model_sc</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># K-means++</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_plusplus</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
<span class="n">model_plusplus</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_plusplus</span> <span class="o">=</span> <span class="n">model_plusplus</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_spectral_knn</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_spectral_rbf</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_plusplus</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie Spectral Clustering (KNN)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie Spectral Clustering (RBF)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacją k-means++&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_1 wraz z centroidami&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Czas kalkulacji</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">] Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\knajmajer\.conda\envs\jbook\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\knajmajer\.conda\envs\jbook\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\knajmajer\.conda\envs\jbook\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
</pre></div>
</div>
<img alt="../_images/124655e6ee93fbdc41c9b97d56950dfe4efbc336e7d219f0d133605f5c568f73.png" src="../_images/124655e6ee93fbdc41c9b97d56950dfe4efbc336e7d219f0d133605f5c568f73.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (1000, 2)
[SPECTRAL_KNN] Duration: 0:00:00.235930
[SPECTRAL_RBF] Duration: 0:00:03.836767
[KMEANS] Duration: 0:00:00.015738
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-success">
<b>Zadanie</b> 
<p>Sprawdź co się stanie gdy zmienisz wartość parametru <code class="docutils literal notranslate"><span class="pre">gamma</span></code>.</p>
</div></section>
<section id="bibliografia-spectral-clustering">
<h3>Bibliografia [Spectral Clustering]<a class="headerlink" href="#bibliografia-spectral-clustering" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html#r5f6cbeb1558e-2">https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html#r5f6cbeb1558e-2</a></p></li>
<li><p><a class="reference external" href="https://towardsdatascience.com/spectral-clustering-aba2640c0d5b">https://towardsdatascience.com/spectral-clustering-aba2640c0d5b</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Radial_basis_function_kernel">https://en.wikipedia.org/wiki/Radial_basis_function_kernel</a></p></li>
</ul>
</section>
</section>
<section id="dbscan">
<h2>DBSCAN<a class="headerlink" href="#dbscan" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">DBSCAN</span>
</pre></div>
</div>
</div>
</div>
<p>Algorytm <em>DBSCAN</em> w dużym uproszczeniu polega na interpretacji klastrów jako pół o wysokiej gęstości odseparowanych polami o niskiej gęstości. To powoduję, że klastry znaleznione przy pomocy alorytmu <em>DBSCAN</em> mogą mieć dowolny kształt w stosunku do klastrów powstałych przy pomocy algorytmu <em>KMeans</em>, który zakłada wypukłość klastrów. Główną składową algorytmu jest pojęcie <em>próbki podstawowej</em>, która jest próbką znajdującą się w obszarze wysokiej gęstości. Wtedy klaster jest zbiorem próbek podstawowych, dla których każda jest blisko kolejnej próbki (odległość liczona za pomocą przyjętej metryki odległości) oraz zbioru próbek niepodstawowych, które są blisko próbki podstawowej, ale nie są próbką podstawową. Algorytm opiera się na dwóch podstawowych parametrach: <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> oraz <code class="docutils literal notranslate"><span class="pre">eps</span></code>, które formalnie definiują co użytkownik ma na myśli mówiąc o gęstości. Wysoka wartość <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> oraz niska wartość <code class="docutils literal notranslate"><span class="pre">eps</span></code> oznacza potrzebę uzyskania wyższej gęstości obserwacji potrzebną do uformowania się klastra. Dokładniej, definujemy <em>próbkę podstawową</em> jako podzbiór obserwacji dla którego istnieje <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> innych podzbiorów w odległości <code class="docutils literal notranslate"><span class="pre">eps</span></code>, które są “sąsiadami” <em>próbki podstawowej</em>. Oznacza to, że <em>próbka podstawowa</em> znajduje się w gęstym obszarze przestrzeni wektorowej.</p>
<section id="id4">
<h3>Przykład 1<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h3>
<p>Pierwszy przykład obejmuje klastrowanie zbioru <span class="math notranslate nohighlight">\(X_1\)</span>. Poniżej porówanjmy zachowanie trzech algorytmów: DBSCAN, Spectral Clustering oraz KMeans. Warto zwrócić uwagę na jedną rzecz w przypadku algorytmu <em>DBSCAN</em>. Przy definiowaniu parametrów modelu nie znajdziemy parametru <code class="docutils literal notranslate"><span class="pre">n_clusters</span></code> tak jak w przypadku poprzednich. Jest to bardzo duży atut tego algorytmu, ponieważ on sam dzieli nasz zbiór na odpowiednią liczbę klastrów w zależności jak zdefiniujemy gęstość za pomocą parametrów <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> oraz <code class="docutils literal notranslate"><span class="pre">eps</span></code>.</p>
<p>Przy zadanych parametrach wydaję się, że algorytm <em>Spectral Clustering</em> działa najlepiej. Jednak jak przyjrzymy się bliżej to może się wydawać, że algorytm <em>DBSCAN</em> dzieli obserwacje na 3 klastry. Nic bardziej mylnego. Labelka “-1” oznacza, że daną obsewację nie udało się zaliczyć do żadnego klastra - przynajmniej w przypadku tak określonych parametrów <code class="docutils literal notranslate"><span class="pre">min_sample</span></code> oraz <code class="docutils literal notranslate"><span class="pre">eps</span></code>. Zatem obserwacje z labelką “-1” można określić jako anomalie w danym zbiorze obserwacji. Właśnie wykrywanie anomalii jest kolejnym zastosowaniem algorytmu <em>DBSCAN</em> oprócz klastrowania. W powyższym przykładzie zapewne uda się podzielić zbiór przy pomocy <em>DBSCAN</em> jeszcze lepiej (zmieniając parametry), ponieważ wydaję się że niektóre z obserwacji mogą jednak nie być anomaliami.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;DBSCAN&#39;</span><span class="p">,</span> <span class="s1">&#39;SPECTRAL&#39;</span><span class="p">,</span> <span class="s1">&#39;KMEANS++&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_1</span><span class="o">.</span><span class="n">shape</span>

<span class="c1"># Algorytm DBSCAN</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_dbscan</span> <span class="o">=</span> <span class="n">DBSCAN</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">min_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">model_dbscan</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_dbscan</span> <span class="o">=</span> <span class="n">model_dbscan</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># Spectral clustering</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_sc</span> <span class="o">=</span> <span class="n">SpectralClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">10.0</span><span class="p">)</span>
<span class="n">model_sc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_sc</span> <span class="o">=</span> <span class="n">model_sc</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># K-means++</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_plusplus</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
<span class="n">model_plusplus</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_plusplus</span> <span class="o">=</span> <span class="n">model_plusplus</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_dbscan</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_sc</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_plusplus</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie DBSCAN&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie Spectral Clustering&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacją k-means++&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_1 wraz z centroidami&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Cza kalkulacji</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">] Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\knajmajer\.conda\envs\jbook\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
C:\Users\knajmajer\.conda\envs\jbook\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
</pre></div>
</div>
<img alt="../_images/085683ed3c802b32b1d07f074976d9ee46752a026a889f35186f102a8afe140f.png" src="../_images/085683ed3c802b32b1d07f074976d9ee46752a026a889f35186f102a8afe140f.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (1000, 2)
[DBSCAN] Duration: 0:00:00.014120
[SPECTRAL] Duration: 0:00:00.220607
[KMEANS++] Duration: 0:00:00
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-success">
<b>Zadanie</b> 
<p>Spróbuj nieco zmienić hiperparametry <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> oraz <code class="docutils literal notranslate"><span class="pre">eps</span></code>. Czy uda ci się lepiej podzielić obserwacje na klastry ?</p>
</div></section>
<section id="id5">
<h3>Przykład 2<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h3>
<p>Tym razem na warsztat weźmy zbiór danych <span class="math notranslate nohighlight">\(X_4\)</span>, który składa się z trzech okręgów o różnej średnicy. Zobaczmy jak w tym przypadku zadziała algorytm <em>DBSCAN</em> na tle innych.</p>
<p>Jak widać z powyższymi parametrami model <em>DBSCAN</em> znajduję klastry w taki sam sposób jak model <em>Spectral Clustering</em>. Jednakże bardzo duża różnica tkwi w czasie przeliczeń. W przypadku <em>DBSCAN</em> klastrowanie następuje ponad 1000 razy szybciej - przynajmniej w tym konkretnym przypadku. Wynika to ze złożoności obliczeń w algorytmie <em>Spectral Clustering</em>. Jeśli chodzi o <em>KMeans</em> to podobnie jak było to w <em>Przykład 1</em> klastry są dobierane zgodnie z założeniem wypukłości klastrów, co w tym przypadku nie jest oczekiwane.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;DBSCAN&#39;</span><span class="p">,</span> <span class="s1">&#39;SPECTRAL&#39;</span><span class="p">,</span> <span class="s1">&#39;KMEANS++&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_4</span><span class="o">.</span><span class="n">shape</span>

<span class="c1"># Algorytm DBSCAN</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_dbscan</span> <span class="o">=</span> <span class="n">DBSCAN</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">min_samples</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">model_dbscan</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_4</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_dbscan</span> <span class="o">=</span> <span class="n">model_dbscan</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># Algorytm Spectral clustering</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_sc</span> <span class="o">=</span> <span class="n">SpectralClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">10.0</span><span class="p">)</span>
<span class="n">model_sc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_4</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_sc</span> <span class="o">=</span> <span class="n">model_sc</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># Algorytm K-means++</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_plusplus</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
<span class="n">model_plusplus</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_4</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_plusplus</span> <span class="o">=</span> <span class="n">model_plusplus</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_4</span><span class="p">)</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_4</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_4</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_dbscan</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_4</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_4</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_sc</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_4</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_4</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_plusplus</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie DBSCAN&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie Spectral Clustering&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacją k-means++&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_4 wraz z centroidami&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Cza kalkulacji</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">] Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\knajmajer\.conda\envs\jbook\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=12.
  warnings.warn(
C:\Users\knajmajer\.conda\envs\jbook\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=12.
  warnings.warn(
</pre></div>
</div>
<img alt="../_images/429fd1bf6e88076e7a68b46bdfb54c728e83dc4187b662b1a6598794c4599d0a.png" src="../_images/429fd1bf6e88076e7a68b46bdfb54c728e83dc4187b662b1a6598794c4599d0a.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (3000, 2)
[DBSCAN] Duration: 0:00:00.015756
[SPECTRAL] Duration: 0:00:11.484307
[KMEANS++] Duration: 0:00:00.015633
</pre></div>
</div>
</div>
</div>
</section>
<section id="bibliografia-dbscan">
<h3>Bibliografia [DBSCAN]<a class="headerlink" href="#bibliografia-dbscan" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/clustering.html#dbscan">https://scikit-learn.org/stable/modules/clustering.html#dbscan</a></p></li>
<li><p><a class="reference external" href="https://towardsdatascience.com/dbscan-clustering-explained-97556a2ad556">https://towardsdatascience.com/dbscan-clustering-explained-97556a2ad556</a></p></li>
<li><p><a class="reference external" href="https://dashee87.github.io/data%20science/general/Clustering-with-Scikit-with-GIFs/">https://dashee87.github.io/data science/general/Clustering-with-Scikit-with-GIFs/</a></p></li>
</ul>
</section>
</section>
<section id="birch">
<h2>BIRCH<a class="headerlink" href="#birch" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">Birch</span>
</pre></div>
</div>
</div>
</div>
<p>Algorytm <em>Balanced Iterative Reducing and Clustering using Hierarchies</em> w skrócie <strong>BIRCH</strong> buduje drzewo o nazwie <em>Clustering Feature Tree</em> (CFT) dla podanych danych, które są kompresowane stratnie do zestawu węzłów <em>Clustering Feature Nodes</em> (Nodes CF). Węzły CF mają pewną liczbę podklastrów zwanych <em>Clustering Feature Subclasters</em> (CFS). Podklastry CF przechowują informacje niezbędne do grupowania, co zapobiega konieczności przechowywania wszystkich danych wejściowych w pamięci. Informacje te obejmują:</p>
<ul class="simple">
<li><p><em>Number of Samples</em> - liczbę próbek w podgrupie,</p></li>
<li><p><em>Linear Sum</em> - sumę liniową, która jest n-wymiarowem wektorm przechowującym sumę wszystkich próbek,</p></li>
<li><p><em>Squared Sum</em> - suma kwadratów normy L2 dla wszystkich próbek,</p></li>
<li><p><em>Centroids</em> - centroidy równe <em>Linear Sum</em> / <em>Number of Samples</em>,</p></li>
<li><p>Norma kwadratowa centroidów.</p></li>
</ul>
<p>W dużym uproszczeniu algorytm <strong>BIRCH</strong> zajmuje się dużymi zestawami danych, najpierw generując bardziej zwarte podsumowanie, które zachowuje jak najwięcej informacji o rozkładzie, a następnie grupując podsumowanie danych zamiast oryginalnego zestawu obserwacji. Więcej informacji znajdziecie pod linkami w bibliografii.</p>
<section id="id6">
<h3>Przykład 1<a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;BIRCH&#39;</span><span class="p">,</span> <span class="s1">&#39;MINIBATCH_KMEANS&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_3</span><span class="o">.</span><span class="n">shape</span>


<span class="c1"># BIRCH</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_brc</span> <span class="o">=</span> <span class="n">Birch</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">branching_factor</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">model_brc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_3</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_birch</span> <span class="o">=</span> <span class="n">model_brc</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1">#  Minibatch K-means</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_minibatch</span> <span class="o">=</span> <span class="n">MiniBatchKMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">model_minibatch</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_3</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_minibatch</span> <span class="o">=</span> <span class="n">model_minibatch</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_3</span><span class="p">)</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>


<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_3</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_3</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_birch</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_3</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_3</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_minibatch</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie BIRCH&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie MiniBatch KMeans&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_3&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Cza kalkulacji</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">] Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\knajmajer\.conda\envs\jbook\Lib\site-packages\sklearn\cluster\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size &gt;= 3584 or by setting the environment variable OMP_NUM_THREADS=1
  warnings.warn(
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\knajmajer\.conda\envs\jbook\Lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Creating legend with loc=&quot;best&quot; can be slow with large amounts of data.
  fig.canvas.print_figure(bytes_io, **kw)
</pre></div>
</div>
<img alt="../_images/a17ecdf08f8c603972007a885817a3ca7892e5e75bc4f906df0418e7bbb6f710.png" src="../_images/a17ecdf08f8c603972007a885817a3ca7892e5e75bc4f906df0418e7bbb6f710.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (1000000, 2)
[BIRCH] Duration: 0:00:54.427949
[MINIBATCH_KMEANS] Duration: 0:00:17.220540
</pre></div>
</div>
</div>
</div>
</section>
<section id="id7">
<h3>Przykład 2<a class="headerlink" href="#id7" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;BIRCH&#39;</span><span class="p">,</span> <span class="s1">&#39;MINIBATCH_KMEANS&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_5</span><span class="o">.</span><span class="n">shape</span>


<span class="c1"># BIRCH</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_brc</span> <span class="o">=</span> <span class="n">Birch</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">branching_factor</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">model_brc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_5</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_birch</span> <span class="o">=</span> <span class="n">model_brc</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1">#  Minibatch K-means</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_minibatch</span> <span class="o">=</span> <span class="n">MiniBatchKMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">model_minibatch</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_5</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_minibatch</span> <span class="o">=</span> <span class="n">model_minibatch</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_5</span><span class="p">)</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>


<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_5</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_5</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_birch</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_5</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_5</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_minibatch</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie BIRCH&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie MiniBatch KMeans&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_5&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Cza kalkulacji</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">] Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\knajmajer\.conda\envs\jbook\Lib\site-packages\sklearn\cluster\_kmeans.py:1955: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size &gt;= 3584 or by setting the environment variable OMP_NUM_THREADS=1
  warnings.warn(
</pre></div>
</div>
<img alt="../_images/19e046891823114375565dd563bffd785bdfc8d70dd77b94d1e4dff0206a7bde.png" src="../_images/19e046891823114375565dd563bffd785bdfc8d70dd77b94d1e4dff0206a7bde.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (10000, 2)
[BIRCH] Duration: 0:00:00.331123
[MINIBATCH_KMEANS] Duration: 0:00:00.549658
</pre></div>
</div>
</div>
</div>
</section>
<section id="bibliografia-birch">
<h3>Bibliografia [BIRCH]<a class="headerlink" href="#bibliografia-birch" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/clustering.html#mean-shift">https://scikit-learn.org/stable/modules/clustering.html#mean-shift</a></p></li>
<li><p><a class="reference external" href="https://towardsdatascience.com/machine-learning-birch-clustering-algorithm-clearly-explained-fb9838cbeed9">https://towardsdatascience.com/machine-learning-birch-clustering-algorithm-clearly-explained-fb9838cbeed9</a></p></li>
</ul>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="analiza-skutecznosci">
<h1>Analiza skuteczności<a class="headerlink" href="#analiza-skutecznosci" title="Permalink to this heading">#</a></h1>
<p>Badanie skuteczności algorytmów klastrujących nie jest łatwe. W zależności od problemu biznesowego oczekujemy zupełnie innych wyników. Dodatkowo w przypadku danych wielowymiarowych, gdzie wykorzystujemy do klastrowania więcej niż dwie, trzy zmienne pojawiają się dodatkowo problemy z wizualizacją wyników. W tym przypadku mogą się przydać algorytmy z rodziny redukcji wymiarowości tj. PCA, ICA czy TSNE. Nadal jednak potrzebujemy odpowiedzieć sobie na pytanie czy dany podział na klastry jest prawidłowy? W końcu nie będziemy dokonywać decyzji biznesowych  wyłącznie na podstawie wizualizacji wyników - do tego potrzebujemy odpowiednich metryk. Dodatkowo w przypadku automatyzacji naszego procesu nie będzie czasu na to, aby przy każdym przeliczeniu sprawdzać wizualne wyniki, ale będziemy chcieli podejmować decyzje na podstawie wybranej, bądź wybranych metryk aby ostatecznie nasz proces był w pełni zautomatyzowany.</p>
<p>W poniższej części zostanie wprowadzonych kilka podstawowych miar, które mogą pomóc nam w zadaniu analizy skuteczności klastrowania.</p>
<section id="silhouette-coefficient">
<h2>Silhouette Coefficient<a class="headerlink" href="#silhouette-coefficient" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>
</pre></div>
</div>
</div>
</div>
<p>Jedną z najpopularniejszych metod do oceny jakości klastrowania jest metryka <em>Silhouette Coefficient</em>. Jej wysoką wartość interpretujemy jako bardzo dobrze wykonane klastrowanie. Metryka zdefiniowana jest dla każdej obserwacji z osobna w następujący sposób:</p>
<div class="math notranslate nohighlight">
\[ s = \frac{b-a}{\max(a, b)}\]</div>
<p>gdzie:</p>
<ul class="simple">
<li><p>a: średnia odległość pomiędzy obserwacją oraz resztą obserwacji z tego samego klastra</p></li>
<li><p>b: średnia odległość pomiędzy obserwacją oraz innymi obserwacjami z kolejnego <strong>najbliższego</strong> klastra</p></li>
</ul>
<p>Metryka <em>Silhouette coefficient</em> dla zbioru obserwacji jest średnią z wartości <span class="math notranslate nohighlight">\(s\)</span> dla każdej obserwacji z osobna.</p>
<p><strong>Warto zapamiętać</strong></p>
<ul class="simple">
<li><p>metryka osiąga wyniki z przedziału [-1, 1], gdzie -1 oznacza zupełnie błędne dopasowanie, a 1 bardzo dobrze podzielone zbiory. W przypadku wartości 0 nie jesteśmy nic w stanie stwierdzić a propos podziału zbioru danych na grupy</p></li>
<li><p>wynik jest wyższy, gdy klastry są gęste i dobrze odseparowane od siebie (Przykład 1)</p></li>
<li><p>wynik jest wyższy w przypadku klastrów wypukłych (Przykład 1), niż dla innych rodzajów klastrów np. takich opartych na gęstości jak DBSCAN (Przykład 2)</p></li>
</ul>
</section>
<section id="calinski-harabasz-index">
<h2>Caliński-Harabasz Index<a class="headerlink" href="#calinski-harabasz-index" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">calinski_harabasz_score</span>
</pre></div>
</div>
</div>
</div>
<p>Kolejną metryką przydatną w trakcie klastrowania jest mniej popularna metryka <em>Calinski-Harabasz</em>, inaczej zwana <em>Variance Ratio Criterion</em>. Została ona zaproponowana przez Polskich naukowców Calińskiego i Harabasza w 1972 roku.  Podobnie jak w przypadku poprzedniej metryki wyższa wartość oznacza lepsze grupowanie danych w klastry. Metrykę <em>Variance Ratio Criterion</em> dla zbioru danych <span class="math notranslate nohighlight">\(E\)</span> o liczbie obserwacji <span class="math notranslate nohighlight">\(n\)</span> oraz liczbie klastrów <span class="math notranslate nohighlight">\(k\)</span> definiujemy w następujacy sposób:</p>
<div class="math notranslate nohighlight">
\[ s = \frac{tr(B_{k})}{tr(W_{k})} \cdot \frac{n - k}{k-1}\]</div>
<p>gdzie <span class="math notranslate nohighlight">\(tr(B_{k})\)</span> oraz <span class="math notranslate nohighlight">\(tr(W_{k})\)</span> jest śladem macierzy <span class="math notranslate nohighlight">\(B_{k}\)</span> oraz <span class="math notranslate nohighlight">\(W_{k}\)</span>. Dla przypomnienia ślad macierzy <span class="math notranslate nohighlight">\(A\)</span> definiujemy jako:</p>
<div class="math notranslate nohighlight">
\[ tr(A) = \sum_{i=1}^{n} a_{ii} = a_{11}+a_{22}+a_{33}+...\]</div>
<p>czyli jest to suma wartości na przekątnej macierzy kwdaratowej. Macierze <span class="math notranslate nohighlight">\(B_{k}\)</span> oraz <span class="math notranslate nohighlight">\(W_{k}\)</span> są wyliczane dla każdego klastra z osobna i mają następująco postać:</p>
<div class="math notranslate nohighlight">
\[ W_{k} = \sum_{q=1}^{k}\sum_{x \in C_{q}}(x-c_{q})(x-c_{q})^{T} \]</div>
<div class="math notranslate nohighlight">
\[ B_{k} = \sum_{q=1}^{k}n_{q}(c_{q}-c_{E})(c_{q}-c_{E})^{T} \]</div>
<p>gdzie <span class="math notranslate nohighlight">\(C_{q}\)</span> jest zbiorem obserwacji klastra <span class="math notranslate nohighlight">\(q\)</span>, <span class="math notranslate nohighlight">\(c_{q}\)</span> jest środkiem klastra <span class="math notranslate nohighlight">\(q\)</span>, <span class="math notranslate nohighlight">\(c_{E}\)</span> jest środkiem całego zbioru obserwacji <span class="math notranslate nohighlight">\(E\)</span> oraz <span class="math notranslate nohighlight">\(n_{q}\)</span> jest liczbą obserwacji w klastrze <span class="math notranslate nohighlight">\(q\)</span>.</p>
<p><strong>Warto zapamiętać</strong></p>
<ul class="simple">
<li><p>wartość metryki jest wyższa, gdy klastry są gęste oraz dobrze rozdzielone od siebie</p></li>
<li><p>metryka jest szybka do kalkulacji</p></li>
</ul>
</section>
<section id="davies-bouldin-index">
<h2>Davies-Bouldin Index<a class="headerlink" href="#davies-bouldin-index" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">davies_bouldin_score</span>
</pre></div>
</div>
</div>
</div>
<p>Kolejnym z analizowanych metryk skuteczności klastrowania jest <em>Davies-Bouldin Index</em>. Metryka mierzy średnie “podobieństwo” między klastrami. Wtedy wartość równa zero jest najniższą osiągana wartością, natomiast 1 najwyższa. Jak nie trudno się domyślić chcemy aby klastry był jak najmniej do siebie podobne stąd interesuje nas jak najniższa wartość tej metryki.</p>
<p><em>Davies-Bouldin Index</em> definiujemy jako średnie podobieństwo między klastrami <span class="math notranslate nohighlight">\(C_{i}\)</span> dla <span class="math notranslate nohighlight">\(i=1, 2, ..., k\)</span> oraz najbardziej podobnym klastrem <span class="math notranslate nohighlight">\(C_{j}\)</span>. Podobieństwo jest definiowane za pomocą wartości <span class="math notranslate nohighlight">\(R_{ij}\)</span> oraz wzoru:</p>
<div class="math notranslate nohighlight">
\[ R_{ij} = \frac{s_{i} + s_{j}}{d_{ij}}\]</div>
<p>gdzie:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(s_{i}\)</span> jest średnią odległością pomiędzy każdą z obserwacji klastra <span class="math notranslate nohighlight">\(i\)</span> oraz centroidu tego klastra</p></li>
<li><p><span class="math notranslate nohighlight">\(d_{ij}\)</span> jest odległością pomiędzy centroidami klastrów <span class="math notranslate nohighlight">\(i\)</span> oraz <span class="math notranslate nohighlight">\(j\)</span></p></li>
</ul>
<p>Wtedy <em>Davies-Bouldin Index</em> ma następującą postać:</p>
<div class="math notranslate nohighlight">
\[ DB = \frac{1}{k} \sum_{i=1}^{k}\max_{i \neq j} R_{ij}\]</div>
<p><strong>Warto zapamiętać</strong></p>
<ul class="simple">
<li><p>kalkulacja tej metryki <em>Davies-Bouldin index</em> jest prostsza niż <em>Silhouette coefficient</em></p></li>
<li><p>podobnie jak poprzednie metody <em>Davies-Bouldin index</em> osiąga lepsze wyniki dla klastrów wypukłych, lepiej odseparowanych od siebie niż dla metod opartych o gęstość jak DBSCAN.</p></li>
</ul>
</section>
<section id="dunn-index">
<h2>Dunn Index<a class="headerlink" href="#dunn-index" title="Permalink to this heading">#</a></h2>
<p>Ostatnia z metryk to indeks Dunna. Ma ona na celu ilościowe określenie zwartości i wariancji skupień. Klaster uważa się za gęsty, jeśli różnice między elementami klastra są niewielkie. Mając klastry <span class="math notranslate nohighlight">\(C_{i}\)</span> dla <span class="math notranslate nohighlight">\(i=1, 2, ..., k\)</span> można to obliczyć za pomocą
$<span class="math notranslate nohighlight">\(\Delta(c_k) = \max_{x_i, x_j \in c_k}{d_e(x_i, x_j)}\)</span>$</p>
<p>gdzie:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(d_e\)</span> jest odległością eukildesową pomiędzy elementami tego samego klastra</p></li>
</ul>
<p>Następnie klaster uważa się za dobrze odseparowany, jeśli zgrupowania są od siebie oddalone. Można to określić przez
$<span class="math notranslate nohighlight">\( \delta(c_k, c_l) = \min_{x_i \in c_k}\min_{x_j\in c_l}{d_e(x_i, x_j)}. \)</span>$</p>
<p>Biorąc pod uwagę nasze wcześniej określone klastry, indeks Dunna <span class="math notranslate nohighlight">\(DI(C)\)</span> można zapisać jako
$<span class="math notranslate nohighlight">\(DI(C)=\frac{\min_{c_k \in C}{\delta(c_k, c_l)}}{\max_{c_k\in C}\Delta(c_k)}\)</span>$</p>
<p>Zatem licznik będzie najmniejszą odleglością między klastrami, a mianownik wskaże klaster najmniej gęsty (najbardziej rozpięty).</p>
<p><strong>Warto zapamiętać</strong></p>
<ul class="simple">
<li><p>wartość metryki jest wyższa, gdy klastry są gęste oraz dobrze rozdzielone od siebie</p></li>
<li><p>metryka ma problem gdy jedno ze skupień zachowuje się źle, podczas gdy inne są dobrze dopasowane, ponieważ w mianowniku znajduje się max zamiast średniej.</p></li>
</ul>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="przyklady-analiza-skutecznosci">
<h1>Przykłady (analiza skuteczności)<a class="headerlink" href="#przyklady-analiza-skutecznosci" title="Permalink to this heading">#</a></h1>
<section id="id8">
<h2>Przykład 1<a class="headerlink" href="#id8" title="Permalink to this heading">#</a></h2>
<p>Poniżej widoczne są 3 rodzaje klastrowania. Wizualizacja 1 jest wynikiem klastrowania KMeans z inicjalizacją random dla trzech klastrów. Dodatkowo w tym przypadku stosujemy tylko jedną iteracje algorytmu aby wynik był niezadawalający. Kolejne wizualizacja jest wynikiem algorytmu KMeans++ z trzema klastrami, zaś ostatnia to wynik KMeans++ z czterama klastrami. Gołym okiem widać, że drugi rodzaj klastrowania jest najlepszy. Jak wyglądają wyniki względem metryki <em>Silhouette coeffcient</em> ? Wartość najwyższa jest osiągana dla drugiego algorytmu - tak jak się spodziewaliśmy. Dużo niższe wyniki są dla algorytmu pierwszego i trzeciego. To pokazuję na siłę tej metryki, która oprócz informacji jaki algorytm wybrać (KMeans z inicjalizacją random czy Kmeans++) to dodatkowo może pomóc nam w wyborze liczby klastrów dla naszych danych (3 a może 4?). Najczęściej w tego typu przypadkach jest wykorzystywana ta metryka.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;KMEANS_RANDOM&#39;</span><span class="p">,</span> <span class="s1">&#39;KMEANS++(3)&#39;</span><span class="p">,</span> <span class="s1">&#39;KMEANS++(4)&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">silh_distances</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">calinski_distances</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">db_distances</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_2</span><span class="o">.</span><span class="n">shape</span>

<span class="c1"># K-means random, ncluster=3</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_random</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;random&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model_random</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_random</span> <span class="o">=</span> <span class="n">model_random</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>
<span class="n">silh_dist</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X_2</span><span class="p">,</span> <span class="n">y_cluster_random</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">silh_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">silh_dist</span><span class="p">)</span>
<span class="n">cali_dist</span> <span class="o">=</span> <span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">X_2</span><span class="p">,</span> <span class="n">y_cluster_random</span><span class="p">)</span>
<span class="n">calinski_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cali_dist</span><span class="p">)</span>
<span class="n">db_dist</span> <span class="o">=</span> <span class="n">davies_bouldin_score</span><span class="p">(</span><span class="n">X_2</span><span class="p">,</span> <span class="n">y_cluster_random</span><span class="p">)</span>
<span class="n">db_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">db_dist</span><span class="p">)</span>

<span class="c1"># K-means++, ncluster=3</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_plusplus</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
<span class="n">model_plusplus</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_plusplus</span> <span class="o">=</span> <span class="n">model_plusplus</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>
<span class="n">silh_dist</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X_2</span><span class="p">,</span> <span class="n">y_cluster_plusplus</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">silh_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">silh_dist</span><span class="p">)</span>
<span class="n">cali_dist</span> <span class="o">=</span> <span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">X_2</span><span class="p">,</span> <span class="n">y_cluster_plusplus</span><span class="p">)</span>
<span class="n">calinski_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cali_dist</span><span class="p">)</span>
<span class="n">db_dist</span> <span class="o">=</span> <span class="n">davies_bouldin_score</span><span class="p">(</span><span class="n">X_2</span><span class="p">,</span> <span class="n">y_cluster_plusplus</span><span class="p">)</span>
<span class="n">db_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">db_dist</span><span class="p">)</span>

<span class="c1"># K-means++, ncluster=4</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_plusplus4</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
<span class="n">model_plusplus4</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_plusplus4</span> <span class="o">=</span> <span class="n">model_plusplus4</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>
<span class="n">silh_dist</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X_2</span><span class="p">,</span> <span class="n">y_cluster_plusplus4</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">silh_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">silh_dist</span><span class="p">)</span>
<span class="n">cali_dist</span> <span class="o">=</span> <span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">X_2</span><span class="p">,</span> <span class="n">y_cluster_plusplus4</span><span class="p">)</span>
<span class="n">calinski_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cali_dist</span><span class="p">)</span>
<span class="n">db_dist</span> <span class="o">=</span> <span class="n">davies_bouldin_score</span><span class="p">(</span><span class="n">X_2</span><span class="p">,</span> <span class="n">y_cluster_plusplus4</span><span class="p">)</span>
<span class="n">db_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">db_dist</span><span class="p">)</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_random</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_plusplus</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_plusplus4</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacja random </span><span class="se">\n</span><span class="s1">(ncluster=3)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacją k-means++ </span><span class="se">\n</span><span class="s1">(ncluster=3)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacją k-means++ </span><span class="se">\n</span><span class="s1">(ncluster=4)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_2 wraz z centroidami&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Czas kalkulacji / Silhouette score / Calinski-Harabasz score / Davies-Boulding index</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span><span class="p">,</span> <span class="n">silh</span><span class="p">,</span> <span class="n">cali</span><span class="p">,</span> <span class="n">db</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">,</span> <span class="n">silh_distances</span><span class="p">,</span> <span class="n">calinski_distances</span><span class="p">,</span> <span class="n">db_distances</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;-----------[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">]-----------&#39;</span><span class="p">)</span> 
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Silhouette coeffcient: </span><span class="si">{</span><span class="n">silh</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Calinski-Harabasz coeffcient: </span><span class="si">{</span><span class="n">cali</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Davies-Bouldin index: </span><span class="si">{</span><span class="n">db</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\knajmajer\.conda\envs\jbook\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=6.
  warnings.warn(
C:\Users\knajmajer\.conda\envs\jbook\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=6.
  warnings.warn(
C:\Users\knajmajer\.conda\envs\jbook\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=6.
  warnings.warn(
</pre></div>
</div>
<img alt="../_images/215797c2ccebf528c11a9b6403f85c82444ab4a511c871cf78af2ba6f245dde5.png" src="../_images/215797c2ccebf528c11a9b6403f85c82444ab4a511c871cf78af2ba6f245dde5.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (1500, 2)


-----------[KMEANS_RANDOM]-----------
Duration: 0:00:00
Silhouette coeffcient: 0.5552189244037514
Calinski-Harabasz coeffcient: 3926.26945406362
Davies-Bouldin index: 0.5415468489574247


-----------[KMEANS++(3)]-----------
Duration: 0:00:00
Silhouette coeffcient: 0.7333423486262539
Calinski-Harabasz coeffcient: 10633.868943793219
Davies-Bouldin index: 0.3645102673195062


-----------[KMEANS++(4)]-----------
Duration: 0:00:00.015613
Silhouette coeffcient: 0.5817871280263665
Calinski-Harabasz coeffcient: 7945.133454263886
Davies-Bouldin index: 0.8169579224359983
</pre></div>
</div>
</div>
</div>
</section>
<section id="id9">
<h2>Przykład 2<a class="headerlink" href="#id9" title="Permalink to this heading">#</a></h2>
<p>Niestety nie zawsze powyższe metryki się sprawdzają. W poniższym przykładzie porównujemy między sobą 3 klastrowania: <em>KMeans++</em>, <em>Spectral Clustering</em> oraz <em>DBSCAN</em>. Każda z tych metod dzieli obserwacje w innym sposób. Wydaję się, że najgorzej robi to metoda <em>KMeans++</em>, natomiast Spectral Clustering oraz <em>DBSCAN</em> działają podobnie, choć <em>DBSCAN</em> wskazuję nam jeszcze pewne anomalie w naszych danych. Jeśli jednak spojrzymy na wyniki tych metryk to okazuję się, że żadna z trzech metryk nie odpowie nam na pytanie, które z tych klastrowań jest poprawne. W tego typu problemach, gdzie klastry nie charakteryzują się rozkładem normalnym metryka każda z tych metryk nie do końca zda egzamin.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;KMEANS++&#39;</span><span class="p">,</span> <span class="s1">&#39;SPECTRAL_RBF&#39;</span><span class="p">,</span> <span class="s1">&#39;DBSCAN&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">silh_distances</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">calinski_distances</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">db_distances</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_1</span><span class="o">.</span><span class="n">shape</span>

<span class="c1"># KMeans++</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
<span class="n">model_kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_plus_plus</span> <span class="o">=</span> <span class="n">model_kmeans</span><span class="o">.</span><span class="n">labels_</span>
<span class="n">silh_dist</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X_1</span><span class="p">,</span> <span class="n">y_cluster_plus_plus</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">silh_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">silh_dist</span><span class="p">)</span>
<span class="n">cali_dist</span> <span class="o">=</span> <span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">X_1</span><span class="p">,</span> <span class="n">y_cluster_plus_plus</span><span class="p">)</span>
<span class="n">calinski_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cali_dist</span><span class="p">)</span>
<span class="n">db_dist</span> <span class="o">=</span> <span class="n">davies_bouldin_score</span><span class="p">(</span><span class="n">X_1</span><span class="p">,</span> <span class="n">y_cluster_plus_plus</span><span class="p">)</span>
<span class="n">db_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">db_dist</span><span class="p">)</span>

<span class="c1"># Spectral Clustering (RBF)</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_sc</span> <span class="o">=</span> <span class="n">SpectralClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">affinity</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">assign_labels</span><span class="o">=</span><span class="s1">&#39;kmeans&#39;</span><span class="p">)</span>
<span class="n">model_sc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_spectral_rbf</span> <span class="o">=</span> <span class="n">model_sc</span><span class="o">.</span><span class="n">labels_</span>
<span class="n">silh_dist</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X_1</span><span class="p">,</span> <span class="n">y_cluster_spectral_rbf</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">silh_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">silh_dist</span><span class="p">)</span>
<span class="n">cali_dist</span> <span class="o">=</span> <span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">X_1</span><span class="p">,</span> <span class="n">y_cluster_spectral_rbf</span><span class="p">)</span>
<span class="n">calinski_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cali_dist</span><span class="p">)</span>
<span class="n">db_dist</span> <span class="o">=</span> <span class="n">davies_bouldin_score</span><span class="p">(</span><span class="n">X_1</span><span class="p">,</span> <span class="n">y_cluster_spectral_rbf</span><span class="p">)</span>
<span class="n">db_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">db_dist</span><span class="p">)</span>

<span class="c1"># Algorytm DBSCAN</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_dbscan</span> <span class="o">=</span> <span class="n">DBSCAN</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">min_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">model_dbscan</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_dbscan</span> <span class="o">=</span> <span class="n">model_dbscan</span><span class="o">.</span><span class="n">labels_</span>
<span class="n">silh_dist</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X_1</span><span class="p">,</span> <span class="n">y_cluster_dbscan</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">silh_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">silh_dist</span><span class="p">)</span>
<span class="n">cali_dist</span> <span class="o">=</span> <span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">X_1</span><span class="p">,</span> <span class="n">y_cluster_dbscan</span><span class="p">)</span>
<span class="n">calinski_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cali_dist</span><span class="p">)</span>
<span class="n">db_dist</span> <span class="o">=</span> <span class="n">davies_bouldin_score</span><span class="p">(</span><span class="n">X_1</span><span class="p">,</span> <span class="n">y_cluster_dbscan</span><span class="p">)</span>
<span class="n">db_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">db_dist</span><span class="p">)</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_plus_plus</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_spectral_rbf</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_dbscan</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans++&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie Spectral Clustering (RBF)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie DBSCAN&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_1 wraz z centroidami&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Czas kalkulacji / Silhouette score / Calinski-Harabasz score / Davies-Boulding index</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span><span class="p">,</span> <span class="n">silh</span><span class="p">,</span> <span class="n">cali</span><span class="p">,</span> <span class="n">db</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">,</span> <span class="n">silh_distances</span><span class="p">,</span> <span class="n">calinski_distances</span><span class="p">,</span> <span class="n">db_distances</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;-----------[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">]-----------&#39;</span><span class="p">)</span> 
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Silhouette coeffcient: </span><span class="si">{</span><span class="n">silh</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Calinski-Harabasz coeffcient: </span><span class="si">{</span><span class="n">cali</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Davies-Bouldin index: </span><span class="si">{</span><span class="n">db</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\knajmajer\.conda\envs\jbook\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\knajmajer\.conda\envs\jbook\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.
  warnings.warn(
</pre></div>
</div>
<img alt="../_images/93b7ac0676a8ef51a96a4237a2e5aab64cd15c6f9507022ecba26c38af285116.png" src="../_images/93b7ac0676a8ef51a96a4237a2e5aab64cd15c6f9507022ecba26c38af285116.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (1000, 2)


-----------[KMEANS++]-----------
Duration: 0:00:00.015648
Silhouette coeffcient: 0.4271848670924971
Calinski-Harabasz coeffcient: 886.9516041548748
Davies-Bouldin index: 0.9325615075331334


-----------[SPECTRAL_RBF]-----------
Duration: 0:00:00.912473
Silhouette coeffcient: 0.42967355323274
Calinski-Harabasz coeffcient: 658.0643390191713
Davies-Bouldin index: 0.9970552748687121


-----------[DBSCAN]-----------
Duration: 0:00:00
Silhouette coeffcient: 0.4157241178607082
Calinski-Harabasz coeffcient: 310.90990033808214
Davies-Bouldin index: 10.006292286691144
</pre></div>
</div>
</div>
</div>
<p>W zależności od problemu do identyfikacji czy nasze klastry są dobrane poprawnie można wykorzystać uczenie maszynowe. W powyższym przykładzie wydaję się zastosowanie regresji liniowej dla zmiennej <span class="math notranslate nohighlight">\(x\)</span> względem zmiennej celu <span class="math notranslate nohighlight">\(y\)</span> pozwoliło by sprawdzić jak podstawowy model wyjaśni nam takie dane. Jeśli model działajacy na klastrach działa lepiej niż dla wszystkich obserwacji to można przypuszczać, że nasze klastrowanie jest dobre. Porównując się do róznych metod klastrowania można wtedy badać błędy MAE, RMSE czy R2.</p>
<div class="alert alert-block alert-success">
<b>Zadanie</b> 
<p>Nawiązując do <strong>Przykład 2</strong> sprawdź skuteczność algorytmu klastrowania stosując regresję liniową dla podziału przy pomocy KMeans++ oraz Spectral Clustering. Dodatkowo zastosują również model regresji liniowej na całym zbiorze danych. Czy model działający na klastrach działa lepiej czy gorzej ?</p>
<p>Podpowiedź: Zastosuj funkcje <code class="docutils literal notranslate"><span class="pre">LinearRegression</span></code> z <code class="docutils literal notranslate"><span class="pre">sklearn.linear_model</span></code></p>
</div></section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./7. Klasteryzacja"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../10.%20Czyszczenie_danych/Czyszczenie%20danych.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Czyszczenie danych</p>
      </div>
    </a>
    <a class="right-next"
       href="../12.%20Klasyfikacja/Klasyfikacja.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Klasyfikacja w Python</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Klasteryzacja w Python</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#wstep">Wstęp</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#biblioteki">Biblioteki</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#przygotowanie-danych">Przygotowanie danych</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#losowe-dane-x-1">Losowe dane: <span class="math notranslate nohighlight">\(X_1\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#losowe-dane-x-2">Losowe dane: <span class="math notranslate nohighlight">\(X_2\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#losowe-dane-x-3">Losowe dane: <span class="math notranslate nohighlight">\(X_3\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#losowe-dane-x-4">Losowe dane: <span class="math notranslate nohighlight">\(X_4\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#losowe-dane-x-5">Losowe dane: <span class="math notranslate nohighlight">\(X_5\)</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#modele-klastrujace">Modele klastrujące</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#k-means">K-Means</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#czym-jest-k-means">Czym jest K-Means ++</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#przyklad-1">Przykład 1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#przyklad-2">Przykład 2</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bibliografia-k-means">Bibliografia [K-Means]</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#minibatch-k-means">MiniBatch K-Means</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#przyklad">Przykład</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bibliografia-minibatch-k-means">Bibliografia [Minibatch K-Means]</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#agglomerative-clustering">Agglomerative Clustering</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Przykład 1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Przykład 2</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bibliografia-agglomerative-clustering">Bibliografia [Agglomerative Clustering]</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spectral-clustering">Spectral Clustering</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Przykład</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bibliografia-spectral-clustering">Bibliografia [Spectral Clustering]</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dbscan">DBSCAN</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Przykład 1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">Przykład 2</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bibliografia-dbscan">Bibliografia [DBSCAN]</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#birch">BIRCH</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">Przykład 1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">Przykład 2</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bibliografia-birch">Bibliografia [BIRCH]</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#analiza-skutecznosci">Analiza skuteczności</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#silhouette-coefficient">Silhouette Coefficient</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calinski-harabasz-index">Caliński-Harabasz Index</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#davies-bouldin-index">Davies-Bouldin Index</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dunn-index">Dunn Index</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#przyklady-analiza-skutecznosci">Przykłady (analiza skuteczności)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">Przykład 1</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">Przykład 2</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By codersi
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>