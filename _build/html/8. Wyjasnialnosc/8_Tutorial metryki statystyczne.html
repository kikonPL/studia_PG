

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Wyjaśnialność modeli - metryki statystyczne - tutorial &#8212; Silky Coders Data Science</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.4cbf315f70debaebd550c87a6162cf0f.min.css" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '8. Wyjasnialnosc/8_Tutorial metryki statystyczne';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Wyjaśnialność modeli - definicje" href="../9.%20XAI/Wyjasnialnosc_modeli_definicje.html" />
    <link rel="prev" title="Regresja oparta o modele drzewiaste" href="../11.%20Regresja/Regresja_trees.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/silky-logo.png" class="logo__image only-light" alt="Silky Coders Data Science - Home"/>
    <img src="../_static/silky-logo.png" class="logo__image only-dark pst-js-only" alt="Silky Coders Data Science - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Laboratorium specjalistyczne: Data Science w branży modowej, 1 semestr studiów magisterskich Matematyki na Wydziale Fizyki Technicznej i Matematyki Stosowanej na Politechnice Gdańskiej
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Wprowadzenie do pakietów numpy i pandas</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../1.%20Tutorial%20pandas/1_Tutorial%20pandas.html">Pakiet pandas - tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2.%20Numpy_tutorial/2_Tutorial%20numpy.html">Pakiet NumPy - tutorial</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Wizualizacja danych</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../3.%20Wizualizacja_danych/3_Wizualizacja%20danych.html">Wizualizacja danych w Python</a></li>







</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Analiza statystyczna</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../4.%20Analiza_statystyczna/4_Analiza%20statystyczna.html">Analiza statystyczna - tutorial</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Wykrywanie anomalii</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../5.%20Wykrywanie_anomalii/Wykrywanie_anomalii_teoria.html">Wykrywanie anomalii - definicje</a></li>
<li class="toctree-l1"><a class="reference internal" href="../5.%20Wykrywanie_anomalii/5_Wykrywanie%20anomalii%20tutorial.html">Wykrywanie anomalii - tutorial</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Inżynieria cech</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../6.%20Inzynieria_cech/6_Inzynieria%20cech.html">Inżynieria cech</a></li>











</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Czyszczenie danych</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../10.%20Czyszczenie_danych/Czyszczenie%20danych.html">Czyszczenie danych</a></li>



</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Klasteryzacja</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../7.%20Klasteryzacja/7_Klasteryzacja.html">Klasteryzacja w Python</a></li>



</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Klasyfikacja</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../12.%20Klasyfikacja/Klasyfikacja.html">Klasyfikacja w Python</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Regresja GLM</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../11.%20Regresja/Regresja_lin.html">Liniowe modele regresji</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Regresja - modele drzewiaste</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../11.%20Regresja/Regresja_trees.html">Regresja oparta o modele drzewiaste</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Wyjaśnialność modeli</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Wyjaśnialność modeli - metryki statystyczne - tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../9.%20XAI/Wyjasnialnosc_modeli_definicje.html">Wyjaśnialność modeli - definicje</a></li>
<li class="toctree-l1"><a class="reference internal" href="../9.%20XAI/9_Wyjasnialnosc%20modeli.html">Wyjaśnialność modeli - XAI - tutorial</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Przetwarzanie języka naturalnego</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../13.%20NLP/TutorialNLP.html">NLP</a></li>





</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/kikonPL/studia_PG/blob/main/8. Wyjasnialnosc/8_Tutorial metryki statystyczne.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/kikonPL/studia_PG" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/kikonPL/studia_PG/issues/new?title=Issue%20on%20page%20%2F8. Wyjasnialnosc/8_Tutorial metryki statystyczne.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/8. Wyjasnialnosc/8_Tutorial metryki statystyczne.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Wyjaśnialność modeli - metryki statystyczne - tutorial</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#wstep">Wstęp</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#omawiane-bledy-dla-danych-typow-predykcji">Omawiane błędy dla danych typów predykcji</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#podejscie-regresyjne">Podejście Regresyjne</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#me">ME</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mae">MAE</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mse">MSE</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rmse">RMSE</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rmsle">RMSLE</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mape">MAPE</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#smape">SMAPE</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#podejscie-klasyfikacyjne">Podejście Klasyfikacyjne</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#accuracy-dokladnosc">Accuracy - dokładność</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#specificity">Specificity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sensitivity-recall">Sensitivity / Recall</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#precision">Precision</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#blad-f-score">Błąd F-Score</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#roc-curve">ROC Curve</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#auc-metric">AUC metric</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#podejscie-grupujace">Podejście Grupujące</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#v-measure">V-measure</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#silhouette-coefficient">Silhouette Coefficient</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dunn-s-index">Dunn’s Index</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="wyjasnialnosc-modeli-metryki-statystyczne-tutorial">
<h1>Wyjaśnialność modeli - metryki statystyczne - tutorial<a class="headerlink" href="#wyjasnialnosc-modeli-metryki-statystyczne-tutorial" title="Permalink to this heading">#</a></h1>
<section id="wstep">
<h2>Wstęp<a class="headerlink" href="#wstep" title="Permalink to this heading">#</a></h2>
<p>O modelach uczenia maszynowego w ogólnym pojęciu możemy mówić jako o czarnych skrzynkach (eng. “black box”).
Wiemy, że podając do wytrenowanego modelu pewne określone wcześniej argumenty otrzymamy pewną predykcję oczekiwanej wartości. Ostatecznie mamy nadzieję, że wyniki podane przez model będą, jak najbliżej wartości, które byśmy zaobserwowali w rzeczywistości przy określonych parametrach (argumenty modelu).</p>
<p>Pojawiają się tutaj dwa miejsca, które są w stanie dostarczyć nam wiedzy na temat jakości naszego modelu. Na jakość modelu składa się zarówno sposób w jaki model dochodzi do tego wyniku, sposób jego działania, jak i wynik predykcji modelu.</p>
<p>Część dotycząca tego w jaki sposób model podejmuje końcową decyzje, skupia się na wyjaśnieniu tego, jak poszczególne argumenty dostarczone do modelu są przez niego interpretowane i jak wpływają na końcowy wynik predykcji. Proces ten nazywamy XAI (“Explainable AI”), czyli wyjaśnialność modelu. O tym w jaki sposób możemy podejść do wyjaśnienia tego co siedzi wewnątrz modelu dowiemy się w kolejnym module.</p>
<p>W tym module skupimy się na tej drugiej części, która pozwoli poznać jakość naszego modelu, a mianowicie na interpretacji wyników predykcji. Projektując modele uczenia maszynowego dążymy, aby model odznaczał się jak najlepszym odwzorowaniem wartości rzeczywistych za pomocą predykcji przy zadanych parametrach. W tym celu wyliczamy pewne miary, nazywane metrykami, które pozwalają ocenić grupowo wyniki predykcji względem wartości rzeczywistych. <br>
Nie wszystkie problemy biznesowe, na których potrzeby chcemy odpowiedzieć, będziemy w stanie dobrze ocenić tymi samymi metrykami. Oraz nie każda z metryk będzie potrafiła odpowiedzieć nam na wszystkie wątpliwości na temat jakości naszej predykcji. Stąd bardzo ważnym krokiem jest odpowiedni dobór metryki dopasowanej pod problem biznesowy, który staramy się rozwiązać. Na podstawie wyników z tej metryki, bądź kilku metryk, będziemy podejmować dalsze decyzje o rozwoju modelu. Tak, więc wybór nieodpowiedniej metryki może spowodować wyciągnięcie błędnych wniosków oraz błędne określenie dalszych kroków prac nad modelem.</p>
</section>
<section id="omawiane-bledy-dla-danych-typow-predykcji">
<h2>Omawiane błędy dla danych typów predykcji<a class="headerlink" href="#omawiane-bledy-dla-danych-typow-predykcji" title="Permalink to this heading">#</a></h2>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Modele Regresyjne</p></th>
<th class="head"><p>Modele Klasyfikacyjne</p></th>
<th class="head"><p>Modele Grupujące</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ME</p></td>
<td><p>Macierz pomyłek</p></td>
<td><p>V-measure</p></td>
</tr>
<tr class="row-odd"><td><p>MAE</p></td>
<td><p>Accuracy</p></td>
<td><p>Silhouette Coefficient</p></td>
</tr>
<tr class="row-even"><td><p>MSE</p></td>
<td><p>Precision</p></td>
<td><p>Davies-Bouldin Index</p></td>
</tr>
<tr class="row-odd"><td><p>RMSE</p></td>
<td><p>F-score</p></td>
<td><p>Dunn’s Index</p></td>
</tr>
<tr class="row-even"><td><p>MSLE</p></td>
<td><p>ROC</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>MAPE</p></td>
<td><p>AUC</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>SMAPE</p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
<p>Zaprezentowane metryki zostały pokrótce omówione w części wykładowej. <br>
W tym tutorialu skupimy się głównie na wyliczaniu metryk dla podanych przykładów oraz na interpretacji ich wartości.</p>
<p>Większość metryk została zaimplementowana i jest dostępna poprzez bibliotekę scikit-learn. <br>
Jeśli chcemy znaleźć metrykę dla naszego modelu, a żadna z nam znanych nie spełnia założonych kryteriów warto tutaj zajrzeć:
<a class="reference external" href="https://scikit-learn.org/stable/modules/model_evaluation.html">https://scikit-learn.org/stable/modules/model_evaluation.html</a></p>
</section>
<section id="podejscie-regresyjne">
<h2>Podejście Regresyjne<a class="headerlink" href="#podejscie-regresyjne" title="Permalink to this heading">#</a></h2>
<p>Podstawowym podejściem na którym wyliczamy większość z błędów w regresji jest różnica pomiędzy wartością oczekiwaną, a predykcją otrzymaną z modelu. Różnicę tą nazywamy błędem predykcji - z ang. <strong>Error</strong></p>
<div class="math notranslate nohighlight">
\[Error= y_i - \hat{y_i}\]</div>
<div class="alert alert-block alert-success">
<p>Jako <span class="math notranslate nohighlight">\(y_i\)</span> będziemy oznaczać pojedyńczą rzeczywistą obserwacje ze zbioru <span class="math notranslate nohighlight">\(N\)</span> elementów, natomiast <span class="math notranslate nohighlight">\(\hat{y_i}\)</span> będzie reprezentować predykcje odpowiadającą tej obserwacji. Wartość <span class="math notranslate nohighlight">\(\overline{y}\)</span> oznaczać będzie natomiast średnią ze wszystkich obserwacji.</p>
</div>
<section id="me">
<h3>ME<a class="headerlink" href="#me" title="Permalink to this heading">#</a></h3>
<p>W celu obliczenia średniego błędu na całym zadanym zbiorze używamy najbardziej podstawowej metryki, czyli średniego błędu - z ang. <strong>Mean Error</strong></p>
<div class="math notranslate nohighlight">
\[ME=\frac{1}{N} \sum^N_{i=1}(y_i-\hat{y_i})\]</div>
<p>Interpretujemy ją jako średnią odległość pomiędzy wartościami rzeczywistymi, a predykcjami naszego modelu. <br>
Metryka ta posiada jedną dość istotną wadę. Dla błędów o takiej samej sile, lecz przeciwnym kierunku następuje redukcja wpływu tych błędów na końcową wartość metryki, co ukrywa niedoskonałości modelu.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">mean_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; </span>
<span class="sd">    Funkcja pozwalająca na wyliczenie wartości Mean Error</span>
<span class="sd">    </span>
<span class="sd">    :param y: wektor wartości rzeczywistych</span>
<span class="sd">    :param y_hat: wektor wartości przewidywanych</span>
<span class="sd">    </span>
<span class="sd">    :return: średni błąd na obserwacjach</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># y oraz y_hat są reprezentowane poprzez wektory</span>
    <span class="c1"># jeśli wykonamy obliczenie różnicy między nimi to powstanie rónież wektor</span>
    <span class="c1"># wyliczenie średniej z biblioteki numpy spowoduje wyliczenie średniej z wartości takiego wektora</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">y_hat</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span> <span class="c1"># argumenty</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span> <span class="c1"># wartości</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="s1">&#39;o&#39;</span><span class="p">)</span> <span class="c1"># wizualizacja wartości rzeczywistych</span>
<span class="n">m</span><span class="p">,</span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># regresja liniowa (model)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">m</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="n">b</span><span class="p">)</span> <span class="c1"># wizualizacja predykcji modelu (żółta)</span>
<span class="n">y_hat_linear</span> <span class="o">=</span> <span class="n">m</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="n">b</span> <span class="c1"># predykcje modelu liniowego</span>

<span class="n">a1</span><span class="p">,</span><span class="n">a2</span><span class="p">,</span><span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># regresja wielomianem drugiego stopnia (model)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a1</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">a2</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">c</span><span class="p">)</span> <span class="c1"># wizualizacja predykcji (zielona linia)</span>
<span class="n">y_hat_poly</span> <span class="o">=</span> <span class="n">a1</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">a2</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">c</span> <span class="c1"># predykcje modelu wielomianowego</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;liniowa&#39;</span><span class="p">,</span> <span class="s1">&#39;wielomianowa&#39;</span><span class="p">])</span> <span class="c1"># dodanie legendy</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span> <span class="c1"># wizualizacja</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Mean Error dla regresji liniowej: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mean_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_hat_linear</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Mean Error dla regresji wielomianowej: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mean_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_hat_poly</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/21ce9a24a2b971be434355eba4ca1544185bb3db92eb489f736762a6b4d44661.png" src="../_images/21ce9a24a2b971be434355eba4ca1544185bb3db92eb489f736762a6b4d44661.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Błąd Mean Error dla regresji liniowej: 0.0
Błąd Mean Error dla regresji wielomianowej: -0.0
</pre></div>
</div>
</div>
</div>
<p>Jak możemy zaobserwować, zarówno dla regresji liniowej, jak i wielomianowej średni błąd dla modelu wyniósł zero. <br>
Bazując tylko na tej metryce moglibyśmy powiedzieć, że oba z modeli osiągają jednakowy wynik. Dopiero wizualizacja pozwala nam zaobserwować, że tak naprawdę regresja liniowa jest mocnym przybliżeniem tego co byśmy oczekiwali.</p>
</section>
<section id="mae">
<h3>MAE<a class="headerlink" href="#mae" title="Permalink to this heading">#</a></h3>
<p>W celu uniknięcia złych interpretacji częściej używa się metryki średniego błędu bezwzględnego - z ang. <strong>Mean Absolute Error</strong></p>
<p><span class="math notranslate nohighlight">\(MAE=\frac{1}{N} \sum^N_{i=1} | y_i-\hat{y_i} |\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mean_absolute_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; </span>
<span class="sd">    Funkcja pozwalająca na wyliczenie wartości Mean Absolute Error</span>
<span class="sd">    </span>
<span class="sd">    :param y: wektor wartości rzeczywistych</span>
<span class="sd">    :param y_hat: wektor wartości przewidywanych</span>
<span class="sd">    </span>
<span class="sd">    :return: średni błąd bezwzględny na obserwacjach</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">y_hat</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Mean Absolute Error dla regresji liniowej: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_hat_linear</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Mean Absolute Error dla regresji wielomianowej: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_hat_poly</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Błąd Mean Absolute Error dla regresji liniowej: 2.0
Błąd Mean Absolute Error dla regresji wielomianowej: 0.0
</pre></div>
</div>
</div>
</div>
<p>Po zastoswaniu błędu MAE widzimy, że model używający regresji liniowej dla naszego przypadku myli się średnio o 2 jednostki względem wartości rzeczywistych. Jest to poprawne wyjaśnienie jakości dla zaprezentowanego, prostego przypadku.</p>
<p>Zestawiając obok siebie błąd MAE oraz ME pozwala zyskać natomiast dodatkową informacje. <br>
O ile błąd MAE trafniej pozwoli określić nam o ile się średnio mylimy podczas predykcji to zestawiając wraz z błędem ME możemy otrzymać informację w którą stronę częściej się mylimy. Czy nasze predykcje względem wartości rzeczywistych są częściej zawyżane, czy zaniżane.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">])</span> <span class="c1"># argumenty</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span> <span class="c1"># wartości</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="s1">&#39;o&#39;</span><span class="p">)</span> <span class="c1"># wizualizacja wartości rzeczywistych</span>
<span class="n">m</span><span class="p">,</span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># regresja liniowa (model)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">m</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="n">b</span><span class="p">)</span> <span class="c1"># wizualizacja predykcji modelu (żółta)</span>
<span class="n">y_hat_linear</span> <span class="o">=</span> <span class="n">m</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="n">b</span> <span class="c1"># predykcje modelu liniowego</span>

<span class="n">b2</span> <span class="o">=</span> <span class="n">b</span><span class="o">+</span><span class="mi">2</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">m</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="n">b2</span><span class="p">)</span> <span class="c1"># wizualizacja predykcji modelu (zielona)</span>
<span class="n">y_hat_linear_up</span> <span class="o">=</span> <span class="n">m</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="n">b2</span> <span class="c1"># predykcje modelu liniowego zawyżonego</span>

<span class="n">b3</span> <span class="o">=</span> <span class="n">b</span><span class="o">-</span><span class="mi">1</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">m</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="n">b3</span><span class="p">)</span> <span class="c1"># wizualizacja predykcji modelu (czerwona)</span>
<span class="n">y_hat_linear_down</span> <span class="o">=</span> <span class="n">m</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="n">b3</span> <span class="c1"># predykcje modelu liniowego zaniżonego</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;liniowa&#39;</span><span class="p">,</span> <span class="s1">&#39;liniowa_up&#39;</span><span class="p">,</span> <span class="s1">&#39;liniowa_down&#39;</span><span class="p">])</span> <span class="c1"># dodanie legendy</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span> <span class="c1"># wizualizacja</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Mean Error dla regresji liniowej: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mean_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_hat_linear</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Mean Error dla regresji liniowej zawyżonej: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mean_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_hat_linear_up</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Mean Error dla regresji liniowej zaniżonej: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mean_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_hat_linear_down</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Mean Absolute Error dla regresji liniowej: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_hat_linear</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Mean Absolute Error dla regresji liniowej zawyżonej: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_hat_linear_up</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Mean Absolute Error dla regresji liniowej zaniżonej: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_hat_linear_down</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/a558f424a41b14e2ee1c41473dba927237d8ad3089051668365defadeb9012c2.png" src="../_images/a558f424a41b14e2ee1c41473dba927237d8ad3089051668365defadeb9012c2.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Błąd Mean Error dla regresji liniowej: 0.0
Błąd Mean Error dla regresji liniowej zawyżonej: -2.0
Błąd Mean Error dla regresji liniowej zaniżonej: 1.0 

Błąd Mean Absolute Error dla regresji liniowej: 0.6
Błąd Mean Absolute Error dla regresji liniowej zawyżonej: 2.0
Błąd Mean Absolute Error dla regresji liniowej zaniżonej: 1.0
</pre></div>
</div>
</div>
</div>
<p>Interpretując powyższe wyniki jesteśmy w stanie zauważyć, że model liniowy zawyżony faktycznie zawyża wyniki na co wskazuje znak ‘-’ przy metryce ME. Oznacza to, że średnio większość obserwacji rzeczywistych była niższa, niż wartość predykcji z modelu.<br>
Odwrotnie natomiast jest w przypadku modelu zaniżonego, gdzie widzimy, że błąd ME osiągnął wartość dodatnią.</p>
<br>
<br>
<br>
</section>
<section id="mse">
<h3>MSE<a class="headerlink" href="#mse" title="Permalink to this heading">#</a></h3>
<p>Kolejną ważną metryką jest metryka związana z kwadratem błędu, czyli średni kwadrat błędu - z ang. <strong>Mean Square Error</strong></p>
<p>Reprezentuje ta wartość wariancję wśród odległości pomiędzy wartościami rzeczywistymi, a predykcją.</p>
<p><span class="math notranslate nohighlight">\(MSE=\frac{1}{N} \sum^N_{i=1}(y_i-\hat{y_i})^2\)</span></p>
<p>Dużym minusem tej metryki jest interpretowalność. Ze względu na to, że obliczana jest ona na podstawie kwadratu odległości pomiędzy wartościami, jednostka w jakiej jest reprezentowana jest również kwadratem jednostki, w której reprezentujemy predykcję.
<br>
Plusem, który stoi za popularnością tej metryki jest jej różniczkowalność, co pozwala na wykonywanie na tej metryce różnych operacji matematycznych w przeciwieństwie do MAE, które jest nieróżniczkowalne. Konsekwencją tego jest użycie wartości MSE w wyliczaniu innych metryk, jak na przykład RMSE.
<br>
Dodatkową charakterystyczną rzeczą dla metryki MSE jest jej wrażliwość na wartości odstające. Może to być traktowane jako wada, jak i zaleta. Z jednej strony posiadając bardzo dobrze dopasowany model z pojedyńczym, lecz wysokim odchyleniem od wartości rzeczywistej uzyskujemy podobny błąd co do modelu, który jest dość przeciętny, jednak wartości predykcji znajdują się w węższym zakresie wartości.
<br>
Jednakże, chcąc stworzyć dobry model oczekujemy od niego, że będzie on w miarę stabilny i mniej wrażliwy na odchylenia wśród wartości. Z uwagi na to metryka ta jest dobrą metryką do monitorowania naszego modelu pod kątem stabilności predykcji.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mean_square_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; </span>
<span class="sd">    Funkcja pozwalająca na wyliczenie wartości Mean Square Error</span>
<span class="sd">    </span>
<span class="sd">    :param y: wektor wartości rzeczywistych</span>
<span class="sd">    :param y_hat: wektor wartości przewidywanych</span>
<span class="sd">    </span>
<span class="sd">    :return: średni kwadrat błędu na obserwacjach</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">y_hat</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">])</span> <span class="c1"># argumenty</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># wartości</span>
<span class="n">y_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">y_3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="s1">&#39;o&#39;</span><span class="p">)</span> <span class="c1"># wizualizacja wartości rzeczywistych</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y_2</span><span class="p">)</span> <span class="c1"># wizualizacja wartości rzeczywistych</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y_3</span><span class="p">)</span> <span class="c1"># wizualizacja wartości rzeczywistych</span>


<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;model_1&#39;</span><span class="p">,</span> <span class="s1">&#39;model_2&#39;</span><span class="p">])</span> <span class="c1"># dodanie legendy</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span> <span class="c1"># wizualizacja</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Mean Absolute Error dla model_1: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_2</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Mean Absolute Error dla model_2: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_3</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Mean Square Error dla model_1: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mean_square_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_2</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Mean Square Error dla model_2: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mean_square_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_3</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/772abc3bf3f5ba73a96f48d6b57bdd833936b65538211d45c62ac0df8f241010.png" src="../_images/772abc3bf3f5ba73a96f48d6b57bdd833936b65538211d45c62ac0df8f241010.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Błąd Mean Absolute Error dla model_1: 0.2
Błąd Mean Absolute Error dla model_2: 0.2

Błąd Mean Square Error dla model_1: 0.1
Błąd Mean Square Error dla model_2: 0.2
</pre></div>
</div>
</div>
</div>
<p>W powyższym przykładzie możemy zobserwować, że dla modelu drugiego, który bardzo wrażliwie zareagował na zmianę, metryka MSE pokazała wyższy błąd, niż dla modelu pierwszego. Mimo, że błędy MAE dla obu modeli są jednakowe, po dodaniu błędu MSE zyskaliśmy świadomość, który z tych dwóch modeli będzie bardziej zachowawczy w przyszłych predykcjach.
<br>
<br>
<br></p>
</section>
<section id="rmse">
<h3>RMSE<a class="headerlink" href="#rmse" title="Permalink to this heading">#</a></h3>
<p>Pewną korektą dla błędu MSE jest błąd RMSE, który posiada ułatwioną interpretację ze względu na taką samą jednostkę, jak dla wartości, które predykujemy. Błąd RMSE jest to pierwiastek kwadratowy z błędu MSE - z ang. <strong>Root Mean Square Error</strong></p>
<p><span class="math notranslate nohighlight">\(RMSE=\sqrt{\frac{1}{N} \sum^N_{i=1}(y_i-\hat{y_i})^2}\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">root_mean_square_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; </span>
<span class="sd">    Funkcja pozwalająca na wyliczenie wartości Root Mean Square Error</span>
<span class="sd">    </span>
<span class="sd">    :param y: wektor wartości rzeczywistych</span>
<span class="sd">    :param y_hat: wektor wartości przewidywanych</span>
<span class="sd">    </span>
<span class="sd">    :return: pierwiastek średniego kwadratu błędu na obserwacjach</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">y_hat</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">])</span> <span class="c1"># argumenty</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># wartości</span>
<span class="n">y_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">y_3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="s1">&#39;o&#39;</span><span class="p">)</span> <span class="c1"># wizualizacja wartości rzeczywistych</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y_2</span><span class="p">)</span> <span class="c1"># wizualizacja wartości rzeczywistych</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y_3</span><span class="p">)</span> <span class="c1"># wizualizacja wartości rzeczywistych</span>


<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;model_1&#39;</span><span class="p">,</span> <span class="s1">&#39;model_2&#39;</span><span class="p">])</span> <span class="c1"># dodanie legendy</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span> <span class="c1"># wizualizacja</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Mean Absolute Error dla model_1: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_2</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Mean Absolute Error dla model_2: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_3</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Mean Square Error dla model_1: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mean_square_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_2</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Mean Square Error dla model_2: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mean_square_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_3</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Root Mean Square Error dla model_1: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">root_mean_square_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_2</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Root Mean Square Error dla model_2: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">root_mean_square_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_3</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/772abc3bf3f5ba73a96f48d6b57bdd833936b65538211d45c62ac0df8f241010.png" src="../_images/772abc3bf3f5ba73a96f48d6b57bdd833936b65538211d45c62ac0df8f241010.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Błąd Mean Absolute Error dla model_1: 0.2
Błąd Mean Absolute Error dla model_2: 0.2

Błąd Mean Square Error dla model_1: 0.1
Błąd Mean Square Error dla model_2: 0.2

Błąd Root Mean Square Error dla model_1: 0.3
Błąd Root Mean Square Error dla model_2: 0.4
</pre></div>
</div>
</div>
</div>
</section>
<section id="rmsle">
<h3>RMSLE<a class="headerlink" href="#rmsle" title="Permalink to this heading">#</a></h3>
<p>W przypadku biznesu, jak na przykład LPP, znaczące jest to w którą stronę się myli. To znaczy, czy nasze błędy są przeszacowane, bądź niedoszacowane. Stosując miary oparte o kwadrat odległosci pomiędzy wartościami rzeczywistymi, a przewidywanymi gubimy tą informacje. W takim celu możemy użyć metryki, która jest odpowiednikiem dla RMSE (oraz MSE), a mianowicie RMSLE (MSLE) - z ang. <strong>Root Mean Square Logarithmic Error</strong></p>
<p><span class="math notranslate nohighlight">\(RMSLE=\sqrt{\frac{1}{N} \sum^N_{i=1}(log_e(1+y_i)-log_e(1+\hat{y_i}))^2}\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">root_mean_square_logarithmic_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; </span>
<span class="sd">    Funkcja pozwalająca na wyliczenie wartości Root Mean Square Logarithmic Error</span>
<span class="sd">    </span>
<span class="sd">    :param y: wektor wartości rzeczywistych</span>
<span class="sd">    :param y_hat: wektor wartości przewidywanych</span>
<span class="sd">    </span>
<span class="sd">    :return: pierwiastek średniego kwadratu błędu zlogarytmowawanego na obserwacjach</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">y</span><span class="p">)</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">y_hat</span><span class="p">),</span><span class="mi">2</span><span class="p">)))</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">])</span> <span class="c1"># argumenty</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span> <span class="c1"># wartości</span>
<span class="n">y_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">y_3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="s1">&#39;o&#39;</span><span class="p">)</span> <span class="c1"># wizualizacja wartości rzeczywistych</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y_2</span><span class="p">)</span> <span class="c1"># wizualizacja wartości rzeczywistych</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y_3</span><span class="p">)</span> <span class="c1"># wizualizacja wartości rzeczywistych</span>


<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;model_1&#39;</span><span class="p">,</span> <span class="s1">&#39;model_2&#39;</span><span class="p">])</span> <span class="c1"># dodanie legendy</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span> <span class="c1"># wizualizacja</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Mean Absolute Error dla model_1: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_2</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Mean Absolute Error dla model_2: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_3</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Root Mean Square Error dla model_1: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">root_mean_square_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_2</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Root Mean Square Error dla model_2: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">root_mean_square_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_3</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Root Mean Square Logarithmic Error dla model_1: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">root_mean_square_logarithmic_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_2</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Root Mean Square Logarithmic Error dla model_2: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">root_mean_square_logarithmic_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_3</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/4175c66e3b75734c4bcd0295779fb9d444398ab3efcd19e8a8481e4b775f90d4.png" src="../_images/4175c66e3b75734c4bcd0295779fb9d444398ab3efcd19e8a8481e4b775f90d4.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Błąd Mean Absolute Error dla model_1: 0.5
Błąd Mean Absolute Error dla model_2: 0.5

Błąd Root Mean Square Error dla model_1: 0.7
Błąd Root Mean Square Error dla model_2: 0.7

Błąd Root Mean Square Logarithmic Error dla model_1: 0.2
Błąd Root Mean Square Logarithmic Error dla model_2: 0.3
</pre></div>
</div>
</div>
</div>
<p>Tak, jak możemy zauważyć na powyższych wynikach, pomimo identycznych błędów MAE oraz RMSE, metryka RMSLE pozwala nam określić, który model byłby lepszy przy naszych założeniach biznsowych. W przypadku zamówień towaru, stworzenie modelu, który częściej będzie niedoszacowywał wartości sprzedażowe spowoduje utracenie sprzedaży w sklepach czego efektem będzie strata sporych sum pieniężnych.</p>
<br>
<br>
<br>
</section>
<section id="mape">
<h3>MAPE<a class="headerlink" href="#mape" title="Permalink to this heading">#</a></h3>
<p>Szczególnym rodzajem metryk są metryki oparte o błędy procentowe. Ich główną zaletą jest fakt, że moga być porównywane pomiędzy modelami niezależnie od jednostki, bądź skali w jakiej predykcja została wykonana ze względu na zastosowanie błędu procentowego. Podstawową metryką jest średni bezwględny błąd procentowy - z ang. <strong>Mean Absolute Percentage Error</strong></p>
<p><span class="math notranslate nohighlight">\(MAPE=\frac{1}{n} \sum^N_{i=1}\frac{|y_i-\hat{y_i}|}{max( \epsilon , |y_i|)}\)</span></p>
<p>Wartość <span class="math notranslate nohighlight">\(\epsilon\)</span> w mianowniku jest to bardzo niewielka wartość bliska zeru, która pozwala bezpiecznie wyliczyć metryke w momencie, gdy wartość rzeczywista otrzymuje wartość 0.
<br></p>
<p>Ze względu na wyrażenie metryki w ujęciu procentowym metryka ta jest łatwo prównywalna i łatwo zrozumiała.<br></p>
<p>Jednakże posiada również swoje minus. Kwestia skali i asymetryczności. Dla wartości rzeczywistych bardzo bliskich zeru otrzymujemy wartości ekstremalnie wysokie. Druga kwestia, dużo większą karę nakłada się na przeszacowanie, niż niedoszacowanie. Wynika to z faktu, że dla wartości zbyt niskich nie może wartość błędu przekroczyć 100%. Jednak nie posiada ona granicy dla górnej prognozy. Przez co MAPE faworyzuje modele, które niedoszacowują nad te które przeszacowują.
<br>
<br>
<br></p>
</section>
<section id="smape">
<h3>SMAPE<a class="headerlink" href="#smape" title="Permalink to this heading">#</a></h3>
<p>W celu poprawy problemu z asymetrią została zaproponowana symetryczna wersja błędu MAPE, czyli SMAPE - z ang. <strong>Symetric Mean Absolute Percentage Error</strong></p>
<p><span class="math notranslate nohighlight">\(SMAPE=\frac{1}{n} \sum^N_{i=1}\frac{|y_i-\hat{y_i}|}{max( \epsilon , \frac{|y_i|+|\hat{y_i}|}{2})}\)</span></p>
<p>Z zalet więc jest również to metryka wyrażona w wartości procentowej i dodatkowo naprawia wadę asymetryczności wprowadzając dolna granicę 0% i górną 200%. <br></p>
<p>Ta metryka też ma swoje wady, <a class="reference external" href="http://m.in">m.in</a>.: otrzymujemy wartości nieokreślone gdy zarówno wartość rzeczywista i przewidywana są równe 0. Gdy wartość rzeczywista lub prognoza osiągnię wartość 0, to SMAPE automatycznie zwraca górną granicę (to nie koniecznie musi być traktowane jako wada).<br></p>
<p>Jednakże jest jeszcze jedna ważna różnica, która może okazać się kluczowa w różnych problemach biznesowych. Tak, jak przy wspomnianej wcześniej metryce MSLE kluczowe dla nas jest, aby uniknąć niedoszacowań przy predykcji. Gdy MAPE faworyzowało modele, które niedoszacowują to SMAPE ma efekt odwrotny.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>

<span class="k">def</span> <span class="nf">mean_absolute_percentage_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; </span>
<span class="sd">    Funkcja pozwalająca na wyliczenie wartości Mean Absolute Percentage Error</span>
<span class="sd">    </span>
<span class="sd">    :param y: wektor wartości rzeczywistych</span>
<span class="sd">    :param y_hat: wektor wartości przewidywanych</span>
<span class="sd">    </span>
<span class="sd">    :return: średni bezwględny błąd procentowy na obserwacjach</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">y_hat</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">max</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">float_info</span><span class="o">.</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">y</span><span class="p">]))</span>


<span class="k">def</span> <span class="nf">symetric_mean_absolute_percentage_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; </span>
<span class="sd">    Funkcja pozwalająca na wyliczenie wartości Symetric Mean Absolute Percentage Error</span>
<span class="sd">    </span>
<span class="sd">    :param y: wektor wartości rzeczywistych</span>
<span class="sd">    :param y_hat: wektor wartości przewidywanych</span>
<span class="sd">    </span>
<span class="sd">    :return: symetryczny średni bezwględny błąd procentowy na obserwacjach</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">y_hat</span><span class="p">)</span> <span class="o">/</span> <span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y_hat</span><span class="p">))</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span>


<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">])</span> <span class="c1"># argumenty</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span> <span class="c1"># wartości</span>
<span class="n">y_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">y_3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="s1">&#39;o&#39;</span><span class="p">)</span> <span class="c1"># wizualizacja wartości rzeczywistych</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y_2</span><span class="p">)</span> <span class="c1"># wizualizacja wartości rzeczywistych</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y_3</span><span class="p">)</span> <span class="c1"># wizualizacja wartości rzeczywistych</span>


<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;model_1&#39;</span><span class="p">,</span> <span class="s1">&#39;model_2&#39;</span><span class="p">])</span> <span class="c1"># dodanie legendy</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span> <span class="c1"># wizualizacja</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Mean Absolute Error dla model_1: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_2</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Mean Absolute Error dla model_2: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_3</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Mean Absolute Percentage Error dla model_1: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mean_absolute_percentage_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_2</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Mean Absolute Percentage Error dla model_2: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mean_absolute_percentage_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_3</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Symetric Mean Absolute Percentage Error dla model_1: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">symetric_mean_absolute_percentage_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_2</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Błąd Symetric Mean Absolute Percentage Error dla model_2: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">symetric_mean_absolute_percentage_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">y_3</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/4175c66e3b75734c4bcd0295779fb9d444398ab3efcd19e8a8481e4b775f90d4.png" src="../_images/4175c66e3b75734c4bcd0295779fb9d444398ab3efcd19e8a8481e4b775f90d4.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Błąd Mean Absolute Error dla model_1: 0.5
Błąd Mean Absolute Error dla model_2: 0.5

Błąd Mean Absolute Percentage Error dla model_1: 0.2
Błąd Mean Absolute Percentage Error dla model_2: 0.2

Błąd Symetric Mean Absolute Percentage Error dla model_1: 0.2
Błąd Symetric Mean Absolute Percentage Error dla model_2: 0.3
</pre></div>
</div>
</div>
</div>
<p>Ponownie możemy zaobserwować, że metryka SMAPE zwróciła różne od siebie wartości dla zaprezentowanego przypadku bardziej karając model, który niedoszacował wartości predykcji względem wartości rzeczywistych.</p>
</section>
</section>
<section id="podejscie-klasyfikacyjne">
<h2>Podejście Klasyfikacyjne<a class="headerlink" href="#podejscie-klasyfikacyjne" title="Permalink to this heading">#</a></h2>
<p>W przypadku klasyfikacji trochę innaczej podchodzimy do oceny jakości modelu. Rodzaj wartości na jakich tutaj operujemy nie są to wartości ciągłe, a znane wcześniej, z góry określone klasy. Na przykład klasyfikując górne części garderoby będzie to zbiór: {‘koszulka’, ‘bluza’, ‘sweter’, ‘koszula’, ‘kurtka’}.
<br></p>
<p>W takim przypadku byłoby ciężko wyliczyczać odległość od wartości prawdziwej i na tej podstawie wyznaczać metryki, ponieważ odległość pomiędzy klasami staje sie tutaj pojęciem abstrakcyjnym, które nie jest naturalnie zdefiniowane.
<br></p>
<p>Z tego powodu, przy klasyfikacji posługujemy się macierzą pomyłek. Macierz ta mówi nam do której klasy została zaklasyfikowana dana obserwacja. Jeśli będzie to błędna predykcja to jesteśmy w stanie wyciągnąć pewne wnioski obserwując z którą inną klasą została zazwyczaj mylona poprawna klasa.
<br></p>
<p><strong>Macierz pomyłek</strong>
<br></p>
<!-- <img src="media/confusion_matrix.png" alt="DT" style="width: 800px;">
 -->
<p><img alt="media" src="../_images/confusion_matrix.png" /></p>
<p>Macierz pomyłek może reprezentować zarówno problem ze zbiorem klas binarnym, bądź wieloklasowy.
<br></p>
<p>W pierwszym przypadku klasyfikator ma za zadanie określić, czy dane zwierzę to kot. Klasy które naturalnie wynikają z tego problemu to ‘Kot’ i ‘nie-Kot’. W związku z dodatkową wiedzą o zbiorze możemy stwierdzić, że jeśli to nie jest ‘Kot’ to to będzie ‘Pies’ i dla podanych poniżej wartości macierze pomyłek prezentuje się w następujący sposób.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Predykcja</p></td>
<td><p>Kot</p></td>
<td><p>Pies</p></td>
<td><p>Kot</p></td>
<td><p>Pies</p></td>
<td><p>Pies</p></td>
<td><p>Pies</p></td>
<td><p>Kot</p></td>
<td><p>Kot</p></td>
<td><p>Pies</p></td>
<td><p>Pies</p></td>
</tr>
<tr class="row-odd"><td><p>Rzeczywista klasa</p></td>
<td><p>Kot</p></td>
<td><p>Kot</p></td>
<td><p>Kot</p></td>
<td><p>Pies</p></td>
<td><p>Kot</p></td>
<td><p>Pies</p></td>
<td><p>Pies</p></td>
<td><p>Kot</p></td>
<td><p>Pies</p></td>
<td><p>Kot</p></td>
</tr>
</tbody>
</table>
</div>
<br>
<!-- <img src="media/conf_matrix_binary.png" alt="DT" style="width: 800px;">
 -->
![media](media/conf_matrix_binary.png)
<p>Drugi przypadek reprezentować będzie klasyfikacje wieloklasową. Taka macierz jest bardziej rozbudowana on macierzy binarnej, jednakże jest dokładnie w taki sam sposób interpretowana.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Predykcja</p></td>
<td><p>1</p></td>
<td><p>2</p></td>
<td><p>3</p></td>
<td><p>4</p></td>
<td><p>1</p></td>
<td><p>2</p></td>
<td><p>3</p></td>
<td><p>4</p></td>
<td><p>1</p></td>
<td><p>2</p></td>
<td><p>4</p></td>
</tr>
<tr class="row-odd"><td><p>Rzeczywista klasa</p></td>
<td><p>1</p></td>
<td><p>4</p></td>
<td><p>2</p></td>
<td><p>3</p></td>
<td><p>2</p></td>
<td><p>3</p></td>
<td><p>4</p></td>
<td><p>1</p></td>
<td><p>2</p></td>
<td><p>3</p></td>
<td><p>4</p></td>
</tr>
</tbody>
</table>
</div>
<br>
<!-- <img src="media/conf_matrix_multi.png" alt="DT" style="width: 800px;">
 -->
<p><img alt="media" src="../_images/conf_matrix_multi.png" /></p>
<br>
<br>
<section id="accuracy-dokladnosc">
<h3>Accuracy - dokładność<a class="headerlink" href="#accuracy-dokladnosc" title="Permalink to this heading">#</a></h3>
<p>Pierwszą podstawową miarą skuteczności w podejściu klasyfkacyjnym jest dokładność. Miara ta jest wyrażon jako stosunek wszystkkich poprawnie zaklasyfikowanych wartości do wszystkich obserwacj, które podległy klasyfikacji.</p>
<p><span class="math notranslate nohighlight">\(Accuracy=\frac{TP+TN}{TP+FP+TN+FN}\)</span></p>
<p>TP to akronim od True Positive, FP od False Positive, TN od True Negative, oraz FN od False Negative.
<br></p>
<p>Metryka ta jest bardzo ogólna i posiada kluczową wadę, a mianowicie przywiązuje jednakową wagę do wartości False Positive oraz False Negative. Nie do końca się to sprawdzi w przypadku niezbalansowanego zbioru danych. W przypadku gdybyśmy posiadali w zbiorze 99% obsewacji należących do klasy ‘A’ oraz 1 % należący do klasy ‘B’ to wykonując zawsze klasyfikacje jako klasa ‘A’ otrzymujemy dokładność na poziomie 99%. Nie do końca jest to poprawnę podejście, a problem się zwiększa ty waga niepoprawnej predykcji nie są jednakowe dla FP oraz FN.</p>
<p>Takim przypadkiem są bardzo rzadkie choroby. Waga jaką przywiązujemy do tego, że niepoprawnie uznamy osobę za zdrową jest znacznie większa, niż gdybyśmy niepoprawnie uznali, że ktoś choruje na daną chorobę. Taką osobę można wysłać na dodatkowe badania, natomiast w przeciwnym przypadku tracimy szansę pomocy chorej osobie. Tak więc jak widać może to być dość kluczowe.</p>
<p>Jeśli chodzi o przypadki medyczne to dla diagnostyki ogólnie bardzo często stosuje się miary Wrażliwości (Sensivity) i Osobliwości (Specificity).
Pomagają te miary określić dokładność modelu, którego zadaniem jest informowanie o występowaniu, bądź nieobecności jakiegoś zjawiska.</p>
</section>
<section id="specificity">
<h3>Specificity<a class="headerlink" href="#specificity" title="Permalink to this heading">#</a></h3>
<p><span class="math notranslate nohighlight">\(Specificity=\frac{TN}{TN+FP}\)</span></p>
<p>Miara osobliwości pozwala nam określić, jak często potrafimy poprawnie zaklasyfikować obserwacje w których dane zjawisko nie zachodzi. W przypadku choroby miara ta odpowiada na pytanie: Jak wielu zdrowych ludzi byliśmy w stanie zaklasyfikować jako faktycznie nieposiadających choroby.</p>
</section>
<section id="sensitivity-recall">
<h3>Sensitivity / Recall<a class="headerlink" href="#sensitivity-recall" title="Permalink to this heading">#</a></h3>
<p><span class="math notranslate nohighlight">\(Sensitivity=\frac{TP}{TP+FN}\)</span></p>
<p>Miara wrażliwości pozwala nam określić, jak często spośród wszystkich obserwacji, które wskazują na występowanie danego zjawiska jesteśmy w stanie poprawnie określić, że ono występuje. W przypadku choroby miara ta odpowiada na pytanie: Jak wielu chorych byliśmy w stanie zaklasyfikować jako faktycznie chorych.</p>
<p>Miara wrażliwości jest również nazywana w angielskim Recall. Patrząc z perspektywy statystycznej można powiedzieć, że miara ta pozwala lepiej określić dokładność w problemach, gdzie błędy False Negative (czyli błędy II rodzaju) są bardziej krtyczne. Jako przykłady można przytoczyć wymienione wyżje rzadkie choroby, czy oszustwa finansowe, bankowe.</p>
</section>
<section id="precision">
<h3>Precision<a class="headerlink" href="#precision" title="Permalink to this heading">#</a></h3>
<p><span class="math notranslate nohighlight">\(Precision=\frac{TP}{TP+FP}\)</span></p>
<p>Miara Recall jest najczęściej zestawiana wraz z miarą Precision, czyli precyzją modelu. Precyzja pozwala nam określić, jak wiele obserwacji z danej klasy udało się zaklasyfikować poprawnie. Pozwala ona lepiej okreslić dokładność w problemach, gdzie błędy False Positive (błąd I rodzaju) są bardziej krytyczne. Takim przypadkiem są na przykład spamy mailowe.</p>
</section>
<section id="blad-f-score">
<h3>Błąd F-Score<a class="headerlink" href="#blad-f-score" title="Permalink to this heading">#</a></h3>
<p><span class="math notranslate nohighlight">\(F_1= 2 \times \frac{Precision \times Recall}{Precision + Recall}\)</span></p>
<p>F1-score jest to metryka, która jest dokładniejszą metryką, niż Accuracy pozwalająca zachować odpowiednia równowagę pomiędzy Recall, a Precision.</p>
<p>W przypadku, gdy potrzebujemy, aby jedna z miar była istotniejsza dla ostatecznego wyniku tej metryki można zastosować bardziej uogólnioną wersję F<span class="math notranslate nohighlight">\(\beta\)</span>-score. W tym przypadku za pomocą współczynnika <span class="math notranslate nohighlight">\(\beta\)</span> możemy zmieniać istotność Precision względem Recall.</p>
<p><span class="math notranslate nohighlight">\(F_{\beta}=(1+ \beta)^2 \times \frac{Precision \times Recall}{\beta ^2 \times Precision + Recall}\)</span></p>
<br>
<br>
<br>
</section>
<section id="roc-curve">
<h3>ROC Curve<a class="headerlink" href="#roc-curve" title="Permalink to this heading">#</a></h3>
<p>Kolejną ważną kwestią przy problemach klasyfikacyjnych jest zaznajomienie się z konceptem krzywer ROC.
Krzywa ta odzwierciedla relacje pomiędzy wartościami FPR (czyli False Positive Rate), a TPR (czyli True Positive Rate) na przestrzeni różnych thresholds (progi odcięcia / wartości graniczne).</p>
<p>Wartość FPR określamy poprzez wzór:</p>
<p><span class="math notranslate nohighlight">\(FPR=\frac{FP}{FP+TN}\)</span></p>
<p>Wartość TPR określamy poprzez wzór:</p>
<p><span class="math notranslate nohighlight">\(TPR=\frac{TP}{FN+TP}\)</span></p>
<p>Wartość threshold natomiast jest to wartość graniczna od której uznajemy klasyfikacje do danej klasy. Klasyfikator nie zwraca bezpośrednio informacji na temat tego, że jest to konkretna klasa, a bardziej prawdopodobieństwo, że dana obserwacja może zostać zaklasyfikowana do danej klasy.</p>
<p>I tak przyjmując, że klasyfikator tego czy dane zdjęcie przedstawia kota zwraca nam wartości:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Lp.</p></th>
<th class="head"><p>Prawdopodobieństwo</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td><p>0.3</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>0.45</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>0.6</p></td>
</tr>
<tr class="row-odd"><td><p>3</p></td>
<td><p>0.8</p></td>
</tr>
</tbody>
</table>
</div>
<p>Jeśli określimy wartość threshold na 50%, to oznacza, że jeśli klasyfikator powyżej 50% powie nam, że to może być ‘Kot’ to to nam wystarcza, aby zaklasyfikować daną obserwację jako ‘Kot’.
W taki sposób można sterować dokładnością modelu.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Lp.</p></th>
<th class="head"><p>Prawdopodobieństwo</p></th>
<th class="head"><p>Threshold 1</p></th>
<th class="head"><p>Klasyfikacja 1</p></th>
<th class="head"><p>Threshold 2</p></th>
<th class="head"><p>Klasyfikacja 2</p></th>
<th class="head"><p>Threshold 3</p></th>
<th class="head"><p>Klasyfikacja 3</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td><p>0.3</p></td>
<td><p>0.2</p></td>
<td><p>Kot</p></td>
<td><p>0.5</p></td>
<td><p>nie-Kot</p></td>
<td><p>0.7</p></td>
<td><p>nie-Kot</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>0.45</p></td>
<td><p>0.2</p></td>
<td><p>Kot</p></td>
<td><p>0.5</p></td>
<td><p>nie-Kot</p></td>
<td><p>0.7</p></td>
<td><p>nie-Kot</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>0.6</p></td>
<td><p>0.2</p></td>
<td><p>Kot</p></td>
<td><p>0.5</p></td>
<td><p>Kot</p></td>
<td><p>0.7</p></td>
<td><p>nie-Kot</p></td>
</tr>
<tr class="row-odd"><td><p>3</p></td>
<td><p>0.8</p></td>
<td><p>0.2</p></td>
<td><p>Kot</p></td>
<td><p>0.5</p></td>
<td><p>Kot</p></td>
<td><p>0.7</p></td>
<td><p>Kot</p></td>
</tr>
</tbody>
</table>
</div>
<p>Manipulując wartością threshold otrzymujemy inne końcowe etykiety i tą zmianę przedstawia krzywa ROC pozwalając nam ustalić jaki próg odcięcia będzie dla nas najbardziej korzystny. ROC curve to wartości TPR oraz FPR przedstawione na wykresie dla różnych wartości theshold.</p>
<p>I tak cofając się do nasze pierwszego przypadku:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Predykcja</p></td>
<td><p>Kot</p></td>
<td><p>Pies</p></td>
<td><p>Kot</p></td>
<td><p>Pies</p></td>
<td><p>Pies</p></td>
<td><p>Pies</p></td>
<td><p>Kot</p></td>
<td><p>Kot</p></td>
<td><p>Pies</p></td>
<td><p>Pies</p></td>
</tr>
<tr class="row-odd"><td><p>Rzeczywista klasa</p></td>
<td><p>Kot</p></td>
<td><p>Kot</p></td>
<td><p>Kot</p></td>
<td><p>Pies</p></td>
<td><p>Kot</p></td>
<td><p>Pies</p></td>
<td><p>Pies</p></td>
<td><p>Kot</p></td>
<td><p>Pies</p></td>
<td><p>Kot</p></td>
</tr>
</tbody>
</table>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">prettytable</span> <span class="kn">import</span> <span class="n">PrettyTable</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span>

<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Kot&#39;</span><span class="p">,</span> <span class="s1">&#39;Kot&#39;</span><span class="p">,</span> <span class="s1">&#39;Kot&#39;</span><span class="p">,</span> <span class="s1">&#39;Pies&#39;</span><span class="p">,</span> <span class="s1">&#39;Kot&#39;</span><span class="p">,</span> <span class="s1">&#39;Pies&#39;</span><span class="p">,</span> <span class="s1">&#39;Pies&#39;</span><span class="p">,</span> <span class="s1">&#39;Kot&#39;</span><span class="p">,</span> <span class="s1">&#39;Pies&#39;</span> <span class="p">,</span><span class="s1">&#39;Kot&#39;</span><span class="p">]</span> <span class="c1"># wartości oczekiwana</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">y_n</span><span class="o">==</span><span class="s1">&#39;Kot&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">y_n</span> <span class="ow">in</span> <span class="n">y</span><span class="p">])</span> <span class="c1"># rzutowanie na {0,1} = {&#39;nieKot&#39;, &#39;Kot&#39;}</span>
<span class="n">probabilities</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.31</span><span class="p">,</span> <span class="mf">0.69</span><span class="p">,</span> <span class="mf">0.42</span><span class="p">,</span> <span class="mf">0.54</span><span class="p">,</span> <span class="mf">0.36</span><span class="p">,</span> <span class="mf">0.78</span><span class="p">,</span> <span class="mf">0.82</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">,</span> <span class="mf">0.49</span><span class="p">])</span> <span class="c1"># Prawdopodobieństwo z modelu</span>


<span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">prob</span><span class="o">&gt;=</span><span class="mf">0.6</span><span class="p">)</span> <span class="k">for</span> <span class="n">prob</span> <span class="ow">in</span> <span class="n">probabilities</span><span class="p">])</span>
<span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Return z funkcji sklearn.metrics.confusion_matrix: &quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="n">confusion_matrix_t</span> <span class="o">=</span> <span class="n">PrettyTable</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Prediction_True&#39;</span><span class="p">,</span> <span class="s1">&#39;Prediction_False&#39;</span><span class="p">])</span>
<span class="n">confusion_matrix_t</span><span class="o">.</span><span class="n">add_row</span><span class="p">([</span><span class="s1">&#39;Actual_True&#39;</span><span class="p">]</span><span class="o">+</span><span class="nb">list</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="n">confusion_matrix_t</span><span class="o">.</span><span class="n">add_row</span><span class="p">([</span><span class="s1">&#39;Actual_False&#39;</span><span class="p">]</span><span class="o">+</span><span class="nb">list</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Ładniejsza forma reprezentacji wartości&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix_t</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Wyliczenie poszczególnych metryk </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">TP</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">FP</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">TN</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
<span class="n">FN</span> <span class="o">=</span> <span class="n">conf_matrix</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;True  Positive: </span><span class="si">{</span><span class="n">TP</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;False Positive: </span><span class="si">{</span><span class="n">FP</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;True  Negative: </span><span class="si">{</span><span class="n">TN</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;False Negative: </span><span class="si">{</span><span class="n">FN</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Accuracy</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy: </span><span class="si">{</span><span class="p">(</span><span class="n">TP</span><span class="o">+</span><span class="n">TN</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">TP</span><span class="o">+</span><span class="n">TN</span><span class="o">+</span><span class="n">FP</span><span class="o">+</span><span class="n">FN</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1"># Specificity</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Specificity: </span><span class="si">{</span><span class="p">(</span><span class="n">TN</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">TN</span><span class="o">+</span><span class="n">FP</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1"># Sensitivity/Recall</span>
<span class="n">Recall</span> <span class="o">=</span> <span class="p">(</span><span class="n">TP</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">TP</span><span class="o">+</span><span class="n">FN</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sensitivity/Recall: </span><span class="si">{</span><span class="p">(</span><span class="n">TP</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">TP</span><span class="o">+</span><span class="n">FN</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1"># Precision</span>
<span class="n">Precision</span> <span class="o">=</span> <span class="p">(</span><span class="n">TP</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">TP</span><span class="o">+</span><span class="n">FP</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision: </span><span class="si">{</span><span class="p">(</span><span class="n">TP</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">TP</span><span class="o">+</span><span class="n">FP</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1"># F-score</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F1-score: </span><span class="si">{</span><span class="mi">2</span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">Precision</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Recall</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">Precision</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Recall</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F_0.5-score: </span><span class="si">{</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">Precision</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Recall</span><span class="p">)</span><span class="o">/</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Precision</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Recall</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F_2-score: </span><span class="si">{</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">Precision</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Recall</span><span class="p">)</span><span class="o">/</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Precision</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Recall</span><span class="p">)</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Krzywa ROC Curve </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">probabilities</span><span class="p">)</span> <span class="c1"># użycie funkcji z biblioteki sklearn</span>

<span class="k">def</span> <span class="nf">plot_static_roc_curve</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Wizaulizacja krzywej ROC</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">7</span><span class="p">,</span><span class="mi">7</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)),</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;False Positive Rate&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True Positive Rate&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;ROC curve&quot;</span><span class="p">);</span>
    
<span class="n">plot_static_roc_curve</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span> <span class="c1"># użycie funkcji wizualizującej</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Return z funkcji sklearn.metrics.confusion_matrix: 
[[3 1]
 [3 3]]

Ładniejsza forma reprezentacji wartości
+--------------+-----------------+------------------+
|              | Prediction_True | Prediction_False |
+--------------+-----------------+------------------+
| Actual_True  |        3        |        1         |
| Actual_False |        3        |        3         |
+--------------+-----------------+------------------+

 Wyliczenie poszczególnych metryk 

True  Positive: 3
False Positive: 3
True  Negative: 3
False Negative: 1

Accuracy: 0.6
Specificity: 0.5
Sensitivity/Recall: 0.75
Precision: 0.5
F1-score: 0.6
F_0.5-score: 0.5357142857142857
F_2-score: 0.6818181818181818 


 Krzywa ROC Curve 
</pre></div>
</div>
<img alt="../_images/5e0ea6ef6b57c0b4b045b73db77379ef3d2b1cf0633a5d7aa5f9a8375c839195.png" src="../_images/5e0ea6ef6b57c0b4b045b73db77379ef3d2b1cf0633a5d7aa5f9a8375c839195.png" />
</div>
</div>
</section>
<section id="auc-metric">
<h3>AUC metric<a class="headerlink" href="#auc-metric" title="Permalink to this heading">#</a></h3>
<p>Obszar znajdujący się pod krzywą ROC nazywany jest błędem AUC i jest to miara wydajności klasyfikatora dla wszystkich wartości progowych. Metryka ta przyjmuje wartości z zakresu od 0 do 1, gdzie wartożsci bliższe 1 oznacza, że krzywa ROC zbliża się ku lewemu górnemu narożnikowi wykresu.</p>
<p>Wartość tą interpretujemy, że dla wysokiej wartości AUC model oceni wyżej losowy pozytywny przypadek, niż losowy negatywny dla klasyfikacji w danej klasie.</p>
</section>
</section>
<section id="podejscie-grupujace">
<h2>Podejście Grupujące<a class="headerlink" href="#podejscie-grupujace" title="Permalink to this heading">#</a></h2>
<p>Grupowanie, czyli szerzej znane jako klasteryzacja (od ang. “Clustering”) polega na podzieleniu populacji lub próbki na wiele grup, tak aby obserwacje w tych samych grupach były bardziej podobne do obserwacji w tej samej grupie, niż w innej.</p>
<section id="v-measure">
<h3>V-measure<a class="headerlink" href="#v-measure" title="Permalink to this heading">#</a></h3>
<p>Metryka ta łączy dwa koncepty Jednorodności (Homogeneity) oraz Kompletności (Completeness).</p>
<div class="math notranslate nohighlight">
\[\upsilon =\frac{(1+\beta \times homogeneity \times completness)}{\beta \times homogeneity + cimpletness}\]</div>
<p>Metryka ta przyjmuje wartości od 0 do 1, gdzie 1 oznacza najlepszą jakość w obrębie tej metryki.
Jednym z minusów dla tej metryki jest konieczność posiadania wiedzy na temat prawdziwych klastrów (grup) dla danych obserwacji, a często przy problemach klastrowania nie znamy tych grup i chcemy je wywnioskować na podstawie wyników algorytmu.</p>
<p><strong>Jednorodność</strong> - każdy klaster zawiera tylko członków jednej klasy</p>
<p><span class="math notranslate nohighlight">\(h=1- \frac{H(C|K)}{H(C)}\)</span></p>
<p>, gdzie</p>
<p><span class="math notranslate nohighlight">\(H(C|K)=-\sum _{c,k} \frac{n_{ck}}{N}log \frac{n_{ck}}{n_k}\)</span></p>
<p>Wartości <span class="math notranslate nohighlight">\(n_{ck}\)</span> - oznacza ilość obserwacji klasy c w obrębie klastra k,
natomiast <span class="math notranslate nohighlight">\(n_k\)</span> - oznacza ilość wszystkich obserwacji w obrębie klastra k.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics.cluster</span> <span class="kn">import</span> <span class="n">v_measure_score</span>
<span class="kn">import</span> <span class="nn">matplotlib.patches</span> <span class="k">as</span> <span class="nn">patches</span>

<span class="c1"># stworzenie prostej przykladowej ramki danych</span>
<span class="n">df_completness</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;klasa&#39;</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>
                     <span class="s1">&#39;x&#39;</span><span class="p">:[</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.3</span><span class="p">,</span><span class="mf">0.15</span><span class="p">,</span><span class="mf">0.24</span><span class="p">,</span><span class="mf">0.14</span><span class="p">,</span><span class="mf">0.32</span><span class="p">,</span><span class="mf">0.4</span><span class="p">,</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.64</span><span class="p">,</span><span class="mf">0.74</span><span class="p">,</span><span class="mf">0.69</span><span class="p">,</span><span class="mf">0.71</span><span class="p">,</span><span class="mf">0.89</span><span class="p">,</span><span class="mf">0.94</span><span class="p">,</span><span class="mf">0.76</span><span class="p">,</span><span class="mf">0.83</span><span class="p">],</span>
                     <span class="s1">&#39;y&#39;</span><span class="p">:[</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.12</span><span class="p">,</span><span class="mf">0.11</span><span class="p">,</span><span class="mf">0.64</span><span class="p">,</span><span class="mf">0.76</span><span class="p">,</span><span class="mf">0.68</span><span class="p">,</span><span class="mf">0.66</span><span class="p">,</span><span class="mf">0.45</span><span class="p">,</span><span class="mf">0.62</span><span class="p">,</span><span class="mf">0.53</span><span class="p">,</span><span class="mf">0.55</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.12</span><span class="p">,</span><span class="mf">0.08</span><span class="p">,</span><span class="mf">0.16</span><span class="p">]})</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Homogeneity - każdy Klaster posiada obserwacje tylko z jednej klasy.&quot;</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">scatter</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df_completness</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">df_completness</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">df_completness</span><span class="o">.</span><span class="n">klasa</span><span class="p">)</span> <span class="c1"># Wizualizacjach obserwacji</span>
<span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="o">*</span><span class="n">scatter</span><span class="o">.</span><span class="n">legend_elements</span><span class="p">(),</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper right&quot;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Klasy&quot;</span><span class="p">))</span> <span class="c1"># dodanie legendy</span>
<span class="n">ax</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">patches</span><span class="o">.</span><span class="n">Rectangle</span><span class="p">((</span><span class="mf">0.11</span><span class="p">,</span><span class="mf">0.05</span><span class="p">),</span> <span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span> <span class="c1"># dodanie oznaczenia klastra 1</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.15</span><span class="p">,</span><span class="mf">0.3</span><span class="p">,</span><span class="s2">&quot;Klaster 1&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">patches</span><span class="o">.</span><span class="n">Rectangle</span><span class="p">((</span><span class="mf">0.11</span><span class="p">,</span><span class="mf">0.55</span><span class="p">),</span> <span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span> <span class="c1"># dodanie oznaczenia klastra 2</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.15</span><span class="p">,</span><span class="mf">0.8</span><span class="p">,</span><span class="s2">&quot;Klaster 2&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">patches</span><span class="o">.</span><span class="n">Rectangle</span><span class="p">((</span><span class="mf">0.58</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">),</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span> <span class="c1"># dodanie oznaczenia klastra 3</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.6</span><span class="p">,</span><span class="mf">0.65</span><span class="p">,</span><span class="s2">&quot;Klaster 3&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">patches</span><span class="o">.</span><span class="n">Rectangle</span><span class="p">((</span><span class="mf">0.7</span><span class="p">,</span><span class="mf">0.05</span><span class="p">),</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span> <span class="c1"># dodanie oznaczenia klastra 4</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.72</span><span class="p">,</span><span class="mf">0.2</span><span class="p">,</span><span class="s2">&quot;Klaster 4&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Homogeneity - każdy Klaster posiada obserwacje tylko z jednej klasy.
</pre></div>
</div>
<img alt="../_images/d9a03c505c4e16128571ea6ea7ecdb969c51ceac60ec36a5412bbaa95d41d333.png" src="../_images/d9a03c505c4e16128571ea6ea7ecdb969c51ceac60ec36a5412bbaa95d41d333.png" />
</div>
</div>
<hr class="docutils" />
<p><strong>Kompletność</strong> - wszyscy członkowie danej klasy są przypisani do tego samego klastra
<img alt="topic" src="../_images/Completenesss.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics.cluster</span> <span class="kn">import</span> <span class="n">v_measure_score</span>
<span class="kn">import</span> <span class="nn">matplotlib.patches</span> <span class="k">as</span> <span class="nn">patches</span>

<span class="c1"># stworzenie prostej przykladowej ramki danych</span>
<span class="n">df_completness</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;klasa&#39;</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>
                     <span class="s1">&#39;x&#39;</span><span class="p">:[</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.3</span><span class="p">,</span><span class="mf">0.15</span><span class="p">,</span><span class="mf">0.24</span><span class="p">,</span><span class="mf">0.14</span><span class="p">,</span><span class="mf">0.32</span><span class="p">,</span><span class="mf">0.4</span><span class="p">,</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.64</span><span class="p">,</span><span class="mf">0.74</span><span class="p">,</span><span class="mf">0.69</span><span class="p">,</span><span class="mf">0.71</span><span class="p">,</span><span class="mf">0.89</span><span class="p">,</span><span class="mf">0.94</span><span class="p">,</span><span class="mf">0.76</span><span class="p">,</span><span class="mf">0.83</span><span class="p">],</span>
                     <span class="s1">&#39;y&#39;</span><span class="p">:[</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.12</span><span class="p">,</span><span class="mf">0.11</span><span class="p">,</span><span class="mf">0.64</span><span class="p">,</span><span class="mf">0.76</span><span class="p">,</span><span class="mf">0.68</span><span class="p">,</span><span class="mf">0.66</span><span class="p">,</span><span class="mf">0.45</span><span class="p">,</span><span class="mf">0.62</span><span class="p">,</span><span class="mf">0.53</span><span class="p">,</span><span class="mf">0.55</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.12</span><span class="p">,</span><span class="mf">0.08</span><span class="p">,</span><span class="mf">0.16</span><span class="p">]})</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Completeness - każdy Klaster posiada obserwacje tylko z jednej klasy.&quot;</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">scatter</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df_completness</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">df_completness</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">df_completness</span><span class="o">.</span><span class="n">klasa</span><span class="p">)</span> <span class="c1"># Wizualizacjach obserwacji</span>
<span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="o">*</span><span class="n">scatter</span><span class="o">.</span><span class="n">legend_elements</span><span class="p">(),</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper right&quot;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Klasy&quot;</span><span class="p">))</span> <span class="c1"># dodanie legendy</span>
<span class="n">ax</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">patches</span><span class="o">.</span><span class="n">Rectangle</span><span class="p">((</span><span class="mf">0.11</span><span class="p">,</span><span class="mf">0.05</span><span class="p">),</span> <span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span> <span class="c1"># dodanie oznaczenia klastra 1</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.15</span><span class="p">,</span><span class="mf">0.8</span><span class="p">,</span><span class="s2">&quot;Klaster 1&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">patches</span><span class="o">.</span><span class="n">Rectangle</span><span class="p">((</span><span class="mf">0.58</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">),</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span> <span class="c1"># dodanie oznaczenia klastra 2</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.6</span><span class="p">,</span><span class="mf">0.65</span><span class="p">,</span><span class="s2">&quot;Klaster 2&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">patches</span><span class="o">.</span><span class="n">Rectangle</span><span class="p">((</span><span class="mf">0.7</span><span class="p">,</span><span class="mf">0.05</span><span class="p">),</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span> <span class="c1"># dodanie oznaczenia klastra 3</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.72</span><span class="p">,</span><span class="mf">0.2</span><span class="p">,</span><span class="s2">&quot;Klaster 3&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completeness - każdy Klaster posiada obserwacje tylko z jednej klasy.
</pre></div>
</div>
<img alt="../_images/b3cc175805da6760d3a7251e9bf545a7cfec34e0bc24c5d696da01da84dbc05e.png" src="../_images/b3cc175805da6760d3a7251e9bf545a7cfec34e0bc24c5d696da01da84dbc05e.png" />
</div>
</div>
</section>
<section id="silhouette-coefficient">
<h3>Silhouette Coefficient<a class="headerlink" href="#silhouette-coefficient" title="Permalink to this heading">#</a></h3>
<p>Współczynnik ten określa, jak bardzo klastry są od siebie oddalone oraz rozróżnialne.
Przyjmuje on wartości od -1 do 1, gdzie:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span> 1 - Klastry są od siebie oddalone i łatwo rozróżnialne
 0 - Klastry są przeciętne, odległość między nimi jest nieznacząca
-1 - Klastry zostały źle przypisane
</pre></div>
</div>
<p>Wzór określający ten współczynnik przedstawia się następująco:</p>
<div class="math notranslate nohighlight">
\[ s = \frac{b-a}{\max(a, b)}\]</div>
<p>, gdzie</p>
<p><span class="math notranslate nohighlight">\(a\)</span> - jest to średnia odległość pomiędzy obserwacją, a pozostałymi obserwacjami w danym klastrze <br>
<span class="math notranslate nohighlight">\(b\)</span> - jest to średnia odległość pomiędzy obserwacją, a pozostałymi obserwacjami w kolejnym najbliższym klastrze</p>
<p>Po zebraniu wartości dla wszystkich obserwacj wartość ta jest uśredniana.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>

<span class="n">first_group</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># pierwszy klaster</span>
<span class="n">second_group</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span>  <span class="c1"># drugi klaster przesuniety</span>
<span class="n">data_set</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">first_group</span><span class="p">,</span><span class="n">second_group</span><span class="p">))</span> <span class="c1"># zbiór danych</span>
<span class="n">df_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data_set</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;feature_1&#39;</span><span class="p">,</span> <span class="s1">&#39;feature_2&#39;</span><span class="p">])</span> <span class="c1"># wygodniejsze przedstawienie danych</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">df_data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;feature_1&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;feature_2&#39;</span><span class="p">)</span> <span class="c1"># wizualizacja danych</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">KMean_model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># inicjalizacja modelu klastrującego na 2 klastry</span>
<span class="n">KMean_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_data</span><span class="p">)</span> <span class="c1"># dopasowanie się do danych</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">KMean_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">df_data</span><span class="p">)</span> <span class="c1"># dokonanie podziału na klastry</span>

<span class="n">display</span><span class="p">(</span><span class="n">df_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Silhouette Score (liczba klastrow n=2): </span><span class="si">{</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">df_data</span><span class="p">,</span><span class="w"> </span><span class="n">labels</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># obliczenie wartości wspolczynnika Silhouette</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">df_data</span><span class="p">,</span><span class="n">hue</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;feature_1&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;feature_2&#39;</span><span class="p">)</span> <span class="c1"># wizualizacja podziału na klastry</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">KMean_model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span> <span class="c1"># inicjalizacja modelu klastrującego na 3 klastry</span>
<span class="n">KMean_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_data</span><span class="p">)</span> <span class="c1"># dopasowanie się do danych</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">KMean_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">df_data</span><span class="p">)</span> <span class="c1"># dokonanie podziału na klastry</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Silhouette Score (liczba klastrow n=3): </span><span class="si">{</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">df_data</span><span class="p">,</span><span class="w"> </span><span class="n">labels</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># obliczenie wartości wspolczynnika Silhouette</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">df_data</span><span class="p">,</span><span class="n">hue</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;feature_1&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;feature_2&#39;</span><span class="p">)</span> <span class="c1"># wizualizacja podziału na klastry</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/53a8965ced3ec641e9388a35f3c83cc675b9ae8564fe92bea74624a3890130a6.png" src="../_images/53a8965ced3ec641e9388a35f3c83cc675b9ae8564fe92bea74624a3890130a6.png" />
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature_1</th>
      <th>feature_2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.294494</td>
      <td>0.628096</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.578665</td>
      <td>0.582415</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.234716</td>
      <td>0.767424</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.395756</td>
      <td>0.625957</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.794567</td>
      <td>0.918838</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>95</th>
      <td>2.372413</td>
      <td>2.492207</td>
    </tr>
    <tr>
      <th>96</th>
      <td>2.884087</td>
      <td>2.921087</td>
    </tr>
    <tr>
      <th>97</th>
      <td>2.303333</td>
      <td>2.449980</td>
    </tr>
    <tr>
      <th>98</th>
      <td>2.131608</td>
      <td>2.864271</td>
    </tr>
    <tr>
      <th>99</th>
      <td>2.096113</td>
      <td>2.732785</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 2 columns</p>
</div></div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Silhouette Score (liczba klastrow n=2): 0.8187772437429933
</pre></div>
</div>
<img alt="../_images/78702719774f6c5171ff65a7814a123ae1f80a6b4db1abc80a7ed5606cf1116b.png" src="../_images/78702719774f6c5171ff65a7814a123ae1f80a6b4db1abc80a7ed5606cf1116b.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Silhouette Score (liczba klastrow n=3): 0.5842624395392341
</pre></div>
</div>
<img alt="../_images/470519e55ef47961eebc431f8b97c0f0bce0ae9600e2b919c1146df3ca693b09.png" src="../_images/470519e55ef47961eebc431f8b97c0f0bce0ae9600e2b919c1146df3ca693b09.png" />
</div>
</div>
<p>Jak można zaobserwować wartość Silhouette Coefficient (Score) jest niższa w przypadku, gdy liczba wybranych przez nas klastrów wynosi 3, gdyż klastry są mniej rozróżnialne.</p>
<p>Jest to dodatkowe zastosowanie również tej metryki. Dzięki niej możemy okreslić jaka liczba klastrów dla naszego zbioru danych będzie optymalna.</p>
</section>
<section id="dunn-s-index">
<h3>Dunn’s Index<a class="headerlink" href="#dunn-s-index" title="Permalink to this heading">#</a></h3>
<p>Ostatnią omawianą metryką dla problemów grupowania jest metryka Dunn’s Index.</p>
<p>Index ten jest równy minimalnej odległości między klsatrami podzielonej przez maksymalny rozmiar tego klastra.</p>
<p><span class="math notranslate nohighlight">\(DI(C)=\frac{\min_{c_k \in C}{\delta(c_k, c_l)}}{\max_{c_k\in C}\Delta(c_k)}\)</span></p>
<p>Duże odległości pomiędzy klastrami są przejawem lepszej separacji, natomiast mniejszy rozmiar klastra świadczy o wyższej gęstości klastra. Jeśli obie z tych cech zostaną odpowiednio usatysfakcjonowane będzie to prowadziło do wyższej wartości DI (Dunn’s Index). Wyższe DI oznacza lepsze grupowanie pod warunkiem, że lepsze grupowanie jest zdefiniowane jako zwarte klastry dobrze oddzielone od siebie nawzajem.</p>
<!-- <img src="media/dunn_image.png" alt="DT" style="width: 400px;">
 -->
<p><img alt="media" src="../_images/dunn_image.png" /></p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./8. Wyjasnialnosc"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../11.%20Regresja/Regresja_trees.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Regresja oparta o modele drzewiaste</p>
      </div>
    </a>
    <a class="right-next"
       href="../9.%20XAI/Wyjasnialnosc_modeli_definicje.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Wyjaśnialność modeli - definicje</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#wstep">Wstęp</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#omawiane-bledy-dla-danych-typow-predykcji">Omawiane błędy dla danych typów predykcji</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#podejscie-regresyjne">Podejście Regresyjne</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#me">ME</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mae">MAE</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mse">MSE</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rmse">RMSE</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rmsle">RMSLE</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mape">MAPE</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#smape">SMAPE</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#podejscie-klasyfikacyjne">Podejście Klasyfikacyjne</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#accuracy-dokladnosc">Accuracy - dokładność</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#specificity">Specificity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sensitivity-recall">Sensitivity / Recall</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#precision">Precision</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#blad-f-score">Błąd F-Score</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#roc-curve">ROC Curve</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#auc-metric">AUC metric</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#podejscie-grupujace">Podejście Grupujące</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#v-measure">V-measure</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#silhouette-coefficient">Silhouette Coefficient</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dunn-s-index">Dunn’s Index</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By codersi
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>