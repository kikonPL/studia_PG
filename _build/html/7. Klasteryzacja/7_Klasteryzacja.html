
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Klasteryzacja w Python &#8212; Silky Coders Data Science</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Klasyfikacja w Python" href="../12.%20Klasyfikacja/Klasyfikacja.html" />
    <link rel="prev" title="Czyszczenie danych" href="../10.%20Czyszczenie_danych/Czyszczenie%20danych.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/silky-logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Silky Coders Data Science</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Laboratorium specjalistyczne: Data Science w branży modowej, 1 semestr studiów magisterskich Matematyki na Wydziale Fizyki Technicznej i Matematyki Stosowanej na Politechnice Gdańskiej
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Wprowadzenie do pakietów numpy i pandas
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../1.%20Tutorial%20pandas/1_Tutorial%20pandas.html">
   Pakiet pandas - tutorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../2.%20Numpy_tutorial/2_Tutorial%20numpy.html">
   Pakiet NumPy - tutorial
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Wizualizacja danych
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../3.%20Wizualizacja_danych/3_Wizualizacja%20danych.html">
   Wizualizacja danych w Python
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Analiza statystyczna
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../4.%20Analiza_statystyczna/4_Analiza%20statystyczna.html">
   Analiza statystyczna - tutorial
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Wykrywanie anomalii
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../5.%20Wykrywanie_anomalii/Wykrywanie_anomalii_teoria.html">
   Wykrywanie anomalii - definicje
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../5.%20Wykrywanie_anomalii/5_Wykrywanie%20anomalii%20tutorial.html">
   Wykrywanie anomalii - tutorial
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Inżynieria cech
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../6.%20Inzynieria_cech/6_Inzynieria%20cech.html">
   Inżynieria cech
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Czyszczenie danych
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../10.%20Czyszczenie_danych/Czyszczenie%20danych.html">
   Czyszczenie danych
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Klasteryzacja
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Klasteryzacja w Python
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Klasyfikacja
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../12.%20Klasyfikacja/Klasyfikacja.html">
   Klasyfikacja w Python
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Regresja
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../11.%20Regresja/Regresja-Part2.html">
   Analiza regresji
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Wyjaśnialność modeli
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../8.%20Wyjasnialnosc/8_Tutorial%20metryki%20statystyczne.html">
   Wyjaśnialność modeli - metryki statystyczne - tutorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../9.%20XAI/Wyjasnialnosc_modeli_definicje.html">
   Wyjaśnialność modeli - definicje
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../9.%20XAI/9_Wyjasnialnosc%20modeli.html">
   Wyjaśnialność modeli - XAI - tutorial
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/7. Klasteryzacja/7_Klasteryzacja.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/kikonPL/studia_PG"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/kikonPL/studia_PG/issues/new?title=Issue%20on%20page%20%2F7. Klasteryzacja/7_Klasteryzacja.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/kikonPL/studia_PG/main?urlpath=tree/_build/7. Klasteryzacja/7_Klasteryzacja.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/kikonPL/studia_PG/blob/main/_build/7. Klasteryzacja/7_Klasteryzacja.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Klasteryzacja w Python
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#wstep">
     Wstęp
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#biblioteki">
     Biblioteki
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#przygotowanie-danych">
     Przygotowanie danych
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#losowe-dane-x-1">
       Losowe dane:
       <span class="math notranslate nohighlight">
        \(X_1\)
       </span>
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#losowe-dane-x-2">
       Losowe dane:
       <span class="math notranslate nohighlight">
        \(X_2\)
       </span>
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#losowe-dane-x-3">
       Losowe dane:
       <span class="math notranslate nohighlight">
        \(X_3\)
       </span>
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#losowe-dane-x-4">
       Losowe dane:
       <span class="math notranslate nohighlight">
        \(X_4\)
       </span>
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#losowe-dane-x-5">
       Losowe dane:
       <span class="math notranslate nohighlight">
        \(X_5\)
       </span>
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#modele-klastrujace">
   Modele klastrujące
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#k-means">
     K-Means
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#czym-jest-k-means">
       Czym jest K-Means ++
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#przyklad-1">
       Przykład 1
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#przyklad-2">
       Przykład 2
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bibliografia-k-means">
       Bibliografia [K-Means]
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#minibatch-k-means">
     MiniBatch K-Means
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#przyklad">
       Przykład
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bibliografia-minibatch-k-means">
       Bibliografia [Minibatch K-Means]
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#agglomerative-clustering">
     Agglomerative Clustering
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       Przykład 1
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id2">
       Przykład 2
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bibliografia-agglomerative-clustering">
       Bibliografia [Agglomerative Clustering]
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#spectral-clustering">
     Spectral Clustering
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id3">
       Przykład
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bibliografia-spectral-clustering">
       Bibliografia [Spectral Clustering]
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dbscan">
     DBSCAN
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id4">
       Przykład 1
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id5">
       Przykład 2
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bibliografia-dbscan">
       Bibliografia [DBSCAN]
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#birch">
     BIRCH
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id6">
       Przykład 1
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id7">
       Przykład 2
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bibliografia-birch">
       Bibliografia [BIRCH]
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#analiza-skutecznosci">
   Analiza skuteczności
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#silhouette-coefficient">
     Silhouette Coefficient
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#calinski-harabasz-index">
     Caliński-Harabasz Index
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#davies-bouldin-index">
     Davies-Bouldin Index
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dunn-index">
     Dunn Index
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#przyklady-analiza-skutecznosci">
   Przykłady (analiza skuteczności)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     Przykład 1
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     Przykład 2
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="klasteryzacja-w-python">
<h1>Klasteryzacja w Python<a class="headerlink" href="#klasteryzacja-w-python" title="Permalink to this headline">¶</a></h1>
<div class="section" id="wstep">
<h2>Wstęp<a class="headerlink" href="#wstep" title="Permalink to this headline">¶</a></h2>
<p>Algorytmy klastrujące należą do grupy modeli uczenia maszynowego - konkretniej uczenia maszynowego bez nadzoru. Oznacza to, że zmienne nie dzielą się na zmienne objaśniające i zmienną celu. W tym kontekście nie mamy na czym “nadzorować” nauki naszego modelu. W przypadku tego rodzaju modeli naszym celem jest pogrupowanie danych w taki sposób, aby poszczególne skupienia, klastry jak najbardziej różniły się od siebie. Oczywiście podejście do grupowania różni się dla różnych zastosowań jednak ostatecznie chcemy aby poszczególne grupy obserwacji charakteryzowały się czymś innym.</p>
<p>Poniższy tutorial wprowadzi nas w świat metod klastrujących wychodząc od podstawowych modeli do coraz to trudniejszych. W trakcie nauki zobaczymy w jaki sposób działa każdy z algorytmów oraz na czym polegają główne różnice między nimi. Dzięki takiemu podejściu możliwym jest nabranie intuicji pozwalającej określić kiedy powinniśmy korzystać z jakiego modelu. Ponadto w końcowej fazie zostaną zaprezentowane podstawowe metody badania skuteczności  algorytmów klastrujących.</p>
</div>
<div class="section" id="biblioteki">
<h2>Biblioteki<a class="headerlink" href="#biblioteki" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Manpulacja danych i operacje statystyczne</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Przykladowe ramki danych</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span><span class="p">,</span> <span class="n">make_blobs</span>

<span class="c1"># Wizualizacja danych</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Inne</span>
<span class="kn">import</span> <span class="nn">datetime</span> <span class="k">as</span> <span class="nn">dt</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="przygotowanie-danych">
<h2>Przygotowanie danych<a class="headerlink" href="#przygotowanie-danych" title="Permalink to this headline">¶</a></h2>
<p>Do celów dydaktycznych przygotujemy 4 zbiory danych: <span class="math notranslate nohighlight">\(X_1\)</span>, <span class="math notranslate nohighlight">\(X_2\)</span>, <span class="math notranslate nohighlight">\(X_3\)</span> oraz <span class="math notranslate nohighlight">\(X_4\)</span>. Każdy z tych zbiorów charakteryzuje się czym innym. Na ich podstawie postaram się pokazać różnice między algorytmami.</p>
<div class="section" id="losowe-dane-x-1">
<h3>Losowe dane: <span class="math notranslate nohighlight">\(X_1\)</span><a class="headerlink" href="#losowe-dane-x-1" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Stworzenie losowego obiektu np.array</span>
<span class="n">X_1</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_clusters_per_class</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Typ obiektu: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Typ danych: </span><span class="si">{</span><span class="n">X_1</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Wymiar obiektu array: </span><span class="si">{</span><span class="n">X_1</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Typ obiektu: &lt;class &#39;numpy.ndarray&#39;&gt;
Typ danych: float64
Wymiar obiektu array: (1000, 2)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Wizualizacja</span>
<span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Wykres rozrzutu zmiennej x i y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7_Klasteryzacja_11_0.png" src="../_images/7_Klasteryzacja_11_0.png" />
</div>
</div>
</div>
<div class="section" id="losowe-dane-x-2">
<h3>Losowe dane: <span class="math notranslate nohighlight">\(X_2\)</span><a class="headerlink" href="#losowe-dane-x-2" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_samples</span> <span class="o">=</span> <span class="mi">1500</span>
<span class="n">random_state</span> <span class="o">=</span> <span class="mi">170</span>
<span class="n">X_2</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Typ obiektu: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Typ danych: </span><span class="si">{</span><span class="n">X_2</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Wymiar obiektu array: </span><span class="si">{</span><span class="n">X_2</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Typ obiektu: &lt;class &#39;numpy.ndarray&#39;&gt;
Typ danych: float64
Wymiar obiektu array: (1500, 2)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Wizualizacja</span>
<span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Wykres rozrzutu zmiennej x i y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7_Klasteryzacja_15_0.png" src="../_images/7_Klasteryzacja_15_0.png" />
</div>
</div>
</div>
<div class="section" id="losowe-dane-x-3">
<h3>Losowe dane: <span class="math notranslate nohighlight">\(X_3\)</span><a class="headerlink" href="#losowe-dane-x-3" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_samples</span> <span class="o">=</span> <span class="mi">1000000</span>
<span class="n">random_state</span> <span class="o">=</span> <span class="mi">170</span>
<span class="n">X_3</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Typ obiektu: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">X_3</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Typ danych: </span><span class="si">{</span><span class="n">X_3</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Wymiar obiektu array: </span><span class="si">{</span><span class="n">X_3</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Typ obiektu: &lt;class &#39;numpy.ndarray&#39;&gt;
Typ danych: float64
Wymiar obiektu array: (1000000, 2)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Wizualizacja</span>
<span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_3</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_3</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Wykres rozrzutu zmiennej x i y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7_Klasteryzacja_19_0.png" src="../_images/7_Klasteryzacja_19_0.png" />
</div>
</div>
</div>
<div class="section" id="losowe-dane-x-4">
<h3>Losowe dane: <span class="math notranslate nohighlight">\(X_4\)</span><a class="headerlink" href="#losowe-dane-x-4" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set random state. </span>
<span class="n">rs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">generate_circle_sample_data</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generate circle data with random Gaussian noise.&quot;&quot;&quot;</span>
    <span class="n">angles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>

    <span class="n">x_epsilon</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
    <span class="n">y_epsilon</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">r</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">angles</span><span class="p">)</span> <span class="o">+</span> <span class="n">x_epsilon</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">r</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">angles</span><span class="p">)</span> <span class="o">+</span> <span class="n">y_epsilon</span>
    
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>

<span class="k">def</span> <span class="nf">generate_concentric_circles_data</span><span class="p">(</span><span class="n">param_list</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generates many circle data with random Gaussian noise.&quot;&quot;&quot;</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">num</span><span class="p">,</span> <span class="n">params</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">param_lists</span><span class="p">):</span>
        <span class="n">x_</span><span class="p">,</span> <span class="n">y_</span> <span class="o">=</span> <span class="n">generate_circle_sample_data</span><span class="p">(</span><span class="o">*</span><span class="n">params</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">x_</span><span class="p">])</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">y</span><span class="p">,</span> <span class="n">y_</span><span class="p">])</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">])</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span> 
    
    <span class="k">return</span> <span class="n">X</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Number of points per circle. </span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="c1"># Radius. </span>
<span class="n">r_list</span> <span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>
<span class="c1"># Standar deviation (Gaussian noise). </span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.2</span>

<span class="n">param_lists</span> <span class="o">=</span> <span class="p">[(</span><span class="n">r</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">r_list</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_4</span> <span class="o">=</span> <span class="n">generate_concentric_circles_data</span><span class="p">(</span><span class="n">param_lists</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Typ obiektu: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">X_4</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Typ danych: </span><span class="si">{</span><span class="n">X_4</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Wymiar obiektu array: </span><span class="si">{</span><span class="n">X_4</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Typ obiektu: &lt;class &#39;numpy.ndarray&#39;&gt;
Typ danych: float64
Wymiar obiektu array: (3000, 2)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Wizualizacja</span>
<span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_4</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_4</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Wykres rozrzutu zmiennej x i y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7_Klasteryzacja_25_0.png" src="../_images/7_Klasteryzacja_25_0.png" />
</div>
</div>
</div>
<div class="section" id="losowe-dane-x-5">
<h3>Losowe dane: <span class="math notranslate nohighlight">\(X_5\)</span><a class="headerlink" href="#losowe-dane-x-5" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Number of points per circle. </span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="c1"># Radius. </span>
<span class="n">r_list</span> <span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>
<span class="c1"># Standar deviation (Gaussian noise). </span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.2</span>

<span class="n">param_lists</span> <span class="o">=</span> <span class="p">[(</span><span class="n">r</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">r_list</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_5</span> <span class="o">=</span> <span class="n">generate_concentric_circles_data</span><span class="p">(</span><span class="n">param_lists</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_5</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_clusters_per_class</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Typ obiektu: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">X_5</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Typ danych: </span><span class="si">{</span><span class="n">X_5</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Wymiar obiektu array: </span><span class="si">{</span><span class="n">X_5</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Typ obiektu: &lt;class &#39;numpy.ndarray&#39;&gt;
Typ danych: float64
Wymiar obiektu array: (10000, 2)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Wizualizacja</span>
<span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_5</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_5</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Wykres rozrzutu zmiennej x i y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7_Klasteryzacja_31_0.png" src="../_images/7_Klasteryzacja_31_0.png" />
</div>
</div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="modele-klastrujace">
<h1>Modele klastrujące<a class="headerlink" href="#modele-klastrujace" title="Permalink to this headline">¶</a></h1>
<p>W poniższym tutorialu zaprezentowanych zostanie kilka metod klastrowania, tj.:</p>
<ul class="simple">
<li><p>K-Means</p></li>
<li><p>MiniBatch K-Means</p></li>
<li><p>Agglomerative Clustering</p></li>
<li><p>Spectral Clustering</p></li>
<li><p>DBSCAN</p></li>
<li><p>BIRCH</p></li>
</ul>
<div class="section" id="k-means">
<h2>K-Means<a class="headerlink" href="#k-means" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
</pre></div>
</div>
</div>
</div>
<p>Algorytm <em>K-Means</em> jest jednym z podstawowych modeli uczenia maszynowego wykorzystywanym do klastrowania obserwacji. Jego działanie polega na minimalizacji wariancji wewnątrz klastra. Algorytm wymaga podania liczby klastrów na ile chcemy poidzielić nasze obserwacje. Wybór liczby klastrów zależy od zależności statystycznych w naszych danych jak i również wymagań biznesowych.</p>
<p>Algorytm <em>K-Means</em> ma za zadanie podzielić <span class="math notranslate nohighlight">\(N\)</span> elementową próbę zmiennych losowych <span class="math notranslate nohighlight">\(X_{j}\)</span>, gdzie <span class="math notranslate nohighlight">\(j=1,2,...\)</span> na <span class="math notranslate nohighlight">\(K\)</span> rozdzielnych klastrów <span class="math notranslate nohighlight">\(C\)</span>, gdzie każdy z klastrów jest opisany przez średnią <span class="math notranslate nohighlight">\(\mu_{k}\)</span> próbek w klastrze. Wartości średnie <span class="math notranslate nohighlight">\(\mu_{k}\)</span> nazywane są <em>centroidami</em> lub <em>środkami ciężkości</em> klastra <span class="math notranslate nohighlight">\(K\)</span>. Celem algorytmu jest wybór takich <em>centroidów</em>, które minimalizują wartość sumy kwadratów w ramach klastra:</p>
<div class="math notranslate nohighlight">
\[ \min_{C} \sum_{k=1}^{K} N_{k} \sum_{C(i) = k} (\|x_{i}-\mu_{k}\|^{2}) \]</div>
<p>gdzie <span class="math notranslate nohighlight">\(N=\sum_{k=1}^{K} N_{k}\)</span> oraz <span class="math notranslate nohighlight">\(C(i)=k\)</span> oznacza przynależność obserwacji <span class="math notranslate nohighlight">\(i\)</span> do klastra <span class="math notranslate nohighlight">\(k\)</span>.</p>
<div class="section" id="czym-jest-k-means">
<h3>Czym jest K-Means ++<a class="headerlink" href="#czym-jest-k-means" title="Permalink to this headline">¶</a></h3>
<p>Algorytm <em>K-Means++</em> jest rozwinięciem algorytmu <em>K-Means</em>, które w głównej mierze polega na innej metodzie inicjalizacji <em>centroidów</em>. W klasycznej metodzie <em>K-means</em> centroidy w pierwszej iteracji dobierają się losowo - za wyjątkiem inicjalizacji ręcznej. W przypadku <em>K-means++</em> inicjalizacja polega na wybraniu punktów (ogólnie) jak najbardziej oddalonych od siebie. Ostatecznie prowadzi to do lepszych wyników niż losowa inicjalizacja.</p>
</div>
<div class="section" id="przyklad-1">
<h3>Przykład 1<a class="headerlink" href="#przyklad-1" title="Permalink to this headline">¶</a></h3>
<p>Aby lepiej zrozumieć zachowanie obu algorytmów warto spojrzeć na poniższą wizualizajcę. W tym przykładzie opieramy się na losowych obserwacjach <strong>X2</strong>, w których gołym okiem widać jak powinny rozłozyć się klastry dla tego zbioru. W pierwszej wizuzlizacji inijcalizujemy centroid przy pomocy estymatora <em>KMeans</em> biblioteki <em>sklearn</em> z inicjalizatorem <strong>random</strong>. W drugim przypadku inicjalizator random zastępujęmy algorytmem <strong>kmeans++</strong>. W obu przypadkach zakładamy jedną iterację algorytmu. Oznacza to, że w obu przypadkach początkowo wybrane centroidy będą tymi ostatecznymi.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># KMeans</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;WARD&#39;</span><span class="p">,</span> <span class="s1">&#39;AVERAGE&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_2</span><span class="o">.</span><span class="n">shape</span>

<span class="c1">## Inicjalizacja random</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_random</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;random&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model_random</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_random</span> <span class="o">=</span> <span class="n">model_random</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>

<span class="c1">## Inicjalizacja k-means++</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_plusplus</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model_plusplus</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_plusplus</span> <span class="o">=</span> <span class="n">model_plusplus</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_random</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_plusplus</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model_random</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">model_random</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;ro&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacją random&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model_plusplus</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">model_plusplus</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;ro&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacją k-means++&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_2 wraz z centroidami&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Cza kalkulacji</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">] Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7_Klasteryzacja_42_0.png" src="../_images/7_Klasteryzacja_42_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (1500, 2)
[WARD] Duration: 0:00:00.009976
[AVERAGE] Duration: 0:00:00.010084
</pre></div>
</div>
</div>
</div>
<p>Tutaj widać przewagę inicjalizatora kmeans++, który już na początku jest w stanie dobrze podzialić nasz zbiór obserwacji na 3 niezależne klastry. W przypadku inicjalizacji random potrzebujemy większej liczby iteracji, aby znaleźć dobrą lokalizacje centroidów.</p>
<div class="alert alert-block alert-info">
<b>Info</b> 
<p>Zbieżność algorytmu KMeans zależy od liczby iteracji algorytmu. Zazwyczaj przy dużej liczbie iteracji powinniśmy znaleźć globalne minimum naszej funkcji celu. Niestety czasami istnieje ryzyko znalezienia się w lokalnym minimum.</p>
</div><p>W tym prostym przypadku, w momencie gdy zwiększymy liczbę iteracji dla inicjalizacji random do 10, to algorytm osiąga przewidywane przez nas wyniki.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># KMeans</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;KMEANS_RANDOM&#39;</span><span class="p">,</span> <span class="s1">&#39;KMEANS_++&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_2</span><span class="o">.</span><span class="n">shape</span>

<span class="c1">## Inicjalizacja random</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_random</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;random&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">model_random</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_random</span> <span class="o">=</span> <span class="n">model_random</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>

<span class="c1">## Inicjalizacja k-means++</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_plusplus</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model_plusplus</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_plusplus</span> <span class="o">=</span> <span class="n">model_plusplus</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_random</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_plusplus</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model_random</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">model_random</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;ro&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacją random&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model_plusplus</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">model_plusplus</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;ro&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacją k-means++&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_2 wraz z centroidami&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Cza kalkulacji</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">] Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7_Klasteryzacja_46_0.png" src="../_images/7_Klasteryzacja_46_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (1500, 2)
[KMEANS_RANDOM] Duration: 0:00:00.002127
[KMEANS_++] Duration: 0:00:00
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="przyklad-2">
<h3>Przykład 2<a class="headerlink" href="#przyklad-2" title="Permalink to this headline">¶</a></h3>
<p>Poniższy przykład ilustruje zachowanie algorytmu <em>KMeans</em> w nie intuicyjny przez nas sposób. Oczekiwalibyśmy, aby algorytm klastrujący podzielił zbiór  obserwacji na dwa klastry względem widocznych przez nas grup. Niestety tak się nie dzieje i jest to niezależne od liczby iteracji algorytu - poprostu <em>KMeans</em> nie est najlepszy w tego typu problemach.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># KMeans</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;KMEANS_RANDOM&#39;</span><span class="p">,</span> <span class="s1">&#39;KMEANS_++&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_2</span><span class="o">.</span><span class="n">shape</span>

<span class="c1">## Inicjalizacja random</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_random</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;random&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
<span class="n">model_random</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_random</span> <span class="o">=</span> <span class="n">model_random</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>

<span class="c1">## Inicjalizacja k-means++</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_plusplus</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
<span class="n">model_plusplus</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_plusplus</span> <span class="o">=</span> <span class="n">model_plusplus</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_random</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_plusplus</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model_random</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">model_random</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;ro&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacją random&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model_plusplus</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">model_plusplus</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;ro&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacją k-means++&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_2 wraz z centroidami&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Cza kalkulacji</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">] Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7_Klasteryzacja_49_0.png" src="../_images/7_Klasteryzacja_49_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (1500, 2)
[KMEANS_RANDOM] Duration: 0:00:00.022320
[KMEANS_++] Duration: 0:00:00.030524
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="bibliografia-k-means">
<h3>Bibliografia [K-Means]<a class="headerlink" href="#bibliografia-k-means" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/clustering.html#k-means">https://scikit-learn.org/stable/modules/clustering.html#k-means</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/K-means_clustering">https://en.wikipedia.org/wiki/K-means_clustering</a></p></li>
<li><p><em>The Elements of. Statistical Learning: Data Mining, Inference, and Prediction.</em> Second Edition. February 2009. Trevor Hastie · Robert Tibshirani</p></li>
<li><p><a class="reference external" href="https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1">https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1</a></p></li>
</ul>
</div>
</div>
<div class="section" id="minibatch-k-means">
<h2>MiniBatch K-Means<a class="headerlink" href="#minibatch-k-means" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">MiniBatchKMeans</span>
</pre></div>
</div>
</div>
</div>
<p>Algorytm <em>Minibatch KMeans</em> jest jednym z wariantów algorytmu <em>KMeans</em> szczególnie użytecznym w przypadku bardzo dużych zbiorów danych - w przypadkach, gdy czas ewaluacji algorytmu liczy się bardziej niż jego dokładność. <strong>MiniBatch</strong> to podzbiór danych wejściowych, losowo próbkowany w każdej iteracji podczas treningu modelu. W efekcie podział zbioru treningowego na mini-batche redukuję czas kalkulacji potrzebny do osiągnięcia zbieżności algorytmu. Ostatecznie algorytm oparty o mini-batche w ogólności osiąga tylko nieco gorsze wyniki niż klasyczna metoda <em>Kmeans</em>.</p>
<div class="section" id="przyklad">
<h3>Przykład<a class="headerlink" href="#przyklad" title="Permalink to this headline">¶</a></h3>
<p>Zastosowanie algorytmu <em>MiniBatch K-Means</em> w przypadku jasno widocznych klastrów, jednak gdy obserwacji mamy więcej działa tak samo daję takie same wyniki jak algorytm <em>Kmeans</em>. Jednak w tym przypadku zależy nam na sprawdzeniu czasu przetwarzania - to tutaj powinna być widoczna różnica. Tak też się dzieje. Widoczny czas przetwarzania jasno wskazuje na przewagę algorytmu <em>MiniBatch K-Means</em> w przypadku dużych próbek. Czas przetwarzania w tym przypadku jest kilka razy szybszy przy zachowaniu niemal takiego samego podziału na klastry.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;KMEANS_++&#39;</span><span class="p">,</span> <span class="s1">&#39;MINIBATCH_KMEANS&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_3</span><span class="o">.</span><span class="n">shape</span>

<span class="c1"># KMeans</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_random</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">model_random</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_3</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_random</span> <span class="o">=</span> <span class="n">model_random</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_3</span><span class="p">)</span>

<span class="c1">#  Minibatch K-means</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_minibatch</span> <span class="o">=</span> <span class="n">MiniBatchKMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">model_minibatch</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_3</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_minibatch</span> <span class="o">=</span> <span class="n">model_minibatch</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_3</span><span class="p">)</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_3</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_3</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_random</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_3</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_3</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_minibatch</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model_random</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">model_random</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;ro&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie MiniBatch KMeans&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model_minibatch</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">model_minibatch</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;ro&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacją k-means++&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_3 wraz z centroidami&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Cza kalkulacji</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">] Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7_Klasteryzacja_56_0.png" src="../_images/7_Klasteryzacja_56_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (1000000, 2)
[KMEANS_++] Duration: 0:00:07.404238
[MINIBATCH_KMEANS] Duration: 0:00:02.703953
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-success">
<b>Zadanie</b> 
<p>Korzystając z kodu dostępnego przy powyższych wizualizacjach znajdź współrzędne <em>centroidów</em> dla algorytmu KMeans oraz <em>MiniBatchKMeans</em>. Czy w tym przypadku jest jakaś różnica ? Policz odległość Euklidesową między nimi.</p>
<p><em>Podpowiedź</em>: Najpierw znajdź punkty, które są najbliżej siebie. Może się zdarzyć, że oznaczenie klastrów 0, 1, 2 będzie różne dla różnych algorytmów.</p>
</div></div>
<div class="section" id="bibliografia-minibatch-k-means">
<h3>Bibliografia [Minibatch K-Means]<a class="headerlink" href="#bibliografia-minibatch-k-means" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/clustering.html#mini-batch-kmeans">https://scikit-learn.org/stable/modules/clustering.html#mini-batch-kmeans</a></p></li>
</ul>
</div>
</div>
<div class="section" id="agglomerative-clustering">
<h2>Agglomerative Clustering<a class="headerlink" href="#agglomerative-clustering" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">AgglomerativeClustering</span>
</pre></div>
</div>
</div>
</div>
<p>Klastrowanie hierarchiczne polega na budowaniu zagnieżdżonych klastrów poprzez ich kolejne scalanie lub dzielenie. Hierarchia klastrów jest reprezentowana jako drzewo (lub dendrogram). Korzeń drzewa jest unikalnym skupiskiem, które gromadzi wszystkie próbki, a liście są skupiskami z tylko jedną próbką. Obiekt <code class="docutils literal notranslate"><span class="pre">AgglomerativeClustering</span></code> wykonuje hierarchiczne grupowanie przy użyciu podejścia oddolnego: każda obserwacja rozpoczyna się we własnym klastrze, a klastry są sukcesywnie łączone ze sobą. Kryteria powiązania <code class="docutils literal notranslate"><span class="pre">linkage</span></code> określają metrykę używaną w strategii łączenia:</p>
<ul class="simple">
<li><p><strong>Ward</strong> - minimalizuje sumę kwadratów różnic we wszystkich klastrach. Jest to podejście minimalizujące wariancje i w tym sensie jest podobne do funkcji celu k-średnich, ale rozwiązywane za pomocą aglomeracyjnego podejścia hierarchicznego.</p></li>
<li><p><strong>Maximum linkage</strong>/<strong>Complete linkage</strong> - minimalizuje maksymalną odległość między obserwacjami par klastrów.</p></li>
<li><p><strong>Average linkage</strong> - minimalizuje średnią odległości między wszystkimi obserwacjami par klastrów.</p></li>
<li><p><strong>Single linkage</strong> - minimalizuje odległość pomiędzy najbliższymi obserwacjami par klastrów.</p></li>
</ul>
<div class="section" id="id1">
<h3>Przykład 1<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>Metody aglomeracyjne w przypadku klastrów o jasno widocznym środku ciężkości klastra radzą sobie bardzo dobrze. Obie metody <em>Ward</em> oraz <em>Average</em> bardzo dobrze dzielą obserwacje na klastry. Podział jest taki sam jak w przypadku algorytmów z rodziny <em>KMeans</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;WARD&#39;</span><span class="p">,</span> <span class="s1">&#39;AVERAGE&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_2</span><span class="o">.</span><span class="n">shape</span>

<span class="c1"># Algorytm Ward</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_ward</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">linkage</span><span class="o">=</span><span class="s1">&#39;ward&#39;</span><span class="p">,</span> <span class="n">affinity</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">model_ward</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_ward</span> <span class="o">=</span> <span class="n">model_ward</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># Algorytm Average</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_avg</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">linkage</span><span class="o">=</span><span class="s1">&#39;average&#39;</span><span class="p">,</span> <span class="n">affinity</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">model_avg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_avg</span> <span class="o">=</span> <span class="n">model_avg</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_ward</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_avg</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie WARD linkage&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie Average linkage&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Cza kalkulacji</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">] Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7_Klasteryzacja_64_0.png" src="../_images/7_Klasteryzacja_64_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (1500, 2)
[WARD] Duration: 0:00:00.056145
[AVERAGE] Duration: 0:00:00.043821
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id2">
<h3>Przykład 2<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>Drugi przykład jest nieco trudniejszy. Klastry są widoczne ale są różnych kształtów. W tym przypadku oba algorytmy sobie nie radzą. Metoda <em>Ward</em> dzieli klastry podobnie jak algorytm <em>KMeans</em>. W przypadku metody opartej o powiązanie <em>Average</em> dostajemy dwa klastry z czego jeden z nich składa się z jednej obserwacji - raczej nie tego oczekujemy po algorytmie klastrującym.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;WARD&#39;</span><span class="p">,</span> <span class="s1">&#39;AVERAGE&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_1</span><span class="o">.</span><span class="n">shape</span>

<span class="c1"># Algorytm Ward</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_ward</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linkage</span><span class="o">=</span><span class="s1">&#39;ward&#39;</span><span class="p">,</span> <span class="n">affinity</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">model_ward</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_ward</span> <span class="o">=</span> <span class="n">model_ward</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># Algorytm Average</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_avg</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linkage</span><span class="o">=</span><span class="s1">&#39;average&#39;</span><span class="p">,</span> <span class="n">affinity</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">model_avg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_avg</span> <span class="o">=</span> <span class="n">model_avg</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_ward</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_avg</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie WARD linkage&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie Average linkage&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Cza kalkulacji</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">] Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7_Klasteryzacja_67_0.png" src="../_images/7_Klasteryzacja_67_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (1000, 2)
[WARD] Duration: 0:00:00.024352
[AVERAGE] Duration: 0:00:00.025287
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-success">
<b>Zadanie</b> 
<p>Spróbuj analogicznie jak powyżej zastosować algorytmy <em>Single Linkage</em> oraz <em>Maximum Linkage</em>.</p>
</div></div>
<div class="section" id="bibliografia-agglomerative-clustering">
<h3>Bibliografia [Agglomerative Clustering]<a class="headerlink" href="#bibliografia-agglomerative-clustering" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering">https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Hierarchical_clustering">https://en.wikipedia.org/wiki/Hierarchical_clustering</a></p></li>
</ul>
</div>
</div>
<div class="section" id="spectral-clustering">
<h2>Spectral Clustering<a class="headerlink" href="#spectral-clustering" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">SpectralClustering</span>
</pre></div>
</div>
</div>
</div>
<p>W praktyce <em>Spectral Clustering</em> jest bardzo przydatne, gdy struktura poszczególnych klastrów jest wysoce niewypukła lub bardziej ogólnie, gdy miara środka i rozproszenia klastra nie jest odpowiednim opisem całego klastra, na przykład gdy klastry są zagnieżdżonymi okręgami na płaszczyźnie 2D. Cała teoria związana z klastrowaniem spektralnym wywodzi się z teorii grafów oraz algebry liniowej. Algorytm składa się na wejściu  danych w postaci macierzy podobieństwa <em>adjacency matrix</em>, a następnie wyznacza się macierz Laplace’a. Kolejnym etapem jest wyliczenie wektorów i wartosci własnych macierzy Laplace’a. Ostatecznie na wyznaczonych wektorach własnych uruchamiany algorytm <em>k-means</em>.</p>
<p>Aby wyliczyć macierz <em>adjacency matrix</em> możemy wykorzystać metody: skorzystać z algorytmu <em>k nearest neighbors</em> lub skorzystać z kalkulacji przy pomocy jądra <em>rbf</em>. W pierwszym przypadku do wyliczenia maceirz wykorzystujemy teorię grafów oraz algorytm <em>k nearest neighbor</em> znajdujący k najbliższych sąsiadów. W drugim przypadku wykorzystujemy jądro RBF, które (Radial basis function) na dwóch próbkach <span class="math notranslate nohighlight">\(x_{1}\)</span> i <span class="math notranslate nohighlight">\(x_{2}\)</span>, reprezentowanych jako wektory cech w pewnej przestrzeni wejściowej, jest zdefiniowane jako:</p>
<div class="math notranslate nohighlight">
\[ K(x_{1}, x_{2}) = \exp(-\gamma(\| x_{1} - x_{2}\|^{2})) \]</div>
<p>gdzie parameter <span class="math notranslate nohighlight">\(\gamma\)</span> jest parametrem modelu. Czasami możemy się spotkać z zapisem gdzie <span class="math notranslate nohighlight">\(\gamma = \frac{1}{2\sigma^{2}}\)</span>. Wynika to z tego, że jądro RBF jest pewnym “uogólnieniem” jądra Gaussowskiego. W dużym uproszczeniu oznacza to, że przy wywołaniu metody <code class="docutils literal notranslate"><span class="pre">fit</span></code> liczymy macierz <em>adjacency matrix</em> przy pomocy jądra RBF. A następnie dokonywana są kolejne kalkulacje tj. kalkulacja macierzy Laplace’a oraz wyznaczenie wektorów i wartości własnych.</p>
<div class="section" id="id3">
<h3>Przykład<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>W poniższym przykładzie dużo lepszym wyborem jest algorytm <em>SpectralClustering</em> wraz z metodą wyznaczenia macierzy podobieństwa <code class="docutils literal notranslate"><span class="pre">affinity</span></code> ustawioną jako <em>rbf</em>. Przy dobrze dobranych hiperparametrach jesteśmy w stanie skutecznie odseparować od siebie obie grupy obserwacji. W moim odczuciu dobranie lepszych wartości parametrów dla metody <em>knn</em> jest trudniejsze. Ponadto wydaje się, że algorytm oparty o <em>rbf</em> działa nieco szybciej.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;SPECTRAL_KNN&#39;</span><span class="p">,</span> <span class="s1">&#39;SPECTRAL_RBF&#39;</span><span class="p">,</span> <span class="s1">&#39;KMEANS&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_1</span><span class="o">.</span><span class="n">shape</span>

<span class="c1"># Spectral Clustering (KNN)</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_sc</span> <span class="o">=</span> <span class="n">SpectralClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">affinity</span><span class="o">=</span><span class="s1">&#39;nearest_neighbors&#39;</span><span class="p">,</span>  <span class="n">assign_labels</span><span class="o">=</span><span class="s1">&#39;kmeans&#39;</span><span class="p">)</span>
<span class="n">model_sc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_spectral_knn</span> <span class="o">=</span> <span class="n">model_sc</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># Spectral Clustering (RBF)</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_sc</span> <span class="o">=</span> <span class="n">SpectralClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">affinity</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">assign_labels</span><span class="o">=</span><span class="s1">&#39;kmeans&#39;</span><span class="p">)</span>
<span class="n">model_sc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_spectral_rbf</span> <span class="o">=</span> <span class="n">model_sc</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># K-means++</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_plusplus</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">)</span>
<span class="n">model_plusplus</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_plusplus</span> <span class="o">=</span> <span class="n">model_plusplus</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_spectral_knn</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_spectral_rbf</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_plusplus</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie Spectral Clustering (KNN)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie Spectral Clustering (RBF)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacją k-means++&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_1 wraz z centroidami&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Cza kalkulacji</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">] Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7_Klasteryzacja_78_0.png" src="../_images/7_Klasteryzacja_78_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (1000, 2)
[SPECTRAL_KNN] Duration: 0:00:00.292366
[SPECTRAL_RBF] Duration: 0:00:00.239308
[KMEANS] Duration: 0:00:00.024011
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-success">
<b>Zadanie</b> 
<p>Sprawdź co się stanie gdy zmienisz wartość parametru <code class="docutils literal notranslate"><span class="pre">gamma</span></code>.</p>
</div></div>
<div class="section" id="bibliografia-spectral-clustering">
<h3>Bibliografia [Spectral Clustering]<a class="headerlink" href="#bibliografia-spectral-clustering" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html#r5f6cbeb1558e-2">https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html#r5f6cbeb1558e-2</a></p></li>
<li><p><a class="reference external" href="https://towardsdatascience.com/spectral-clustering-aba2640c0d5b">https://towardsdatascience.com/spectral-clustering-aba2640c0d5b</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Radial_basis_function_kernel">https://en.wikipedia.org/wiki/Radial_basis_function_kernel</a></p></li>
</ul>
</div>
</div>
<div class="section" id="dbscan">
<h2>DBSCAN<a class="headerlink" href="#dbscan" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">DBSCAN</span>
</pre></div>
</div>
</div>
</div>
<p>Algorytm <em>DBSCAN</em> w dużym uproszczeniu polega na interpretacji klastrów jako pół o wysokiej gęstości odseparowanych polami o niskiej gęstości. To powoduję, że klastry znaleznione przy pomocy alorytmu <em>DBSCAN</em> mogą mieć dowolny kształt w stosunku do klastrów powstałych przy pomocy algorytmu <em>KMeans</em>, który zakłada wypukłość klastrów. Główną składową algorytmu jest pojęcie <em>próbki podstawowej</em>, która jest próbką znajdującą się w obszarze wysokiej gęstości. Wtedy klaster jest zbiorem próbek podstawowych, dla których każda jest blisko kolejnej próbki (odległość liczona za pomocą przyjętej metryki odległości) oraz zbioru próbek niepodstawowych, które są blisko próbki podstawowej, ale nie są próbką podstawową. Algorytm opiera się na dwóch podstawowych parametrach: <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> oraz <code class="docutils literal notranslate"><span class="pre">eps</span></code>, które formalnie definiują co użytkownik ma na myśli mówiąc o gęstości. Wysoka wartość <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> oraz niska wartość <code class="docutils literal notranslate"><span class="pre">eps</span></code> oznacza potrzebę uzyskania wyższej gęstości obserwacji potrzebną do uformowania się klastra. Dokładniej, definujemy <em>próbkę podstawową</em> jako podzbiór obserwacji dla którego istnieje <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> innych podzbiorów w odległości <code class="docutils literal notranslate"><span class="pre">eps</span></code>, które są “sąsiadami” <em>próbki podstawowej</em>. Oznacza to, że <em>próbka podstawowa</em> znajduje się w gęstym obszarze przestrzeni wektorowej.</p>
<div class="section" id="id4">
<h3>Przykład 1<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>Pierwszy przykład obejmuje klastrowanie zbioru <span class="math notranslate nohighlight">\(X_1\)</span>. Poniżej porówanjmy zachowanie trzech algorytmów: DBSCAN, Spectral Clustering oraz KMeans. Warto zwrócić uwagę na jedną rzecz w przypadku algorytmu <em>DBSCAN</em>. Przy definiowaniu parametrów modelu nie zajdziemy parametru <code class="docutils literal notranslate"><span class="pre">n_clusters</span></code> tak jak w przypadku poprzednich. Jest to bardzo duży atut tego aglorytmu, ponieważ on sam dzieli nasz zbiór na odpowiednią liczbę klastrów w zależności jak zdefiniujemy gęstość za pomocą parametrów <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> oraz <code class="docutils literal notranslate"><span class="pre">eps</span></code>.</p>
<p>Przy zadanych parametrach wydaję się, że algorytm <em>Spectral Clustering</em> działa najlepiej. Jednak jak przyjrzymy się bliżej to może się wydawać, że algorytm <em>DBSCAN</em> dzieli obserwacje na 3 klastry. Nic bardziej mylnego. Labelka “-1” oznacza, że daną obsewację nie udało się zaliczyć do żadnego klastra - przynajmniej w przypadku tak określonych parametrów <code class="docutils literal notranslate"><span class="pre">min_sample</span></code> oraz <code class="docutils literal notranslate"><span class="pre">eps</span></code>. Zatem obserwacje z labelką “-1” można określić jako anomalie w danym zbiorze obserwacji. Właśnie wykrywanie anomalii jest kolejnym zastosowaniem algorytmu <em>DBSCAN</em> oprócz klastrowania. W powyższym przykładzie zapewne uda się podzielić zbiór przy pomocy <em>DBSCAN</em> jeszcze lepiej (zmieniając parametry), ponieważ wydaję się że niektóre z obserwacji mogą jednak nie być anomaliami.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;DBSCAN&#39;</span><span class="p">,</span> <span class="s1">&#39;SPECTRAL&#39;</span><span class="p">,</span> <span class="s1">&#39;KMEANS++&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_1</span><span class="o">.</span><span class="n">shape</span>

<span class="c1"># Algorytm DBSCAN</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_dbscan</span> <span class="o">=</span> <span class="n">DBSCAN</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">min_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">model_dbscan</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_dbscan</span> <span class="o">=</span> <span class="n">model_dbscan</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># Spectral clustering</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_sc</span> <span class="o">=</span> <span class="n">SpectralClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">10.0</span><span class="p">)</span>
<span class="n">model_sc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_sc</span> <span class="o">=</span> <span class="n">model_sc</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># K-means++</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_plusplus</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">)</span>
<span class="n">model_plusplus</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_plusplus</span> <span class="o">=</span> <span class="n">model_plusplus</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_dbscan</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_sc</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_plusplus</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie DBSCAN&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie Spectral Clustering&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacją k-means++&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_1 wraz z centroidami&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Cza kalkulacji</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">] Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7_Klasteryzacja_87_0.png" src="../_images/7_Klasteryzacja_87_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (1000, 2)
[DBSCAN] Duration: 0:00:00.007999
[SPECTRAL] Duration: 0:00:00.206724
[KMEANS++] Duration: 0:00:00.032019
</pre></div>
</div>
</div>
</div>
<div class="alert alert-block alert-success">
<b>Zadanie</b> 
<p>Spróbuj nieco zmienić hiperparametry <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> oraz <code class="docutils literal notranslate"><span class="pre">eps</span></code>. Czy uda ci się lepiej podzielić obserwacje na klastry ?</p>
</div></div>
<div class="section" id="id5">
<h3>Przykład 2<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>Tym razem na warsztat weźmy zbiór danych <span class="math notranslate nohighlight">\(X_4\)</span>, który składa się z trzech okręgów o różnej średnicy. Zobaczmy jak w tym przypadku zadziała algorytm <em>DBSCAN</em> na tle innych.</p>
<p>Jak widać z powyższymi parametrami model <em>DBSCAN</em> znajduję klastry w taki sam sposób jak model <em>Spectral Clustering</em>. Jednakże bardzo duża różnica tkwi w czasie przeliczeń. W przypadku <em>DBSCAN</em> klastrowanie następuje ponad 1000 razy szybciej - przynajmniej w tym konkretnym przypadku. Wynika to ze złożoności obliczeń w algorytmie <em>Spectral Clustering</em>. Jeśli chodzi o <em>KMeans</em> to podobnie jak było to w <em>Przykład 1</em> klastry są dobierane zgodnie z założeniem wypukłości klastrów, co w tym przypadku nie jest oczekiwane.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;DBSCAN&#39;</span><span class="p">,</span> <span class="s1">&#39;SPECTRAL&#39;</span><span class="p">,</span> <span class="s1">&#39;KMEANS++&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_4</span><span class="o">.</span><span class="n">shape</span>

<span class="c1"># Algorytm DBSCAN</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_dbscan</span> <span class="o">=</span> <span class="n">DBSCAN</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">min_samples</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">model_dbscan</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_4</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_dbscan</span> <span class="o">=</span> <span class="n">model_dbscan</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># Algorytm Spectral clustering</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_sc</span> <span class="o">=</span> <span class="n">SpectralClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">10.0</span><span class="p">)</span>
<span class="n">model_sc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_4</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_sc</span> <span class="o">=</span> <span class="n">model_sc</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># Algorytm K-means++</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_plusplus</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">)</span>
<span class="n">model_plusplus</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_4</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_plusplus</span> <span class="o">=</span> <span class="n">model_plusplus</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_4</span><span class="p">)</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_4</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_4</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_dbscan</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_4</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_4</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_sc</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_4</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_4</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_plusplus</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie DBSCAN&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie Spectral Clustering&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacją k-means++&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_4 wraz z centroidami&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Cza kalkulacji</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">] Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7_Klasteryzacja_92_0.png" src="../_images/7_Klasteryzacja_92_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (3000, 2)
[DBSCAN] Duration: 0:00:00.023753
[SPECTRAL] Duration: 0:00:10.105079
[KMEANS++] Duration: 0:00:00.111169
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="bibliografia-dbscan">
<h3>Bibliografia [DBSCAN]<a class="headerlink" href="#bibliografia-dbscan" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/clustering.html#dbscan">https://scikit-learn.org/stable/modules/clustering.html#dbscan</a></p></li>
<li><p><a class="reference external" href="https://towardsdatascience.com/dbscan-clustering-explained-97556a2ad556">https://towardsdatascience.com/dbscan-clustering-explained-97556a2ad556</a></p></li>
<li><p><a class="reference external" href="https://dashee87.github.io/data%20science/general/Clustering-with-Scikit-with-GIFs/">https://dashee87.github.io/data science/general/Clustering-with-Scikit-with-GIFs/</a></p></li>
</ul>
</div>
</div>
<div class="section" id="birch">
<h2>BIRCH<a class="headerlink" href="#birch" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">Birch</span>
</pre></div>
</div>
</div>
</div>
<p>Algorytm <em>Balanced Iterative Reducing and Clustering using Hierarchies</em> w skrócie <strong>BIRCH</strong> buduje drzewo o nazwie <em>Clustering Feature Tree</em> (CFT) dla podanych danych, które są kompresowane stratnie do zestawu węzłów <em>Clustering Feature Nodes</em> (Nodes CF). Węzły CF mają pewną liczbę podklastrów zwanych <em>Clustering Feature Subclasters</em> (CFS). Podklastry CF przechowują informacje niezbędne do grupowania, co zapobiega konieczności przechowywania wszystkich danych wejściowych w pamięci. Informacje te obejmują:</p>
<ul class="simple">
<li><p><em>Number of Samples</em> - liczbę próbek w podgrupie,</p></li>
<li><p><em>Linear Sum</em> - sumę liniową, która jest n-wymiarowem wektorm przechowującym sumę wszystkich próbek,</p></li>
<li><p><em>Squared Sum</em> - suma kwadratów normy L2 dla wszystkich próbek,</p></li>
<li><p><em>Centroids</em> - centroidy równe <em>Linear Sum</em> / <em>Number of Samples</em>,</p></li>
<li><p>Norma kwadratowa centroidów.</p></li>
</ul>
<p>W dużym uproszczeniu algorytm <strong>BIRCH</strong> zajmuje się dużymi zestawami danych, najpierw generując bardziej zwarte podsumowanie, które zachowuje jak najwięcej informacji o rozkładzie, a następnie grupując podsumowanie danych zamiast oryginalnego zestawu obserwacji. Więcej informacji znajdziecie pod linkami w bibliografii.</p>
<div class="section" id="id6">
<h3>Przykład 1<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;BIRCH&#39;</span><span class="p">,</span> <span class="s1">&#39;MINIBATCH_KMEANS&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_3</span><span class="o">.</span><span class="n">shape</span>


<span class="c1"># BIRCH</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_brc</span> <span class="o">=</span> <span class="n">Birch</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">branching_factor</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">model_brc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_3</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_birch</span> <span class="o">=</span> <span class="n">model_brc</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1">#  Minibatch K-means</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_minibatch</span> <span class="o">=</span> <span class="n">MiniBatchKMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">model_minibatch</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_3</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_minibatch</span> <span class="o">=</span> <span class="n">model_minibatch</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_3</span><span class="p">)</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>


<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_3</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_3</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_birch</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_3</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_3</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_minibatch</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie BIRCH&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie MiniBatch KMeans&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_3&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Cza kalkulacji</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">] Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7_Klasteryzacja_99_0.png" src="../_images/7_Klasteryzacja_99_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (1000000, 2)
[BIRCH] Duration: 0:00:46.739096
[MINIBATCH_KMEANS] Duration: 0:00:01.380428
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id7">
<h3>Przykład 2<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;BIRCH&#39;</span><span class="p">,</span> <span class="s1">&#39;MINIBATCH_KMEANS&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_5</span><span class="o">.</span><span class="n">shape</span>


<span class="c1"># BIRCH</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_brc</span> <span class="o">=</span> <span class="n">Birch</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">branching_factor</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">model_brc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_5</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_birch</span> <span class="o">=</span> <span class="n">model_brc</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1">#  Minibatch K-means</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_minibatch</span> <span class="o">=</span> <span class="n">MiniBatchKMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">model_minibatch</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_5</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_minibatch</span> <span class="o">=</span> <span class="n">model_minibatch</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_5</span><span class="p">)</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>


<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_5</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_5</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_birch</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_5</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_5</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_minibatch</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie BIRCH&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie MiniBatch KMeans&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_5&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Cza kalkulacji</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">] Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7_Klasteryzacja_101_0.png" src="../_images/7_Klasteryzacja_101_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (10000, 2)
[BIRCH] Duration: 0:00:00.202899
[MINIBATCH_KMEANS] Duration: 0:00:00.112277
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="bibliografia-birch">
<h3>Bibliografia [BIRCH]<a class="headerlink" href="#bibliografia-birch" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/clustering.html#mean-shift">https://scikit-learn.org/stable/modules/clustering.html#mean-shift</a></p></li>
<li><p><a class="reference external" href="https://towardsdatascience.com/machine-learning-birch-clustering-algorithm-clearly-explained-fb9838cbeed9">https://towardsdatascience.com/machine-learning-birch-clustering-algorithm-clearly-explained-fb9838cbeed9</a></p></li>
</ul>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="analiza-skutecznosci">
<h1>Analiza skuteczności<a class="headerlink" href="#analiza-skutecznosci" title="Permalink to this headline">¶</a></h1>
<p>Badanie skuteczności algorytmów klastrujących nie jest łatwe. W zależności od problemu biznesowego oczekujemy zupełnie innych wyników. Dodatkowo w przypadku danych wielowymiarowych, gdzie wykorzystujemy do klastrowania więcej niż dwie, trzy zmienne pojawiają się dodatkowo problemy z wizualizacją wyników. W tym przypadku mogą się przydać algorytmy z rodziny redukcji wymiarowości tj. PCA, ICA czy TSNE. Nadal jednak potrzebujemy odpowiedzieć sobie na pytanie czy dany podział na klastry jest prawidłowy ? W końcu nie będziemy dokonywać decyzji biznesowych  wyłącznie na podstawie wizualizacji wyników - do tego potrzebujemy odpowiednich metryk. Dodatkowo w przypadku automatyzacji naszego procesu nie będzie czasu na to, aby przy każdym przeliczeniu sprawdzać wizualne wyniki, ale będziemy chcieli podejmować decyzje na podstawie wybranej, bądź wybranych metryk aby ostatecznie nasz proces był w pełni zautomatyzowany.</p>
<p>W poniższej części zostanie wprowadzonych kilka podstawowych miar, które mogą pomóc nam w zadaniu analizy skuteczności klastrowania.</p>
<div class="section" id="silhouette-coefficient">
<h2>Silhouette Coefficient<a class="headerlink" href="#silhouette-coefficient" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>
</pre></div>
</div>
</div>
</div>
<p>Jedną z najpopularniejszych metod do oceny jakości klastrowania jest metryka <em>Silhouette Coefficient</em>. Jej wysoką wartość interpretujemy jako bardzo dobrze wykonane klastrowanie. Metryka zdefiniowana jest dla każdej obserwacji z osobna w następujący sposób:</p>
<div class="math notranslate nohighlight">
\[ s = \frac{b-a}{\max(a, b)}\]</div>
<p>gdzie:</p>
<ul class="simple">
<li><p>a: średnia odległość pomiędzy obserwacją oraz resztą obserwacji z tego samego klastra</p></li>
<li><p>b: średnia odległość pomiędzy obserwacją oraz innymi obserwacjami z kolejnego <strong>najbliższego</strong> klastra</p></li>
</ul>
<p>Metryka <em>Silhouette coefficient</em> dla zbioru obserwacji jest średnią z wartości <span class="math notranslate nohighlight">\(s\)</span> dla każdej obserwacji z osobna.</p>
<p><strong>Warto zapamiętać</strong></p>
<ul class="simple">
<li><p>metryka osiąga wyniki z przedziału [-1, 1], gdzie -1 oznacza zupełnie błędne dopasowanie, a 1 bardzo dobrze podzielone zbiory. W przypadku wartości 0 nie jesteśmy nic w stanie stwierdzić apropo podziału zbioru danych na grupy</p></li>
<li><p>wynik jest wyższy, gdy klastry są gęste i dobrze odseparowane od siebie (Przykład 1)</p></li>
<li><p>wynik jest wyższy w przypadku klastrów wypukłych (Przykład 1), niż dla innych rodzajów klastrów np. takich opartych na gęstości jak DBSCAN (Przykład 2)</p></li>
</ul>
</div>
<div class="section" id="calinski-harabasz-index">
<h2>Caliński-Harabasz Index<a class="headerlink" href="#calinski-harabasz-index" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">calinski_harabasz_score</span>
</pre></div>
</div>
</div>
</div>
<p>Kolejną metryką przydatną w trakcie klastrowania jest mniej popularna metryka <em>Calinski-Harabasz</em>, inaczej zwana <em>Variance Ratio Criterion</em>. Została ona zaproponowana przez Polskich naukowców Calińskiego i Harabasza w 1972 roku.  Podobnie jak w przypadku poprzedniej metryki wyższa wartość oznacza lepsze grupowanie danych w klastry. Metrykę <em>Variance Ratio Criterion</em> dla zbioru danych <span class="math notranslate nohighlight">\(E\)</span> o liczbie obserwacji <span class="math notranslate nohighlight">\(n\)</span> oraz liczbie klastrów <span class="math notranslate nohighlight">\(k\)</span> definiujemy w następujacy sposób:</p>
<div class="math notranslate nohighlight">
\[ s = \frac{tr(B_{k})}{tr(W_{k})} x \frac{n - k}{k-1}\]</div>
<p>gdzie <span class="math notranslate nohighlight">\(tr(B_{k})\)</span> oraz <span class="math notranslate nohighlight">\(tr(W_{k})\)</span> jest śladem macierzy <span class="math notranslate nohighlight">\(B_{k}\)</span> oraz <span class="math notranslate nohighlight">\(W_{k}\)</span>. Dla przypomnienia ślad macierzy <span class="math notranslate nohighlight">\(A\)</span> definiujemy jako:</p>
<div class="math notranslate nohighlight">
\[ tr(A) = \sum_{i=1}^{n} a_{ii} = a_{11}+a_{22}+a_{33}+...\]</div>
<p>czyli jest to suma wartości na przekątnej macierzy kwdaratowej. Macierze <span class="math notranslate nohighlight">\(B_{k}\)</span> oraz <span class="math notranslate nohighlight">\(W_{k}\)</span> są wyliczane dla każdego klastra z osobna i mają następująco postać:</p>
<div class="math notranslate nohighlight">
\[ W_{k} = \sum_{q=1}^{k}\sum_{x \in C_{q}}(x-c_{q})(x-c_{q})^{T} \]</div>
<div class="math notranslate nohighlight">
\[ B_{k} = \sum_{q=1}^{k}n_{q}(c_{q}-c_{E})(c_{q}-c_{E})^{T} \]</div>
<p>gdzie <span class="math notranslate nohighlight">\(C_{q}\)</span> jest zbiorem obserwacji klastra <span class="math notranslate nohighlight">\(q\)</span>, <span class="math notranslate nohighlight">\(c_{q}\)</span> jest środkiem klastra <span class="math notranslate nohighlight">\(q\)</span>, <span class="math notranslate nohighlight">\(c_{E}\)</span> jest środkiem całego zbioru obserwacj <span class="math notranslate nohighlight">\(E\)</span> oraz <span class="math notranslate nohighlight">\(n_{q}\)</span> jest liczbą obserwacji w klastrze <span class="math notranslate nohighlight">\(q\)</span>.</p>
<p><strong>Warto zapamiętać</strong></p>
<ul class="simple">
<li><p>wartość metryki jest wyższa, gdy klastry są gęste oraz dobrze rozdzielone od siebie</p></li>
<li><p>metryka jest szybka do kalkulacji</p></li>
</ul>
</div>
<div class="section" id="davies-bouldin-index">
<h2>Davies-Bouldin Index<a class="headerlink" href="#davies-bouldin-index" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">davies_bouldin_score</span>
</pre></div>
</div>
</div>
</div>
<p>Ostatnim z analizowanych metryk skuteczności klastrowania jest <em>Davies-Bouldin Index</em>. Metryka mierzy średnie “podobieństwo” między klastrami. Wtedy wartość równa zero jest najniższą osiągana wartością, natomiast 1 najwyższa. Jak nie trudno się domyślić chcemy aby klastry był jak najmniej do siebie podobne stąd interesuje nas jak najniższa wartość tej metryki.</p>
<p><em>Davies-Bouldin Index</em> definiujemy jako średnie podobieństwo między klastrami <span class="math notranslate nohighlight">\(C_{i}\)</span> dla <span class="math notranslate nohighlight">\(i=1, 2, ..., k\)</span> oraz najbardziej podobnym klastrem <span class="math notranslate nohighlight">\(C_{j}\)</span>. Podobieństwo jest definiowane za pomocą wartości <span class="math notranslate nohighlight">\(R_{ij}\)</span> oraz wzoru:</p>
<div class="math notranslate nohighlight">
\[ R_{ij} = \frac{s_{i} + s_{j}}{d_{ij}}\]</div>
<p>gdzie:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(s_{i}\)</span> jest średnią odległością pomiędzy każdą z obserwacji klastra <span class="math notranslate nohighlight">\(i\)</span> oraz centroidu tego klastra</p></li>
<li><p><span class="math notranslate nohighlight">\(d_{ij}\)</span> jest odległością pomiędzy centroidami klastrów <span class="math notranslate nohighlight">\(i\)</span> oraz <span class="math notranslate nohighlight">\(j\)</span></p></li>
</ul>
<p>Wtedy <em>Davies-Bouldin Index</em> ma następującą postać:</p>
<div class="math notranslate nohighlight">
\[ DB = \frac{1}{k} \sum_{i=1}^{k}\max_{i \neq j} R_{ij}\]</div>
<p><strong>Warto zapamiętać</strong></p>
<ul class="simple">
<li><p>kalkulacja tej metryki <em>Davies-Bouldin index</em> jest prostsza niż <em>Silhouette coefficient</em></p></li>
<li><p>podobnie jak poprzednie metody <em>Davies-Bouldin index</em> osiąga lepsze wyniki dla klastrów wypukłych, lepiej odseparowanych od siebie niż dla metod opartych o gęstość jak DBSCAN.</p></li>
</ul>
</div>
<div class="section" id="dunn-index">
<h2>Dunn Index<a class="headerlink" href="#dunn-index" title="Permalink to this headline">¶</a></h2>
<p>…</p>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="przyklady-analiza-skutecznosci">
<h1>Przykłady (analiza skuteczności)<a class="headerlink" href="#przyklady-analiza-skutecznosci" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id8">
<h2>Przykład 1<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h2>
<p>Poniżej widoczne są 3 rodzaje klastrowania. Wizualizacja 1 jest wynikiem klastrowania KMeans z inicjalizacją random dla trzech klastrów. Dodatkowo w tym przypadku stosujemy tylko jedną iteracje algorytmu aby wynik był niezadawalający. Kolejne wizualizacja jest wynikiem algorytmu KMeans++ z trzema klastrami, zaś ostatnia to wynik KMeans++ z czterama klastrami. Gołym okiem widać, że drugi rodzaj klastrowania jest najlepszy. Jak wyglądają wyniki względem metryki <em>Silhouette coeffcient</em> ? Wartość najwyższa jest osiągana dla drugiego algorytmu - tak jak się spodziewaliśmy. Dużo niższe wyniki są dla algorytmu pierwszego i trzeciego. To pokazuję na siłę tej metryki, która oprócz informacji jaki algorytm wybrać (KMeans z inicjalizacją random czy Kmeans++) to dodatkowo może pomóc nam w wyborze liczby klastrów dla naszych danych (3 a może 4?). Najczęściej w tego typu przypadkach jest wykorzystywana ta metryka.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;KMEANS_RANDOM&#39;</span><span class="p">,</span> <span class="s1">&#39;KMEANS++(3)&#39;</span><span class="p">,</span> <span class="s1">&#39;KMEANS++(4)&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">silh_distances</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">calinski_distances</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">db_distances</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_2</span><span class="o">.</span><span class="n">shape</span>

<span class="c1"># K-means random, ncluster=3</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_random</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;random&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model_random</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_random</span> <span class="o">=</span> <span class="n">model_random</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>
<span class="n">silh_dist</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X_2</span><span class="p">,</span> <span class="n">y_cluster_random</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">silh_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">silh_dist</span><span class="p">)</span>
<span class="n">cali_dist</span> <span class="o">=</span> <span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">X_2</span><span class="p">,</span> <span class="n">y_cluster_random</span><span class="p">)</span>
<span class="n">calinski_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cali_dist</span><span class="p">)</span>
<span class="n">db_dist</span> <span class="o">=</span> <span class="n">davies_bouldin_score</span><span class="p">(</span><span class="n">X_2</span><span class="p">,</span> <span class="n">y_cluster_random</span><span class="p">)</span>
<span class="n">db_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">db_dist</span><span class="p">)</span>

<span class="c1"># K-means++, ncluster=3</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_plusplus</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">)</span>
<span class="n">model_plusplus</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_plusplus</span> <span class="o">=</span> <span class="n">model_plusplus</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>
<span class="n">silh_dist</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X_2</span><span class="p">,</span> <span class="n">y_cluster_plusplus</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">silh_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">silh_dist</span><span class="p">)</span>
<span class="n">cali_dist</span> <span class="o">=</span> <span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">X_2</span><span class="p">,</span> <span class="n">y_cluster_plusplus</span><span class="p">)</span>
<span class="n">calinski_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cali_dist</span><span class="p">)</span>
<span class="n">db_dist</span> <span class="o">=</span> <span class="n">davies_bouldin_score</span><span class="p">(</span><span class="n">X_2</span><span class="p">,</span> <span class="n">y_cluster_plusplus</span><span class="p">)</span>
<span class="n">db_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">db_dist</span><span class="p">)</span>

<span class="c1"># K-means++, ncluster=4</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_plusplus4</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">)</span>
<span class="n">model_plusplus4</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_plusplus4</span> <span class="o">=</span> <span class="n">model_plusplus4</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_2</span><span class="p">)</span>
<span class="n">silh_dist</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X_2</span><span class="p">,</span> <span class="n">y_cluster_plusplus4</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">silh_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">silh_dist</span><span class="p">)</span>
<span class="n">cali_dist</span> <span class="o">=</span> <span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">X_2</span><span class="p">,</span> <span class="n">y_cluster_plusplus4</span><span class="p">)</span>
<span class="n">calinski_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cali_dist</span><span class="p">)</span>
<span class="n">db_dist</span> <span class="o">=</span> <span class="n">davies_bouldin_score</span><span class="p">(</span><span class="n">X_2</span><span class="p">,</span> <span class="n">y_cluster_plusplus4</span><span class="p">)</span>
<span class="n">db_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">db_dist</span><span class="p">)</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_random</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_plusplus</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_plusplus4</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacja random </span><span class="se">\n</span><span class="s1">(ncluster=3)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacją k-means++ </span><span class="se">\n</span><span class="s1">(ncluster=3)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans z inicjalizacją k-means++ </span><span class="se">\n</span><span class="s1">(ncluster=4)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_2 wraz z centroidami&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Czas kalkulacji / Silhouette score / Calinski-Harabasz score / Davies-Boulding index</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span><span class="p">,</span> <span class="n">silh</span><span class="p">,</span> <span class="n">cali</span><span class="p">,</span> <span class="n">db</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">,</span> <span class="n">silh_distances</span><span class="p">,</span> <span class="n">calinski_distances</span><span class="p">,</span> <span class="n">db_distances</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;-----------[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">]-----------&#39;</span><span class="p">)</span> 
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Silhouette coeffcient: </span><span class="si">{</span><span class="n">silh</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Calinski-Harabasz coeffcient: </span><span class="si">{</span><span class="n">cali</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Davies-Bouldin index: </span><span class="si">{</span><span class="n">db</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7_Klasteryzacja_123_0.png" src="../_images/7_Klasteryzacja_123_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (1500, 2)


-----------[KMEANS_RANDOM]-----------
Duration: 0:00:00
Silhouette coeffcient: 0.3490213397936618
Calinski-Harabasz coeffcient: 1842.6378071189322
Davies-Bouldin index: 1.0000636224579476


-----------[KMEANS++(3)]-----------
Duration: 0:00:00.017297
Silhouette coeffcient: 0.7333423486262539
Calinski-Harabasz coeffcient: 10633.868943793219
Davies-Bouldin index: 0.3645102673195062


-----------[KMEANS++(4)]-----------
Duration: 0:00:00.046877
Silhouette coeffcient: 0.5853530244304029
Calinski-Harabasz coeffcient: 8089.376315003494
Davies-Bouldin index: 0.800320597852641
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id9">
<h2>Przykład 2<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h2>
<p>Niestety nie zawsze powyższe metryki się sprawdzają. W poniższym przykładzie porównujemy między sobą 3 kklastrowania: <em>KMeans++</em>, <em>Spectral Clustering</em> oraz <em>DBSCAN</em>. Każda z tych metod dzieli obserwacje w innym sposób. Wydaję się, że najgorzej robi to metoda <em>KMeans++</em>, natomiast Spectral Clustering oraz <em>DBSCAN</em> działają podobnie, choć <em>DBSCAN</em> wskazuję nam jeszcze pewne anomalie w naszych danych. Jeśli jednak spojrzymy na wyniki tych metryk to okazuję się, że żadna z trzech metryk nie odpowie nam na pytanie, które z tych klastrowań jest poprawne. W tego typu problemach, gdzie klastry nie charakteryzują się rozkładem normalnym metryka każda z tych metryk nie do końca zda egzamin.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;KMEANS++&#39;</span><span class="p">,</span> <span class="s1">&#39;SPECTRAL_RBF&#39;</span><span class="p">,</span> <span class="s1">&#39;DBSCAN&#39;</span><span class="p">]</span>
<span class="n">eval_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">silh_distances</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">calinski_distances</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">db_distances</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">shape_X</span> <span class="o">=</span> <span class="n">X_1</span><span class="o">.</span><span class="n">shape</span>

<span class="c1"># KMeans++</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span><span class="p">)</span>
<span class="n">model_kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_plus_plus</span> <span class="o">=</span> <span class="n">model_kmeans</span><span class="o">.</span><span class="n">labels_</span>
<span class="n">silh_dist</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X_1</span><span class="p">,</span> <span class="n">y_cluster_plus_plus</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">silh_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">silh_dist</span><span class="p">)</span>
<span class="n">cali_dist</span> <span class="o">=</span> <span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">X_1</span><span class="p">,</span> <span class="n">y_cluster_plus_plus</span><span class="p">)</span>
<span class="n">calinski_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cali_dist</span><span class="p">)</span>
<span class="n">db_dist</span> <span class="o">=</span> <span class="n">davies_bouldin_score</span><span class="p">(</span><span class="n">X_1</span><span class="p">,</span> <span class="n">y_cluster_plus_plus</span><span class="p">)</span>
<span class="n">db_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">db_dist</span><span class="p">)</span>

<span class="c1"># Spectral Clustering (RBF)</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_sc</span> <span class="o">=</span> <span class="n">SpectralClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">affinity</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">assign_labels</span><span class="o">=</span><span class="s1">&#39;kmeans&#39;</span><span class="p">)</span>
<span class="n">model_sc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_spectral_rbf</span> <span class="o">=</span> <span class="n">model_sc</span><span class="o">.</span><span class="n">labels_</span>
<span class="n">silh_dist</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X_1</span><span class="p">,</span> <span class="n">y_cluster_spectral_rbf</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">silh_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">silh_dist</span><span class="p">)</span>
<span class="n">cali_dist</span> <span class="o">=</span> <span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">X_1</span><span class="p">,</span> <span class="n">y_cluster_spectral_rbf</span><span class="p">)</span>
<span class="n">calinski_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cali_dist</span><span class="p">)</span>
<span class="n">db_dist</span> <span class="o">=</span> <span class="n">davies_bouldin_score</span><span class="p">(</span><span class="n">X_1</span><span class="p">,</span> <span class="n">y_cluster_spectral_rbf</span><span class="p">)</span>
<span class="n">db_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">db_dist</span><span class="p">)</span>

<span class="c1"># Algorytm DBSCAN</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="n">model_dbscan</span> <span class="o">=</span> <span class="n">DBSCAN</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">min_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">model_dbscan</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>  
<span class="n">eval_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>

<span class="n">y_cluster_dbscan</span> <span class="o">=</span> <span class="n">model_dbscan</span><span class="o">.</span><span class="n">labels_</span>
<span class="n">silh_dist</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X_1</span><span class="p">,</span> <span class="n">y_cluster_dbscan</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">silh_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">silh_dist</span><span class="p">)</span>
<span class="n">cali_dist</span> <span class="o">=</span> <span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">X_1</span><span class="p">,</span> <span class="n">y_cluster_dbscan</span><span class="p">)</span>
<span class="n">calinski_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cali_dist</span><span class="p">)</span>
<span class="n">db_dist</span> <span class="o">=</span> <span class="n">davies_bouldin_score</span><span class="p">(</span><span class="n">X_1</span><span class="p">,</span> <span class="n">y_cluster_dbscan</span><span class="p">)</span>
<span class="n">db_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">db_dist</span><span class="p">)</span>

<span class="c1"># Wizualizacja</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_plus_plus</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_spectral_rbf</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">y_cluster_dbscan</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie KMeans++&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie Spectral Clustering (RBF)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Klastrowanie DBSCAN&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Obserwacje X_1 wraz z centroidami&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Czas kalkulacji / Silhouette score / Calinski-Harabasz score / Davies-Boulding index</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data frame shape: </span><span class="si">{</span><span class="n">shape_X</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">etime</span><span class="p">,</span> <span class="n">silh</span><span class="p">,</span> <span class="n">cali</span><span class="p">,</span> <span class="n">db</span>  <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">algorithms</span><span class="p">,</span> <span class="n">eval_times</span><span class="p">,</span> <span class="n">silh_distances</span><span class="p">,</span> <span class="n">calinski_distances</span><span class="p">,</span> <span class="n">db_distances</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;-----------[</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s1">]-----------&#39;</span><span class="p">)</span> 
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Duration: </span><span class="si">{</span><span class="n">etime</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Silhouette coeffcient: </span><span class="si">{</span><span class="n">silh</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Calinski-Harabasz coeffcient: </span><span class="si">{</span><span class="n">cali</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Davies-Bouldin index: </span><span class="si">{</span><span class="n">db</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7_Klasteryzacja_126_0.png" src="../_images/7_Klasteryzacja_126_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data frame shape: (1000, 2)


-----------[KMEANS++]-----------
Duration: 0:00:00.041757
Silhouette coeffcient: 0.4270730877908618
Calinski-Harabasz coeffcient: 886.9661372979564
Davies-Bouldin index: 0.9324389060600777


-----------[SPECTRAL_RBF]-----------
Duration: 0:00:00.187579
Silhouette coeffcient: 0.42967355323274
Calinski-Harabasz coeffcient: 658.0643390191713
Davies-Bouldin index: 0.9970552748687121


-----------[DBSCAN]-----------
Duration: 0:00:00
Silhouette coeffcient: 0.41572411786070823
Calinski-Harabasz coeffcient: 310.90990033808214
Davies-Bouldin index: 10.006292286691176
</pre></div>
</div>
</div>
</div>
<p>W zależności od problemu do identyfikacji czy nasze klastry są dobrane poprawnie można wykorzystać uczenie maszynowe. W powyższym przykładzie wydaję się zastosowanie regresji liniowej dla zmiennej <span class="math notranslate nohighlight">\(x\)</span> względem zmiennej celu <span class="math notranslate nohighlight">\(y\)</span> pozwoliło by sprawdzić jak podstawowy model wyjaśni nam takie dane. Jeśli model działajacy na klastrach działa lepiej niż dla wszystkich obserwacji to można przypuszczać, że nasze klastrowanie jest dobre. Porównując się do róznych metod kalstrowanie można wtedy badać błędy MAE, RMSE czy R2.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./7. Klasteryzacja"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../10.%20Czyszczenie_danych/Czyszczenie%20danych.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Czyszczenie danych</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../12.%20Klasyfikacja/Klasyfikacja.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Klasyfikacja w Python</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By codersi<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>